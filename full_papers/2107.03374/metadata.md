# Evaluating Large Language Models Trained on Code
## تقييم نماذج اللغة الكبيرة المدربة على الشفرة البرمجية

**arXiv ID:** 2107.03374
**Authors:** Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, Wojciech Zaremba
**Year:** 2021
**Publication:** arXiv preprint
**Categories:** Machine Learning (cs.LG)
**DOI:** arXiv:2107.03374v2
**PDF:** https://arxiv.org/pdf/2107.03374.pdf

**Abstract Translation Quality:** 0.92 (from translations/)
**Full Paper Translation Quality:** TBD

## Citation

```bibtex
@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}
```

## Translation Team
- Translator: Claude (Anthropic) - Session 2025-11-16
- Reviewer: TBD
- Started: 2025-11-16
- Completed: TBD

## Paper Overview
This paper introduces Codex, a GPT language model fine-tuned on publicly available code from GitHub. The paper evaluates Codex's Python code-writing capabilities using HumanEval, a new benchmark for measuring functional correctness. Key contributions include analysis of sampling strategies, supervised fine-tuning approaches, and comprehensive discussion of broader impacts including safety, security, bias, and economic implications.

## Sections
- 00-abstract.md
- 01-introduction.md
- 02-evaluation-framework.md
- 03-code-finetuning.md
- 04-supervised-finetuning.md
- 05-docstring-generation.md
- 06-limitations.md
- 07-broader-impacts.md
- 08-related-work.md
- 09-conclusion.md
- 10-appendices.md (A-H)
