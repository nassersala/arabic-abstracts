                                                                            ReÌnyi Differential Privacy
                                                                                                       Ilya Mironov
                                                                                                        Google Brain


                                            Abstractâ€”We propose a natural relaxation of differential                The second common use of (Ç«, Î´)-differential privacy is
                                         privacy based on the ReÌnyi divergence. Closely related notions         due to applications of advanced composition theorems. The
                                         have appeared in several recent papers that analyzed composition        central feature of Ç«-differential privacy is that it is closed
                                         of differentially private mechanisms. We argue that the useful
                                                                                                                 under composition; moreover, the Ç« parameters of composed
arXiv:1702.07476v3 [cs.CR] 25 Aug 2017




                                         analytical tool can be used as a privacy definition, compactly and
                                         accurately representing guarantees on the tails of the privacy loss.    mechanisms simply add up, which motivates the concept of a
                                            We demonstrate that the new definition shares many important         privacy budget. By relaxing the guarantee to (Ç«, Î´)-differential
                                         properties with the standard definition of differential privacy,        privacy, advanced composition allows tighter analyses for
                                         while additionally allowing tighter analysis of composite hetero-       compositions of (pure) differentially private mechanisms. Iter-
                                         geneous mechanisms.
                                                                                                                 ating this process, however, quickly leads to a combinatorial
                                                                 I. I NTRODUCTION                                explosion of parameters, as each application of an advanced
                                            Differential privacy, introduced by Dwork et al. [1], has            composition theorem leads to a wide selection of possibilities
                                         been embraced by multiple research communities as a com-                for (Ç«(Î´), Î´)-differentially private guarantees.
                                         monly accepted notion of privacy for algorithms on statistical
                                                                                                                    In part to address the shortcomings of (Ç«, Î´)-differential
                                         databases. As applications of differential privacy begin to
                                                                                                                 privacy, several recent works, surveyed in the next section,
                                         emerge, practical concerns of tracking and communicating
                                                                                                                 explored the use of higher-order moments as a way of bound-
                                         privacy guarantees are coming to the fore.
                                                                                                                 ing the tails of the privacy loss variable.
                                            Informally, differential privacy bounds a shift in the output
                                         distribution of a randomized algorithm that can be induced                 Inspired by these theoretical results and their applications,
                                         by a small change in its input. The standard definition of Ç«-           we propose ReÌnyi differential privacy as a natural relaxation
                                         differential privacy puts a multiplicative upper bound on the           of differential privacy that is well-suited for expressing guar-
                                         worst-case change in the distributionâ€™s density.                        antees of privacy-preserving algorithms and for composition
                                            Several relaxations of differential privacy explored other           of heterogeneous mechanisms. Compared to (Ç«, Î´)-differential
                                         measures of closeness between two distributions. The most               privacy, ReÌnyi differential privacy is a strictly stronger privacy
                                         common such relaxation, the (Ç«, Î´) definition, has been a               definition. It offers an operationally convenient and quan-
                                         method of choice for expressing privacy guarantees of a                 titatively accurate way of tracking cumulative privacy loss
                                         variety of differentially private algorithms, especially those          throughout execution of a standalone differentially private
                                         that rely on the Gaussian additive noise mechanism or whose             mechanism and across many such mechanisms. Most sig-
                                         analysis follows from composition theorems. The additive Î´              nificantly, ReÌnyi differential privacy allows combining the
                                         parameter allows suppressing the long tails of the mechanismâ€™s          intuitive and appealing concept of a privacy budget with
                                         distribution where pure Ç«-differential privacy guarantees may           application of advanced composition theorems.
                                         not hold.
                                            Compared to the standard definition, (Ç«, Î´)-differential pri-           The paper presents a self-contained exposition of the new
                                         vacy offers asymptotically smaller cumulative loss under                definition, unifying current literature and demonstrating its
                                         composition and allows greater flexibility in the selection of          applications. The organization of the paper is as follows. Sec-
                                         privacy-preserving mechanisms.                                          tion II reviews the standard definition of differential privacy,
                                            Despite its notable advantages and numerous applications,            its (Ç«, Î´) relaxation and its most common uses. Section III in-
                                         the definition of (Ç«, Î´)-differential privacy is an imperfect fit for   troduces the definition of ReÌnyi differential privacy and proves
                                         its two most common use cases: the Gaussian mechanism and               its basic properties that parallel those of Ç«-differential privacy,
                                         a composition rule. We briefly sketch them here and elaborate           summarizing the results in Table I. Section IV demonstrates a
                                         on these points in the next section.                                    reduction from ReÌnyi differential privacy to (Ç«, Î´)-differential
                                            The first application of (Ç«, Î´)-differential privacy was the         privacy, followed by a proof of an advanced composition
                                         analysis of the Gaussian noise mechanism [2]. In contrast               theorem in Section V. Section VI applies ReÌnyi differential
                                         with the Laplace mechanism, whose privacy guarantee is                  privacy to analysis of several basic mechanisms: randomized
                                         characterized tightly and accurately by Ç«-differential privacy,         response for predicates, Laplace and Gaussian (see Table II for
                                         a single Gaussian mechanism satisfies a curve of (Ç«(Î´), Î´)-             a brief summary). Section VII discusses assessment of risk due
                                         differential privacy definitions. Picking any one point on this         to application of a ReÌnyi differentially private mechanism and
                                         curve leaves out important information about the mechanismâ€™s            use of ReÌnyi differential privacy as a privacy loss tracking
                                         actual behavior.                                                        tool. Section VIII concludes with open questions.
       II. D IFFERENTIAL P RIVACY AND I TS F LAVORS                   differ in what happens with the remaining probability Î´. In
                                                                      the first scenario privacy degrades gracefully, such as to Ç«1 -
Ç«-D IFFERENTIAL PRIVACY [1]. We first recall the standard             DP with probability Î´/2, to Ç«2 -DP with probability Î´/4, etc.
definition of Ç«-differential privacy.                                 In the other scenario, with probability Î´ the secretâ€”whether
Definition 1 (Ç«-DP). A randomized mechanism f : D 7â†’                  the record is part of the database or notâ€”becomes completely
R satisfies Ç«-differential privacy (Ç«-DP) if for any adjacent         exposed. The difference between the two failure modes can
D, Dâ€² âˆˆ D and S âŠ‚ R                                                   be quite stark. In the former, there is always some residual
                                                                      deniability; in the latter, the adversary occasionally learns the
              Pr[f (D) âˆˆ S] â‰¤ eÇ« Pr[f (Dâ€² ) âˆˆ S].                     secret with certainty. Depending on the adversaryâ€™s tolerance
                                                                      to false positives, plausible deniability may offer adequate
   The above definition is contingent on the notion of adjacent
                                                                      protection, but a single (Ç«, Î´)-DP privacy statement cannot
inputs D and Dâ€² , which is domain-specific and is typically
                                                                      differentiate between the two alternatives. For a lively parable
chosen to capture the contribution to the mechanismâ€™s input
                                                                      of the different guarantees offered by the Ç«-DP and (Ç«, Î´)-DP
by a single individual.
                                                                      definitions see McSherry [5].
   The Laplace mechanism is a prototypical Ç«-differentially
                                                                         To avoid the worst-case scenario of always violating privacy
private algorithm, allowing release of an approximate (noisy)
                                                                      of a Î´ fraction of the dataset, the standard recommendation
answer to an arbitrary query with values in Rn . The mecha-
                                                                      is to choose Î´ â‰ª 1/N or even Î´ = negl(1/N ), where N is
nism is defined as
                                                                      the number of contributors. This strategy forecloses possibility
               LÇ« f (x) , f (x) + Î›(0, âˆ†1 f /Ç«),                      of one particularly devastating outcome, but other forms of
                                                                      information leakage remain.
where Î› is the Laplace distribution and â„“1 -sensitivity of the           The definition of (Ç«, Î´)-differential privacy was initially
query f is                                                            proposed to capture privacy guarantees of the Gaussian mech-
              âˆ†1 f , maxâ€² kf (D) âˆ’ f (Dâ€² )k1                          anism, defined as follows:
                         D,D

taken over all adjacent inputs D and Dâ€² .                                              GÏƒ f (x) , f (x) + N (0, Ïƒ 2 ).
   The basic composition theorem states that if f and g are,          Elementary analysis shows that the Gaussian mechanism can-
respectively, Ç«1 - and Ç«2 -DP, then the simultaneous release          not meet Ç«-DP for any Ç«. Instead, it satisfies a continuum
of f (D) and g(D) satisfies (Ç«1 + Ç«2 )-DP. Moreover, the              of incomparablep(Ç«, Î´)-DP guarantees, for all combinations of
mechanism g may be selected adaptively, after seeing the              Ç« < 1 and Ïƒ > 2 ln 1.25/Î´âˆ†2 f /Ç«, where f â€™s â„“2 -sensitivity
output of f (D).                                                      is defined as
(Ç«, Î´)-D IFFERENTIAL PRIVACY [2]. A relaxation of Ç«-                                  âˆ†2 f , maxâ€² kf (D) âˆ’ f (Dâ€² )k2
                                                                                              D,D
differential privacy allows a Î´ additive term in its defining
inequality:                                                           taken over all adjacent inputs D and Dâ€² .
                                                                         There exist valid reasons for preferring the Gaussian mech-
Definition 2 ((Ç«, Î´)-DP). A randomized mechanism f : D 7â†’             anism over Laplace: the noise comes from the same Gaussian
R offers (Ç«, Î´)-differential privacy if for any adjacent D, Dâ€² âˆˆ      distribution (closed under addition) as the error that may
D and S âŠ‚ R                                                           already be present in the dataset; the standard deviation of the
            Pr[f (D) âˆˆ S] â‰¤ eÇ« Pr[f (Dâ€² ) âˆˆ S] + Î´.                   noise is proportional to the queryâ€™s â„“2 sensitivity, which is no
                                                                      larger and often much smaller than â„“1 ; for the same standard
   The common interpretation of (Ç«, Î´)-DP is that it is Ç«-DP          deviation, the tails of the Gaussian (normal) distribution decay
â€œexcept with probability Î´â€. Formalizing this statement runs          much faster than those of the Laplace (exponential) distribu-
into difficulties similar to the ones addressed by Mironov et         tion. Unfortunately, distilling the guarantees of the Gaussian
al. [3] for a different (computational) relaxation. For any two       mechanism down to a single number or a small set of numbers
adjacent inputs, D1 and D2 , it is indeed possible to define an       using the language of (Ç«, Î´)-DP always leaves a possibility of
Ç«-DP mechanism that agrees with f with all but Î´ probability.         a complete privacy compromise that the mechanism itself may
Extending this argument to domains of exponential sizes (for          not allow.
instance, to a boolean hypercube) cannot be done without                 Another common reason for bringing in (Ç«, Î´)-differential
diluting the guarantee exponentially [4]. We conclude that            privacy is application of advanced composition theorems.
(Ç«, Î´)-differential privacy is a qualitatively different definition   Consider the case of k-fold adaptive composition of an (Ç«, Î´)-
than pure Ç«-DP (unless, of course, Î´ = 0, which we assume             DP mechanism. For any Î´ â€² > 0 it holds that   p the composite
not to be the case through the rest of this section).                 mechanism is (Ç«â€² , kÎ´ + Î´ â€² )-DP, where Ç«â€² , 2k ln(1/Î´ â€² )Ç« +
   Even for the simple case of exactly two input databases            kÇ«(eÇ« âˆ’ 1) [6]. Note that, similarly to our discussion of the
(such as when the adversary knows the entire dataset except           Gaussian mechanism, a single mechanism satisfies a contin-
whether it contains a particular record), the Î´ additive term         uum of incomparable (Ç«, Î´)-DP guarantees.
encompasses two very different modes in which privacy may                Kairouz et al. give a procedure for computing an optimal
fail. In both scenarios Ç«-DP holds with probability 1 âˆ’ Î´, they       k-fold composition of an (Ç«, Î´)-DP mechanism [7]. Murtagh
and Vadhan [8] demonstrate that generalizing this result to           nection between the two notions has been pointed out before
composition of heterogeneous mechanisms (i.e., satisfying             (mostly for one extreme order, known as the Kullback-Leibler
(Ç«i , Î´i )-DP for different Ç«i â€™s) is #P-hard; they describe a PTAS   divergence [6], [17]); our contribution is in systematically
for an approximate solution. None of these works tackles the          exploring the relationship and its practical implications.
problem of composing mechanisms that satisfy several (Ç«, Î´)-            The (parameterized) ReÌnyi divergence is classically defined
DP guarantees simultaneously.                                         as follows [18]:
( ZERO )-C ONCENTRATED D IFFERENTIAL P RIVACY AND THE                 Definition 3 (ReÌnyi divergence). For two probability distribu-
MOMENTS ACCOUNTANT. The closely related work by Dwork                 tions P and Q defined over R, the ReÌnyi divergence of order
and Rothblum [9], followed by Bun and Steinke [10], explore           Î± > 1 is
privacy definitionsâ€”Concentrated Differential Privacy and                                       1
                                                                                                              
                                                                                                                P (x)
                                                                                                                      Î±
zero-Concentrated Differential Privacyâ€”that are framed using                   DÎ± (P kQ) ,          log Exâˆ¼Q              .
                                                                                              Î±âˆ’1               Q(x)
the language of, respectively, subgaussian tails and the ReÌnyi
divergence. The main difference between our approaches is               (All logarithms are natural; P (x) is the density of P at x.)
that both Concentrated and zero-Concentrated DP require a               For the endpoints of the interval (1, âˆ) the ReÌnyi diver-
linear bound on all positive moments of a privacy loss variable.      gence is defined by continuity. Concretely, D1 (P kQ) is set to
In contrast, our definition applies to one moment at a time.          be limÎ±â†’1 DÎ± (P kQ) and can be verified to be equal to the
Although less restrictive, it allows for more accurate numerical      Kullback-Leibler divergence (also known as relative entropy):
analyses.                                                                                                        P (x)
   The work by Abadi et al. [11] on differentially private                             D1 (P kQ) = Exâˆ¼P log            .
                                                                                                                 Q(x)
stochastic gradient descent introduced the moments accountant
as an internal tool for tracking privacy loss across multiple         Note that the expectation is taken over P , rather than over
invocations of the Gaussian mechanism applied to random               Q as in the previous definition. It is possible, though, that
subsets of the input dataset. The paperâ€™s results are expressed       D1 (P kQ) thus defined is finite whereas DÎ± (P kQ) = +âˆ
via a necessarily lossy translation of the accountantâ€™s output        for all Î± > 1.
(bounds on select moments of the privacy loss variable) to the          Likewise,
language of (Ç«, Î´)-differential privacy.                                                                             P (x)
   Taken together, the works on Concentrated DP, zero-                               Dâˆ (P kQ) =       sup     log         .
                                                                                                    xâˆˆsupp Q         Q(x)
Concentrated DP, and the moments accountant point towards
adopting ReÌnyi differential privacy as an effective and flexible        For completeness, we reproduce in the Appendix proper-
mechanism for capturing privacy guarantees of a wide variety          ties of the ReÌnyi divergence important to the sequel: non-
of algorithms and their combinations.                                 negativity, monotonicity, probability preservation, and a weak
                                                                      triangle inequality (Propositions 8â€“11).
OTHER RELAXATIONS . We briefly mention other relaxations                 The relationship between the ReÌnyi divergence with Î± = âˆ
and generalizations of differential privacy.                          and differential privacy is immediate. A randomized mecha-
   Under the indistinguishability-based Computational Differ-         nism f is Ç«-differentially private if and only if its distribution
ential Privacy (IND-CDP) definition [3], the test of closeness        over any two adjacent inputs D and Dâ€² satisfies
between distributions on adjacent inputs is computationally
bounded (all other definitions considered in this paper hold                              Dâˆ (f (D)kf (Dâ€² )) â‰¤ Ç«.
against an unbounded, information-theoretic adversary). The
                                                                        It motivates exploring a relaxation of differential privacy
IND-CDP notion allows much more accurate functionalities
                                                                      based on the ReÌnyi divergence.
in the two-party setting [12]; in the traditional client-server
setup there is a natural class of functionalities where the gap       Definition 4 ((Î±, Ç«)-RDP). A randomized mechanism f : D 7â†’
between IND-CDP and (Ç«, Î´)-DP is minimal [13], and there              R is said to have Ç«-ReÌnyi differential privacy of order Î±, or
are (contrived) examples where the computational relaxation           (Î±, Ç«)-RDP for short, if for any adjacent D, Dâ€² âˆˆ D it holds
permits tasks that are infeasible under information-theoretic         that
definitions [14].                                                                         DÎ± (f (D)kf (Dâ€² )) â‰¤ Ç«.
   Several other works, most notably the Pufferfish and
the coupled-worlds frameworks [15], [16], propose different           Remark 1. Similarly to the definition of differential privacy, a
stability constraints on the output distribution of privacy-          finite value for Ç«-RDP implies that feasible outcomes of f (D)
preserving mechanisms. Although they differ in what distri-           for some D âˆˆ D are feasible, i.e., have a non-zero density,
butions are compared, their notion of closeness is the same as        for all inputs from D except for a set of measure 0. Assuming
in (Ç«, Î´)-DP.                                                         that this is the case, we let the event space be the support of
                                                                      the distribution.
             III. R EÌNYI DIFFERENTIAL PRIVACY                        Remark 2. The ReÌnyi divergence can be defined for Î± smaller
   We describe a generalization of the notion of differential         than 1, including negative orders. We are not using these orders
privacy based on the concept of the ReÌnyi divergence. Con-           in our definition of ReÌnyi differential privacy.
   The standard definition of differential privacy has been            By taking the logarithm of both sides and applying Jensenâ€™s
successful as a privacy measure because it simultaneously            inequality we obtain that
meets several important criteria. We verify that the relaxed
definition inherits many of the same properties. The results of         Ef (D) [log Rpost (D, Dâ€² ) âˆ’ log Rprior (D, Dâ€² )] â‰¤
this section are summarized in Table I.                                                                       DÎ± (f (D)kf (Dâ€² )). (1)
â€œBAD OUTCOMES â€ GUARANTEE . A privacy definition is only             (This can also be derived by observing that
as useful as its guarantee for data contributors. The simplest
such assurance is the â€œbad outcomesâ€ interpretation. Consider           Ef (D) [log Rpost (D, Dâ€² ) âˆ’ log Rprior (D, Dâ€² )] =
a person, concerned about some adverse consequences, de-                                                          D1 (f (D)kf (Dâ€² ))
liberating whether to withhold her record from the database.
Let us say that some outputs of the mechanism are labeled            and by monotonicity of the ReÌnyi divergence.)
                                                                       Compare (1) with the guarantee of pure differential privacy,
as â€œbad.â€ The differential privacy guarantee asserts that the
                                                                     which states that log Rpost (D, Dâ€² ) âˆ’ log Rprior (D, Dâ€² ) â‰¤ Ç«
probability of observing a bad outcome will not change (either
                                                                     everywhere, not just in expectation.
way) by more than a factor of eÇ« whether anyoneâ€™s record is
part of the input or not (for appropriately defined â€œadjacentâ€       P OST- PROCESSING . A privacy guarantee that can be dimin-
inputs). This is an immediate consequence of the definition of       ished by manipulating output is unlikely to be useful. Con-
differential privacy, where the subset S is the union of bad         sider a randomized mapping g : R 7â†’ Râ€² . We observe that
outcomes.                                                            DÎ± (P kQ) â‰¥ DÎ± (g(P )kg(Q)) by the analogue of the data
   This guarantee is relaxed for ReÌnyi differential privacy.        processing inequality [19, Theorem 9]. It means that if f (Â·)
Concretely, if f is (Î±, Ç«)-RDP, then by Proposition 10:              is (Î±, Ç«)-RDP, so is g(f (Â·)). In other words, ReÌnyi differential
                                                                     privacy is preserved by post-processing.
  eâˆ’Ç« Pr[f (Dâ€² ) âˆˆ S]Î±/(Î±âˆ’1) â‰¤ Pr[f (D) âˆˆ S]
                                                      (Î±âˆ’1)/Î±        P RESERVATION UNDER ADAPTIVE SEQUENTIAL COMPOSI -
                               â‰¤ (eÇ« Pr[f (Dâ€² ) âˆˆ S])           .
                                                                     TION . The property that makes possible modular construction
  We discuss consequences of this relaxation in Section VII.         of differentially private algorithms is self-composition: if f (Â·)
ROBUSTNESS TO AUXILIARY INFORMATION . Critical to the                is Ç«1 -differentially private and g(Â·) is Ç«2 -differentially private,
adoption of differential privacy as an operationally useful          then simultaneous release of f (D) and g(D) is Ç«1 + Ç«2 -
definition is its lack of assumptions on the adversaryâ€™s knowl-      differentially private. The guarantee even extends to when
edge. More formally, the property is captured by the Bayesian        g is chosen adaptively based on f â€™s output: if g is indexed
interpretation of privacy guarantees, which compares the ad-         by elements of R and gX (Â·) is Ç«2 -differentially private for
versaryâ€™s prior with the posterior.                                  any X âˆˆ R, then publishing (X, Y ), where X âˆ¼ f (D) and
   Assume that the adversary has a prior p(D) over the set           Y âˆ¼ gX (D), is Ç«1 + Ç«2 -differentially private.
of possible inputs D âˆˆ D, and observes an output X of an                We prove a similar statement for the composition of two
Ç«-differentially private mechanism f . Its posterior satisfies the   RDP mechanisms.
following guarantee for all pairs of adjacent inputs D, Dâ€² âˆˆ D       Proposition 1. Let f : D 7â†’ R1 be (Î±, Ç«1 )-RDP and g : R1 Ã—
and all X âˆˆ R:                                                       D 7â†’ R2 be (Î±, Ç«2 )-RDP, then the mechanism defined as
                       p(D |X)       p(D)                            (X, Y ), where X âˆ¼ f (D) and Y âˆ¼ g(X, D), satisfies
                                â‰¤ eÇ«        .
                           â€²
                       p(D |X)       p(Dâ€² )                          (Î±, Ç«1 + Ç«2 )-RDP.
In other words, evidence obtained from an Ç«-differentially           Proof. Let h : D 7â†’ R1 Ã— R2 be the result of running f and g
private mechanism does not move the relative probabilities           sequentially. We write X, Y , and Z for the distributions f (D),
assigned to adjacent inputs (the odds ratio) by more than eÇ« .       g(X, D), and the joint distribution (X, Y ) = h(D). X â€² , Y â€² ,
   The guarantee implied by RDP is a probabilistic statement         and Z â€² are similarly defined if the input is Dâ€² . Then
about the change in the Bayes factor. Let the random variable
R(D, Dâ€² ) be defined as follows:                                     exp [(Î± âˆ’ 1)DÎ± (h(D)kh(Dâ€² ))]
                                                                            Z
                p(Dâ€² |X)   p(X|Dâ€² ) Â· p(Dâ€² )                             =          Z(x, y)Î± Z â€² (x, y)1âˆ’Î± dx dy
  R(D, Dâ€² ) âˆ¼            =                   ,                              ZR1 Ã—R
                                                                                Z 2
                p(D |X)    p(X|D ) Â· p(D )
                                        where X âˆ¼ f (D).                 =          (X(x)Y (x, y))Î± (X â€² (x)Y â€² (x, y))1âˆ’Î± dy dx
                                                                             R1 R2
                                                                                                 Z                           
  It follows immediately from definition that the ReÌnyi diver-
                                                                            Z
                                                                                    Î± â€²     1âˆ’Î±               Î± â€²       1âˆ’Î±
gence of order Î± between P = f (Dâ€² ) and Q = f (D) bounds                = X(x) X (x)                 Y (x, y) Y (x, y)     dy dx
the Î±-th moment of the change in R:                                         ZR1                      R2

                          Î±                                            â‰¤      X(x)Î± X â€² (x)1âˆ’Î± dx Â· exp((Î± âˆ’ 1)Ç«2 )
           Rpost (D, Dâ€² )
       
                                                                              R1
                               = EQ P (x)Î± Q(x)âˆ’Î± =
                                                   
   EQ                 â€²
          Rprior (D, D )                                                  â‰¤ exp((Î± âˆ’ 1)Ç«1 ) exp((Î± âˆ’ 1)Ç«2 )
                              exp[(Î± âˆ’ 1)DÎ± (f (Dâ€² )kf (D))].             = exp((Î± âˆ’ 1)(Ç«1 + Ç«2 )),
from which the claim follows.                                         ReÌnyi divergence, (âˆ, Ç«)-RDP implies (Î±, Ç«)-RDP for all
                                                                      finite Î±.
   Significantly, the guarantee holds whether the releases of f
                                                                         In turn, an (Î±, Ç«)-RDP implies (Ç«Î´ , Î´)-differential privacy
and g are coordinated or not, or computed over the same or
                                                                      for any given probability Î´ > 0.
different versions of the input dataset. It allows us to operate
with a well-defined notion of a privacy budget associated with        Proposition 3 (From RDP to (Ç«, Î´)-DP). If f is an (Î±, Ç«)-RDP
an individual, which is a finite resource consumed with each          mechanism, it also satisfies (Ç« + log 1/Î´
                                                                                                         Î±âˆ’1 , Î´)-differential privacy
differentially private data release.                                  for any 0 < Î´ < 1.
   Extending the concept of the privacy budget, we say that the
ReÌnyi differential privacy has a budget curve parameterized by       Proof. Take any two adjacent inputs D and Dâ€² , and a subset
the order Î±. We present examples illustrating this viewpoint          of f â€™s range S. To show that f is (Ç«â€² , Î´)-differentially private,
                                                                                           1
in Section VI.                                                        where Ç«â€² = Ç« + Î±âˆ’1     log 1/Î´, we need to demonstrate that
                                                                                          Ç«â€²
                                                                      Pr[f (D) âˆˆ S] â‰¤ e Pr[f (Dâ€² ) âˆˆ S] + Î´. In fact, we prove a
G ROUP PRIVACY. Although the definition of differential pri-                                                              â€²
                                                                      stronger statement that Pr[f (D) âˆˆ S] â‰¤ max(eÇ« Pr[f (Dâ€² ) âˆˆ
vacy constrains a mechanismâ€™s outputs on pairs of adjacent            S], Î´).
inputs, its guarantee extends, in a progressively weaker form,           Recall that by Proposition 10
to inputs that are farther apart. This property has two im-
portant consequences. First, the differential privacy guarantee                 Pr[f (D) âˆˆ S] â‰¤ {eÇ« Pr[f (Dâ€² ) âˆˆ S}1âˆ’1/Î± .
degrades gracefully if our assumptions about one personâ€™s
influence on the input are (somewhat) wrong. For example,             Denote Pr[f (Dâ€² ) âˆˆ S] by Q and consider two cases.
a single family contributing to a survey will likely share              Case I. eÇ« Q > Î´ Î±/(Î±âˆ’1) . Continuing the above,
many socio-economic, demographic, and health characteris-
tics. Rather than collapsing, the differential privacy guarantee            Pr[f (D) âˆˆ S] â‰¤ {eÇ« Q}1âˆ’1/Î± = eÇ« Q Â· {eÇ« Q}âˆ’1/Î±
will scale down linearly with the number of family members.
                                                                                            â‰¤ eÇ« Q Â· Î´ âˆ’1/(Î±âˆ’1)
Second, the group privacy property allows preprocessing input                                                    
into a differentially private mechanism, possibly amplifying (in                                          log 1/Î´
                                                                                            = exp Ç« +               Â· Q.
a controlled fashion) one recordâ€™s impact on the output of the                                             Î±âˆ’1
computation.
   We define group privacy using a notion of c-stable transfor-         Case II. eÇ« Q â‰¤ Î´ Î±/(Î±âˆ’1) . This case is immediate since
mation [20]. We say that g : D 7â†’ Dâ€² is c-stable if g(A) and
g(B) are adjacent in Dâ€² implies that there exists a sequence of                     Pr[f (D) âˆˆ S] â‰¤ {eÇ« Q}1âˆ’1/Î± â‰¤ Î´,
length c + 1 so that D0 = A, . . . , Dc = B and all (Di , Di+1 )
                                                                      which completes the proof.
are adjacent in D.
   The standard notion of differential privacy satisfies the
following. If f is Ç«-differentially private and g : Dâ€² 7â†’ D is c-        A more detailed comparison between the notions of RDP
stable, then f â—¦g is cÇ«-differentially private. A similar statement   and (Ç«, Î´)-differential privacy that goes beyond these reduc-
holds for ReÌnyi differential privacy.                                tions is deferred to Section VII.

Proposition 2. If f : D 7â†’ R is (Î±, Ç«)-RDP, g : Dâ€² 7â†’ D is                      V. A DVANCED C OMPOSITION T HEOREM
2c -stable and Î± â‰¥ 2c+1 , then f â—¦ g is (Î±/2c , 3c Ç«)-RDP.
                                                                         The main thesis of this section is that the ReÌnyi differential
Proof. We prove the statement for c = 1, the rest follows by
                                                                      privacy curve of a composite mechanism is sufficient to draw
induction.
                                                                      non-trivial conclusions about its privacy guarantees, similar to
  Define h = f â—¦ g. Since g is 2-stable, it means that for any
                                                                      the ones given by other advanced composition theorems, such
adjacent D, Dâ€² âˆˆ Dâ€² there exist A âˆˆ D, so that g(D) and A,
                                                                      as Dwork et al. [6] or Kairouz et al. [7]. Although our proof
A and g(Dâ€² ) are adjacent in D.
                                                                      is structured similarly to Dwork et al. (for instance, Lemma 1
  By Corollary 4 and monotonicity of the ReÌnyi divergence,
                                                                      is a direct generalization of [6, Lemma III.2]), it is phrased
we have that h = f â—¦ g satisfies
                                                                      entirely in the language of ReÌnyi differential privacy without
                            Î±âˆ’1                                       making any (explicit) use of probability arguments.
  DÎ±/2 (h(D)kh(Dâ€² )) â‰¤          DÎ± (h(D)kh(A))+
                            Î±âˆ’2                                       Lemma 1. If P and Q are such that Dâˆ (P kQ) â‰¤ Ç« and
                                DÎ±âˆ’1 (h(A)kh(Dâ€² )) â‰¤ 3Ç«.              Dâˆ (QkP ) â‰¤ Ç«, then for Î± â‰¥ 1

                                                                                             DÎ± (P kQ) â‰¤ 2Î±Ç«2 .
                    IV. RDP AND (Ç«, Î´)-DP
                                                                      Proof. If Î± â‰¥ 1 + 1/Ç«, then
   As we observed earlier, the definition of Ç«-differential
privacy coincides with (âˆ, Ç«)-RDP. By monotonicity of the                       DÎ± (P kQ) â‰¤ Dâˆ (P kQ) = Ç« â‰¤ (Î± âˆ’ 1)Ç«2 .
  Property                                     Differential Privacy                               ReÌnyi Differential Privacy

                                               Pr[f (D) âˆˆ S] â‰¤   eÇ« Pr[f (D â€² ) âˆˆ S]              Pr[f (D) âˆˆ S] â‰¤ (eÇ« Pr[f (D â€² ) âˆˆ S])(Î±âˆ’1)/Î±
  Change in probability of outcome S
                                               Pr[f (D) âˆˆ S] â‰¥ eâˆ’Ç« Pr[f (D â€² ) âˆˆ S]               Pr[f (D) âˆˆ S] â‰¥ eâˆ’Ç« Pr[f (D â€² ) âˆˆ S]Î±/(Î±âˆ’1)
                                               Rpost (D, D â€² )                                          Rpost (D, D â€² ) Î±
                                                                                                                        
  Change in the Bayes factor                                    â‰¤ eÇ« always                       E                          â‰¤ exp[(Î± âˆ’ 1)Ç«]
                                               Rprior (D, D â€² )                                         Rprior (D, D â€² )
  Change in log of the Bayes factor            |âˆ† log R(D, D â€² )| â‰¤ Ç« always                      E[âˆ† log R(D, D â€² )] â‰¤ Ç«
  Post-processing                                                f is Ç«-DP (or (Î±, Ç«)-RDP) â‡’ g â—¦ f is Ç«-DP (or (Î±, Ç«)-RDP, resp.)
  Adaptive sequential composition (basic)                      f, g are Ç«-DP (or (Î±, Ç«)-RDP) â‡’ (f, g) is 2Ç«-DP (resp., (Î±, 2Ç«)-RDP)
  Group privacy, pre-processing                       f is Ç«-DP (or (Î±, Ç«)-RDP), g is 2c -stable â‡’ f â—¦ g is 2c Ç«-DP (resp., (Î±/2c , 3c Ç«)-RDP)

                                                                  TABLE I
                                       S UMMARY OF PROPERTIES SHARED BY DIFFERENTIAL PRIVACY AND RDP.




   Consider the case when Î± < 1 + 1/Ç«. We first observe that                      The constant in Lemma 1 can be improved to .5 via a
for any x > y > 0, Î» = log(x/y), and 0 â‰¤ Î² â‰¤ 1/Î» the                           substantially more involved analysis [10, Proposition 3.3] (see
following inequality holds:                                                    also )
                                                                               Proposition 4. Let f : D 7â†’ R be an adaptive composition of
  xÎ²+1 y âˆ’Î² + xâˆ’Î² y Î²+1 = x Â· eÎ²Î» + y Â· eâˆ’Î²Î»
                                                                               n mechanisms all satisfying Ç«-differential privacy. Let D and
          â‰¤ x(1 + Î²Î» + (Î²Î»)2 ) + y(1 âˆ’ Î²Î» + (Î²Î»)2 )                            Dâ€² be two adjacent inputs. Then for any S âŠ‚ R:
                       = (1 + (Î²Î»)2 )(x + y) + Î²Î»(x âˆ’ y). (2)                                           p                           
                                                                                 Pr[f (D) âˆˆ S] â‰¤ exp 2Ç« n log 1/ Pr[f (Dâ€² ) âˆˆ S]
Since all terms of the right hand side of (2) are positive, the
inequality applies if Î» is an upper bound on log x/y, which                                                                     Â· Pr[f (Dâ€² ) âˆˆ S].
we use in the argument below.
                                                                               Proof. By applying Lemma 1 to the ReÌnyi differential privacy
                                                                               curve of the underlying mechanisms and Proposition 1 to their
   exp[(Î± âˆ’ 1)DÎ± (P kQ)]                                                       composition, we find that for all Î± â‰¥ 1
         Z
       =     P (x)Î± Q(x)1âˆ’Î± dx                                                                  DÎ± (f (D)kf (Dâ€² )) â‰¤ 2Î±nÇ«2 .
         ZR

       â‰¤
             
              P (x)Î± Q(x)1âˆ’Î± + Q(x)Î± P (x)1âˆ’Î± dx âˆ’ 1                             Denote Pr[f (Dâ€² ) âˆˆ S] by Q and consider two cases.
             R                                                                 pCase I: log âˆš 1/Q â‰¥ Ç«2 n. Choosing with some foresight Î± =
                                (by nonnegativity of DÎ± (QkP ))                  log 1/Q/(Ç« n) â‰¥ 1, we have by Proposition 10 (probability
             Z
                                                                               preservation):
                  (1 + (Î± âˆ’ 1)2 Ç«2 )(P (x) + Q(x))+
                 
        â‰¤
             R                                                                                                                           1âˆ’1/Î±
                 (Î± âˆ’ 1)Ç«|P (x) âˆ’ Q(x)| dx âˆ’ 1                                    Pr[f (D) âˆˆ S] â‰¤ {exp[DÎ± (f (D)kf (Dâ€² )] Â· Q}
                                  (by (2) for Î² = Î± âˆ’ 1 â‰¤ 1/Ç«)                                    â‰¤ exp(2(Î± âˆ’ 1)nÇ«2 ) Â· Q1âˆ’1/Î±
                           2 2
                                                                                                        p                     
        = 1 + 2(Î± âˆ’ 1) Ç« + (Î± âˆ’ 1)Ç«kP âˆ’ Qk1 .                                                     < exp Ç« n log 1/Q âˆ’ (log Q)/Î± Â· Q
                                                                                                        p              
                                                                                                  = exp 2Ç« n log 1/Q Â· Q.
Taking the logarithm of both sides and using that log(1+x) <
x for positive x we find that                                                     Case II: log 1/Q < Ç«2 n. This case follows trivially, since
                                                                               the right hand side of the claim is larger than 1:
             DÎ± (P kQ) â‰¤ 2(Î± âˆ’ 1)Ç«2 + Ç«kP âˆ’ Qk1 .                     (3)            p             
                                                                                exp 2Ç« n log 1/Q Â· Q â‰¥ exp (2 log 1/Q) Â· Q = 1/Q > 1.
  Observe that
             Z
  kP âˆ’ Qk1 = |P (x) âˆ’ Q(x)| dx
                                                                                 The notable feature of Proposition 4 is that its privacy
                          max(P (x), Q(x))
      Z
    =    min(P (x), Q(x))                  âˆ’ 1 dx                              guaranteeâ€”bounded probability gainâ€”comes in the form that
       R                  min(P (x), Q(x))                                     depends on the eventâ€™s probability. We discuss this type of
                             â‰¤ min(2, eÇ« âˆ’ 1) â‰¤ 2Ç«2 .                          guarantee in Section VII.
                                                                                 The following corollary gives a more conventional (Ç«, Î´)
Plugging the bound on kP âˆ’Qk1 into (3) completes the proof.                    variant of advanced composition.
  The claim for Î± = 1 follows by continuity.
Corollary 1. Let f be the composition of the n Ç«-differentially      A. Randomized response
private mechanisms. Let 0 < Î´ < 1 be such that log(1/Î´) â‰¥
Ç«2 n. Then f satisfies (Ç«â€² , Î´)-differential privacy where             Let f be a predicate, i.e., f : D 7â†’ {0, 1}. The Randomize
                              p                                      Response mechanism for f is defined as
                     Ç«â€² , 4Ç« 2n log(1/Î´).
                                                                                        (
Proof. Let D and Dâ€² be two adjacent inputs, and S be some                                   f (D)         with probability p
                                                                         RRp f (D) ,                                             .
subset of the range of f . To argue (Ç«â€² , Î´)-differential privacy                           1 âˆ’ f (D)     with probability 1 âˆ’ p
of f , we need to verify that
                                â€²                                      The following statement can be verified by direct application
           Pr[f (D) âˆˆ S] â‰¤ eÇ« Pr[f (Dâ€² ) âˆˆ S] + Î´.
                                                                     of the definition of ReÌnyi differential privacy:
In fact, we prove a somewhat stronger statement, namely that
                        â€²                                            Proposition 5. Randomized Response mechanism RRp (f )
Pr[f (D) âˆˆ S] â‰¤ max(eÇ« Pr[f (Dâ€² ) âˆˆ S], Î´).
                                                                     satisfies
   By Proposition 4
                                                                                                                  
                       p                                                     1       Î±       1âˆ’Î±          Î± 1âˆ’Î±
                                                                                                                  
   Pr[f (D) âˆˆ S] â‰¤ exp 2Ç« n log 1/ Pr[f (Dâ€² ) âˆˆ S]                       Î±,       log p (1 âˆ’ p)    + (1 âˆ’ p) p       -RDP
                                                                              Î±âˆ’1
                                             Â· Pr[f (Dâ€² ) âˆˆ S].
                                                                     if Î± > 1, and
  Denote Pr[f (Dâ€² ) âˆˆ S] by Q and consider two cases.
  Case I: 8 log 1/Î´ > log 1/Q. Then                                                                           
                                                                                                          p
                                                                                      Î±, (2p âˆ’ 1) log              -RDP
                                                                                                         1âˆ’p
                              p              
         Pr[f (D) âˆˆ S] â‰¤ exp 2Ç« n log 1/Q Â· Q
                              p              
                        < exp 2Ç« 8n log 1/Î´ Â· Q                      if Î± = 1.
                                   (by 8 log 1/Î´ > log 1/Q)
                         = exp (Ç«â€² ) Â· Q.
                                                                     B. Laplace noise
  Case II: 8 log 1/Î´ â‰¤ log 1/Q. Then
                             p                                        Through the rest of this section we assume that f : D 7â†’ R
     Pr[f (D) âˆˆ S] â‰¤ exp 2Ç« n log 1/Q Â· Q                            is a function of sensitivity 1, i.e., for any two adjacent D, Dâ€² âˆˆ
                             p                                     D: |f (D) âˆ’ f (Dâ€² )| â‰¤ 1.
                     â‰¤ exp 2 log 1/Î´ Â· log 1/Q Â· Q                      Define the Laplace mechanism for f of sensitivity 1 as
                                      (since log(1/Î´) â‰¥ Ç«2 n)
                            p              
                     â‰¤ exp     1/2 log 1/Q Â· Q                                        LÎ» f (D) = f (D) + Î›(0, Î»),
                                 (since 8 log 1/Î´ â‰¤ log 1/Q)
                                âˆš
                                                                     where Î›(Âµ, Î») is Laplace distribution with mean Âµ and scale
                      = Q1âˆ’1/ 2 â‰¤ Q1/8                                                                             1
                                                                     Î», i.e., its probability density function is 2Î» exp(âˆ’|x âˆ’ Âµ|/Î»).
                      â‰¤ Î´.                                 (ditto)
                                                                        To derive the RDP budget curve for the exponential mech-
                                                                     anism we compute the ReÌnyi divergence for Laplace distribu-
                                                                     tion and its offset.
Remark 3. The condition log(1/Î´) â‰¥ Ç«2 n corresponds to the           Proposition 6. For any Î± â‰¥ 1 and Î» > 0:
so-called â€œhigh privacyâ€ regime
                            âˆš of the advanced composition
theorem [7], where Ç«â€² < (1+ 2) log(1/Î´). Since Î´ is typically                                                                   
chosen to be small, say, less than 1%, it covers the case of                                   1                Î±           Î±âˆ’1
                                                                       DÎ± (Î›(0, Î»)kÎ›(1, Î»)) =     log                exp
Ç«â€² < 11. In other words, if log(1/Î´) > Ç«2 n, this and other                                   Î±âˆ’1             2Î± âˆ’ 1          Î»
composition theorems are unlikely to yield strong bounds.
                                                                                                                            
                                                                                                            Î±âˆ’1          âˆ’Î±
                                                                                                          +        exp          .
                                                                                                            2Î± âˆ’ 1        Î»
                  VI. BASIC M ECHANISMS
   In this section we analyze ReÌnyi differential privacy of three   Proof. For continuous distributions P and Q defined over the
basic mechanisms and their self-composition: randomized              real interval with densities p and q
response, Laplace and Gaussian noise addition. The results
                                                                                                        Z âˆ
are summarized in Table II and plotted for select parameters                               1
in Figures 1 and 2.                                                           DÎ± (P kQ) =     log             p(x)Î± q(x)1âˆ’Î± dx.
                                                                                          Î±âˆ’1           âˆ’âˆ
   Mechanism                        Differential Privacy             ReÌnyi Differential Privacy for Î±
                                                                               1
                                                                                  log pÎ± (1 âˆ’ p)1âˆ’Î± + (1 âˆ’ p)Î± p1âˆ’Î±
                                                                                                                    
                                          p                          Î± > 1: Î±âˆ’1
   Randomized Response               log 1âˆ’p                                                p
                                                                     Î± = 1: (2p âˆ’ 1) log 1âˆ’p
                                                                                      n                                  o
                                                                     Î± > 1: Î±âˆ’11
                                                                                  log 2Î±âˆ’1Î±
                                                                                              exp( Î±âˆ’1     Î±âˆ’1
                                                                                                       ) + 2Î±âˆ’1 exp(âˆ’ Î± )
   Laplace Mechanism                1/Î»                                                              Î»                Î»
                                                                     Î± = 1: 1/Î» + exp(âˆ’1/Î») âˆ’ 1 = .5/Î»2 + O(1/Î»3 )
   Gaussian Mechanism               âˆ                                Î±/(2Ïƒ2 )

                                                              TABLE II
                                          S UMMARY OF RDP PARAMETERS FOR BASIC MECHANISMS .



                                           1
   To compute the integral for p(x) = 2Î»     exp(âˆ’|x|/Î») and       where N (0, Ïƒ 2 ) is normally distributed random variable with
          1
q(x) = 2Î» exp(âˆ’|x âˆ’ 1|/Î»), we evaluate it separately over          standard deviation Ïƒ 2 and mean 0.
the intervals (âˆ’âˆ, 0], [0, 1] and [1, +âˆ].                            The following statement is a closed-form expression of the
   Z +âˆ                                                            ReÌnyi divergence between a Gaussian and its offset (for a more
         p(x)Î± q(x)1âˆ’Î± dx =                                        general version see [19], [21]).
    âˆ’âˆ
              1
                 Z 0                                               Proposition 7. DÎ± (N (0, Ïƒ 2 )kN (Âµ, Ïƒ 2 )) = Î±Âµ2 /(2Ïƒ 2 ).
                      exp(Î±x/Î» + (1 âˆ’ Î±)(x âˆ’ 1)/Î») dx
             2Î» âˆ’âˆ                                                 Proof. By direct computation we verify that
                 Z 1
              1
          +          exp(âˆ’Î±x/Î» + (1 âˆ’ Î±)(x âˆ’ 1)/Î») dx                   DÎ± (N (0, Ïƒ 2 )kN (Âµ, Ïƒ 2 ))
             2Î» 0                                                                          Z âˆ
                 Z +âˆ                                                            1                   1
              1                                                             =          log         âˆš exp(âˆ’Î±x2 /(2Ïƒ 2 ))
          +            exp(âˆ’Î±x/Î» âˆ’ (1 âˆ’ Î±)(x âˆ’ 1)/Î») dx                       Î±âˆ’1           âˆ’âˆ   Ïƒ    2Ï€
             2Î» 1
             1                                                                         Â· exp(âˆ’(1 âˆ’ Î±)(x âˆ’ Âµ)2 /(2Ïƒ 2 )) dx
       =        exp((Î± âˆ’ 1)/Î»)                                                   1           1
                                                                                                   Z âˆ
             2                                                              =          log âˆš             exp[(âˆ’x2 +
                  1                                                           Î±âˆ’1          Ïƒ 2Ï€ âˆ’âˆ
          +             (exp((Î± âˆ’ 1)/Î») âˆ’ exp(âˆ’Î±/Î»))
             2(2Î± âˆ’ 1)                                                                 2(1 âˆ’ Î±)Âµx âˆ’ (1 âˆ’ Î±)Âµ2 )/(2Ïƒ 2 )] dx
             1                                                                             ( âˆš                                )
          + exp(âˆ’Î±/Î»)                                                            1           Ïƒ 2Ï€          2       2     2
                                                                                                                            
             2                                                              =          log    âˆš exp (Î± âˆ’ Î±)Âµ /(2Ïƒ )
            Î±                          Î±âˆ’1                                    Î±âˆ’1            Ïƒ 2Ï€
       =          exp((Î± âˆ’ 1)/Î») +           exp(âˆ’Î±/Î»),
          2Î± âˆ’ 1                      2Î± âˆ’ 1                                = Î±Âµ2 /(2Ïƒ 2 ).
from which the claim follows.
   Since the Laplace mechanism is additive, the ReÌnyi diver-
gence between LÎ» f (D) and LÎ» f (Dâ€² ) depends only on Î±               The following corollary is immediate:
and the distance |f (D) âˆ’ f (Dâ€² )|. Proposition 6 implies the
                                                                   Corollary 3. If f has sensitivity 1, then the Gaussian mech-
following:
                                                                   anism GÏƒ f satisfies (Î±, Î±/(2Ïƒ 2 ))-RDP.
Corollary 2. If real-valued function f has sensitiv-
                                                                      Observe that the RDP budget curve for the Gaussian mech-
ity 1, then  the Laplace mechanism LÎ»of satisfies (Î±,
  1
       n
           Î±      Î±âˆ’1    Î±âˆ’1        Î±                              anism is particularly simpleâ€”a straight line (Figure 1). Recall
Î±âˆ’1 log 2Î±âˆ’1 exp( Î» ) + 2Î±âˆ’1 exp(âˆ’ Î» ) )-RDP.                      that the (adaptive) composition of RDP mechanisms satisfies
  Predictably,                                                     ReÌnyi differential privacy with the budget curve that is the sum
                                                                   of the mechanismsâ€™ budget curves. It means that a composition
                                                          1        of Gaussian mechanisms will behave, privacy-wise, â€œlikeâ€ a
   lim DÎ± (Î›(0, Î»)kÎ›(1, Î»)) = Dâˆ (Î›(0, Î»)kÎ›(1, Î»)) =        .
  Î±â†’âˆ                                                     Î»        Gaussian mechanism. Concretely, a composition of n Gaussian
This is, of course, consistent with the Laplace mechanism sat-     mechanisms each with parameter Ïƒ will haveâˆšthe RDP curve
isfying 1/Î»-differential privacy. The other extreme evaluates      of a Gaussian mechanism with parameter Ïƒ/ n.
to the following expression limÎ±â†’1 DÎ± (Î›(0, Î»)kÎ›(1, Î»)) =
1/Î» + exp(âˆ’1/Î») âˆ’ 1, which is well approximated by .5/Î»2           D. Privacy of basic mechanisms under composition
for large Î».                                                          The â€œbad outcomesâ€ interpretation of ReÌnyi differential
C. Gaussian noise                                                  privacy ties the probabilities of seeing the same outcome
                                                                   under runs of the mechanism applied to adjacent inputs. The
  Assuming, as before, that f is a real-valued function, the
                                                                   dependency of the upper bound on the increase in probability
Gaussian mechanism for approximating f is defined as
                                                                   on its initial value is complex, especially compared to the
                 GÏƒ f (D) = f (D) + N (0, Ïƒ 2 ),                   standard differential privacy guarantee. The main advantage
                                     Randomized Response                                     Laplace Mechanism                                    Gaussian Mechanism
                      2.5
                                                               p = 0.55                                           1/Î» = 0.25                                                 Ïƒ=4
                      2.0                                      p = 0.6                                            1/Î» = 0.5                                                  Ïƒ=3
                                                               p = 0.75                                           1/Î» = 1.0                                                  Ïƒ=2
                      1.5
      Ç«




                                                                                Ç«




                                                                                                                                     Ç«
                      1.0


                      0.5


                      0.0
                            1          4                   7              10        1         4                   7            10        1          4                   7          10
                                                 Î±                                                      Î±                                                     Î±


                                        Fig. 1. (Î±, Ç«)-ReÌnyi differential privacy budget curve for three basic mechanisms with varying parameters.




                                        Pr[S] = 10âˆ’6                                           Pr[S] = 10âˆ’3                                         Pr[S] = 10âˆ’1

                                                                                                                                                                  NaÄ±Ìˆve bound
                                                                                                                                                                  Generic ReÌnyi
                      101
Randomized Response




                                                                                                                                                                  Generic (Ç«, Î´)
                                                                                                                                                                  RDP analysis




                      100
                            1   50         100       150       200        250       1   50        100       150       200      250       1   50         100       150       200    250



                                        Pr[S] = 10âˆ’6                                           Pr[S] = 10âˆ’3                                         Pr[S] = 10âˆ’1

                                                                                                                                                                  NaÄ±Ìˆve bound
                                                                                                                                                                  Generic ReÌnyi
                        1
Laplace Mechanism




                      10
                                                                                                                                                                  Generic (Ç«, Î´)
                                                                                                                                                                  RDP analysis




                      100
                            1   50         100       150       200        250       1   50        100       150       200      250       1   50         100       150       200    250



Fig. 2. Various privacy guarantees of the randomized response with parameter p = 51% (top row) and the Laplace mechanism with parameter Î» = 20
(bottom row) under self-composition. The x-axis is the number of compositions (1â€“250). The y-axis, in log scale, is the upper bound on the multiplicative
increase in probability of event S, where Sâ€™s initial mass is either 10âˆ’6 (left), 10âˆ’3 (center), or .1 (right). The four plot lines are the â€œnaÄ±Ìˆveâ€ nÇ« bound
(blue); optimal choice (Ç«, Î´) in the standard advanced composition theorem (red); generic bound of Proposition 4 (blue); optimal choice of Î± in Proposition 10
(cyan).
of this more involved analysis is that for most parameters the     BASELINE - DEPENDENT GUARANTEES . The ReÌnyi differen-
bound becomes tighter.                                             tial privacy bound gets weaker for less likely outcomes. For
   In this section we compare numerical bounds for several         instance, if f is a (10.0, .1)-RDP mechanism, an event of
analyses of self-composed mechanisms (see Figure 2), pre-          probability .5 under f (D) can be as large as .586 and as
sented as three sets of graphs, where Pr[f (D) âˆˆ S] takes          small as .419 under f (Dâ€² ). For smaller events the range is (in
values 10âˆ’6 , 10âˆ’3 , and 10âˆ’1 .                                    relative terms) wider. If the probability under f (D) is .001,
   Each of the six graphs in Figure 2 (three probability           then Pr[f (Dâ€² ) âˆˆ S] âˆˆ [.00042, 0.00218]. For Pr[f (D) âˆˆ
values Ã— {randomized response, Laplace}) plots bounds in           S] = 10âˆ’6 the range is wider still: Pr[f (Dâ€² ) âˆˆ S] âˆˆ
logarithmic scale on the relative increase in probability of S     [.195 Â· 10âˆ’6 , 4.36 Â· 10âˆ’6 ].
(i.e., Pr[f (Dâ€² ) âˆˆ S]/ Pr[f (D) âˆˆ S]) offered by four analyses.      Contrasted with the pure Ç«-differential privacy this type
The first, â€œnaÄ±Ìˆveâ€, bound follows from the basic composition      of guarantee is conceptually weaker and more onerous in
theorem for differential privacy and, as expected, is very         application: in order to decide whether the increased risk is
pessimistic for all but a handful of parameters. A tighter,        tolerable, one is required to estimate the baseline risk first.
advanced composition theorem [6], gives a choice of Î´, from           However, in comparison with (Ç«, Î´)-DP the analysis via
which one computes Ç«â€² so that the n-fold composition satisfies     ReÌnyi differential privacy is simpler and, especially for prob-
(Ç«â€² , Î´)-differential privacy. The second curve plots the bound    abilities that are smaller than Î´, leads to stronger bounds.
for the optimal (tightest) choice of (Ç«â€² , Î´). Two other bounds    The reason is that (Ç«, Î´)-differential privacy often arises as
come from ReÌnyi differential privacy analysis: our generic        a result of some analysis that implicitly comes with an Ç«-Î´
advanced composition theorem (Proposition 4) and the bound         tradeoff. Finding an optimal value of (Ç«, Î´) given the baseline
of Proposition 10 for the optimal combination of (Î±, Ç«) from       risk may be non-trivial, especially in closed form. Contrast the
the RDP curve of the composite mechanism.                          following two, basically equivalent, statements of advanced
   Several observations are in order. The RDP-specific analysis    composition theorems (Proposition 4 and its Corollary 1):
for both mechanisms is tighter than all generic bounds whose             Let f : D 7â†’ R be an adaptive composition of n
only input is the mechanismâ€™s differential privacy parameter.            mechanisms all satisfying Ç«-differential privacy for
On the other hand, our version of the advanced composition               Ç« â‰¤ 1. Let D and Dâ€² be two adjacent inputs. Then
bound (Proposition 4) is consistently outperformed by the                for any S âŠ‚ R, by Proposition 4:
standard (Ç«, Î´)-form of the composition theorem, where Î´ is                                         p                           
chosen optimally. We elaborate on this distinction in the next              Pr[f (Dâ€² ) âˆˆ S] â‰¤ exp 2Ç« n log 1/ Pr[f (D) âˆˆ S]
section.
                                                                                                          Â· Pr[f (D) âˆˆ S].
                      VII. D ISCUSSION                                  or, by Corollary 1,
   ReÌnyi differential privacy is a natural relaxation of the                                    p            
standard notion of differential privacy that preserves many                Pr[f (Dâ€² ) âˆˆ S] â‰¤ exp 4Ç« 2n log 1/Î´
of its essential properties. It can most directly be compared                                         Â· Pr[f (D) âˆˆ S] + Î´,
with (Ç«, Î´)-differential privacy, with which it shares several
important characteristics.                                              where 0 < Ç«, Î´ < 1 such that log(1/Î´) â‰¥ Ç«2 n.
                                                                      Given some value of baseline risk Pr[f (D) âˆˆ S], which
P ROBABILISTIC PRIVACY GUARANTEE . The standard â€œbad
                                                                   formulation is easier to interpret? We argue that it is the
outcomesâ€ guarantee of Ç«-differential privacy is independent
                                                                   former, since the (Ç«, Î´) form has a free parameter (Î´) that
of the probability of a bad outcome: it may increase only by
                                                                   ought to be optimized in order to extract a tight bound that
a factor of exp(Ç«). Its relaxation, (Ç«, Î´)-differential privacy,
                                                                   Proposition 4 gives directly.
allows for an additional Î´ term, which allows for a complete
                                                                      The use of (Ç«, Î´) bounds gets even more complex if we con-
privacy compromise with probability Î´.
                                                                   sider a composition of heterogeneous mechanisms. It brings
   In stark contrast, ReÌnyi differential privacy even with very
                                                                   us to the last point of comparison between (Ç«, Î´)- and ReÌnyi
weak parameters never allows a total breach of privacy with
                                                                   differential privacy measures.
no residual uncertainty. The following analysis quantifies this
assurance.                                                         K EEPING TRACK OF ACCUMULATED PRIVACY LOSS . A finite
   Let f be (Î±, Ç«)-RDP with Î± > 1. Recall that for                 privacy budget associated with an individual is an intuitive and
any two adjacent inputs D and Dâ€² , and an arbitrary prior          appealing concept, to which Ç«-differential privacy gives a rig-
p the odds function R(D, Dâ€² ) âˆ¼ p(D)/p(Dâ€² ) satisfies            orous mathematical expression. Cumulative loss of differential
                    oÎ±âˆ’1
                                                                   privacy over the cause of a mechanism run, a protocol, or oneâ€™s
    n
      Rpost (D,Dâ€² )
E Rprior    (D,D )
                â€²         â‰¤ exp((Î± âˆ’ 1)Ç«). By Markovâ€™s in-
                                                                   lifetime can be tracked easily thanks to the additivity property
equality Pr[Rpost (D, Dâ€² ) > Î²Rprior (D, Dâ€² )] < eÇ« /Î² 1/(Î±âˆ’1) .   of differential privacy. Unfortunately, doing so naÄ±Ìˆvely likely
For instance, if Î± = 2, the probability that the ratio between     exaggerates privacy loss, which grows sublinearly in the num-
two posteriors increases by more than the Î² factor drops off       ber of queries with all but negligible probability (via advanced
as O(1/Î²).                                                         composition theorems).
                    100                                                                                                                                          64
                                               S = 10âˆ’6                                                                               optimal Î±, S = .1
                                                                                                                                      restricted Î±, S = .1
                                                                                                                                                                 32
                                                                                                                                      optimal Î±, S = 10âˆ’3
                                                                                                                                      restricted Î±, S = 10âˆ’3
                                                                                                                                      optimal Î±, S = 10âˆ’6        16
probability ratio




                                                                                                                                      restricted Î±, S = 10âˆ’6
                                                             S = 10âˆ’3
                                                                                                                                                                 8




                                                                                      Î±
                     50
                                                                                                                                                                 6
                                                                                                                                                                 5
                                                                                                                                                                 4
                                                                                                                                                                 3
                                                                                                                                                                 2.5
                                                                                                                                                                 2
                                                                                                                                                                 1.75
                                                             S = .1                                                                                              1.5

                      1
                          20          40                60       80           100                     20            40                60          80           100
                                           iterations                                                                    iterations



    Fig. 3. Left: Bounds on the ratio Pr[f (D â€² ) âˆˆ S]/ Pr[f (D) âˆˆ S] for Pr[f (D) âˆˆ S] âˆˆ {.1, 10âˆ’3 , 10âˆ’6 } for up to 100 iterations of a mixed mechanism
    (randomized response with p = .52, Laplace with Î» = 20 and Gaussian with Ïƒ = 10). Each bound is computed twice: once for an optimal choice of Î± and
    once for Î± restricted to {1.5, 1.75, 2, 2.5, 3, 4, 5, 6, 8, 16, 32, 64, +âˆ}. The curves for two choices of Î± are nearly identical. Right: corresponding values of
    Î± in log scale.



       Critically, applying advanced composition theorems breaks                      three basic mechanisms: randomized response, Gaussian, and
    the convenient abstraction of privacy as a non-negative real                      Laplace. Its RDP curve is given, in the closed form, by
    number. Instead, the guarantee comes in the (Ç«, Î´) form that                      application of the basic composition rule to RDP curves of
    effectively corresponds to a single point on an implicitly                        the underlying mechanisms (Table II). The privacy guarantee
    defined curve. Composition of multiple, heterogeneous mech-                       is presented in Figure 3 for three values of the baseline risk:
    anisms makes applying the composition rule optimally much                         .1, .001, and 10âˆ’6 . For each set of parameters two curves
    more challenging, as one may choose various (Ç«, Î´) points to                      are plotted: one for an optimal value of Î± from (1, +âˆ],
    represent their privacy (in the analysis, not during the mech-                    the other for an optimal Î± restricted to the set of 13 values
    anismsâ€™ run time!). It begs the question of how to represent                      {1.5, 1.75, 2, 2.5, 3, 4, 5, 6, 8, 16, 32, 64, +âˆ}. The two curves
    the privacy guarantee of a complex mechanism: distilling it                       are nearly identical, which illustrates our thesis that reporting
    to a single number throws away valuable information, while                        RDP curves for a restricted set of Î±â€™s preserves tightness of
    publishing the entire (Ç«, Î´) curve shifts the problem to the                      privacy analysis.
    aggregation step. (See Kairouz et al. [7] for an optimal bound
    on composition of homogeneous mechanisms and Murtagh                                       VIII. C ONCLUSIONS AND O PEN Q UESTIONS
    and Vadhan [8] for hardness results and an approximation                             We put forth the proposition that ReÌnyi divergence yields
    scheme for composition of mechanisms with heterogeneous                           useful insight into analysis of differentially private mecha-
    privacy guarantees.)                                                              nisms. Among our findings
       ReÌnyi differential privacy restores the concept of a pri-                        â€¢ ReÌnyi differential privacy (RDP) is a natural generaliza-
    vacy budget, thanks to its composition rule: RDP curves for                            tion of pure differential privacy.
    composed mechanisms simply add up. Importantly, the Î±â€™s                              â€¢ RDP shares, with some adaptations, many properties that
    of (Î±, Ç«)-ReÌnyi differential privacy do not change. If RDP                            make differential privacy a useful and versatile tool.
    statements are reported for a common set of Î±â€™s (which                               â€¢ RDP analysis of Gaussian noise is particularly simple.
    includes +âˆ, to keep track of pure differential privacy), RDP                        â€¢ A composition theorem can be proved based solely on
    of the aggregate is the sum of the reported vectors. Since the                         the properties of RDP, which implies that RDP packs
    composition theorem of Proposition 4 takes as an input the                             sufficient information about a composite mechanism as
    mechanismâ€™s RDP curve, it means that the sublinear loss of                             to enable its analysis without consideration of its compo-
    privacy as a function of the number of queries will still hold.                        nents.
       For an example of this approach we tabulate the bound                             â€¢ Furthermore, an RDP curve may be sampled in just a few
    on privacy loss for an iterative mechanism consisting of                               points to provide useful guarantees for a wide range of
       parameters. If these points are chosen consistently across                [14] M. Bun, Y. Chen, and S. P. Vadhan, â€œSeparating computational and
       multiple mechanisms, this information can be used to                           statistical differential privacy in the client-server model,â€ in Theory
                                                                                      of Cryptographyâ€”14th International Conference, TCC 2016-B, Part I,
       estimate aggregate privacy loss.                                               M. Hirt and A. D. Smith, Eds., 2016, pp. 607â€“634.
   Naturally, multiple questions remain open. Among those                        [15] D. Kifer and A. Machanavajjhala, â€œPufferfish: A framework for math-
                                                                                      ematical privacy definitions,â€ ACM Transactions on Database Systems
   â€¢ As Lemma 1 demonstrates, the RDP curve of a differen-                            (TODS), vol. 39, no. 1, pp. 3:1â€“3:36, Jan. 2014.
     tially private mechanism is severely constrained. Making                    [16] R. Bassily, A. Groce, J. Katz, and A. D. Smith, â€œCoupled-worlds privacy:
                                                                                      Exploiting adversarial uncertainty in statistical data privacy,â€ in 54th
     fuller use of these constraints is a promising direction,                        Annual IEEE Symposium on Foundations of Computer Science, 2013,
     in particular towards formal bounds on tightness of RDP                          pp. 439â€“448.
     guarantees from select Î± values.                                            [17] J. C. Duchi, M. I. Jordan, and M. J. Wainwright, â€œLocal privacy
                                                                                      and statistical minimax rates,â€ in 54th Annual IEEE Symposium on
   â€¢ Proposition 10 (probability preservation) is not tight when
                                                                                      Foundations of Computer Science (FOCS). IEEE, Oct. 2013, pp. 429â€“
     DÎ± (P kQ) â†’ 0. We expect that P (A) â†’ Q(A) but the                               438.
     bound does not improve beyond P (A)(Î±âˆ’1)/Î± .                                [18] A. ReÌnyi, â€œOn measures of entropy and information,â€ in Proceedings of
                                                                                      the fourth Berkeley symposium on mathematical statistics and probabil-
                                                                                      ity, vol. 1, 1961, pp. 547â€“561.
                        ACKNOWLEDGMENTS                                          [19] T. van Erven and P. HarremoeÌˆs, â€œReÌnyi divergence and Kullback-Leibler
                                                                                      divergence,â€ IEEE Transactions on Information Theory, vol. 60, no. 7,
  We would like to thank Cynthia Dwork, Kunal Talwar, Salil                           pp. 3797â€“3820, Jul. 2014, arxiv.org/abs/1206.2459.
Vadhan, and Li Zhang for numerous fruitful discussions, the                      [20] F. D. McSherry, â€œPrivacy integrated queries: an extensible platform
CSF reviewers, Nicolas Papernot and Damien Desfontaines for                           for privacy-preserving data analysis,â€ in Proceedings of the 2009 ACM
                                                                                      SIGMOD International Conference on Management of Data, C. Binnig
their helpful comments, and Mark Bun and Thomas Steinke                               and B. Dageville, Eds., 2009, pp. 19â€“30.
for sharing a draft of [10].                                                     [21] F. Liese and I. Vajda, Convex Statistical Distances. Teubner, 1987.
                                                                                 [22] O. Shayevitz, â€œOn ReÌnyi measures and hypothesis testing,â€ in 2011 IEEE
                                                                                      International Symposium on Information Theory Proceedings. IEEE,
                             R EFERENCES                                              Jul. 2011, pp. 894â€“898.
                                                                                 [23] A. Langlois, D. StehleÌ, and R. Steinfeld, â€œGGHLite: More efficient
 [1] C. Dwork, F. McSherry, K. Nissim, and A. D. Smith, â€œCalibrating noise
                                                                                      multilinear maps from ideal lattices,â€ in Advances in Cryptologyâ€”
     to sensitivity in private data analysis,â€ in Third Theory of Cryptography
                                                                                      EUROCRYPT 2014, P. Q. Nguyen and E. Oswald, Eds. Springer Berlin
     Conference, TCC 2006, S. Halevi and T. Rabin, Eds. Springer, 2006,
                                                                                      Heidelberg, 2014, pp. 239â€“256.
     pp. 265â€“284.
                                                                                 [24] V. Lyubashevsky, C. Peikert, and O. Regev, â€œOn ideal lattices and
 [2] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor, â€œOur
                                                                                      learning with errors over rings,â€ J. ACM, vol. 60, no. 6, pp. 43:1â€“43:35,
     data, ourselves: Privacy via distributed noise generation,â€ in Advances
                                                                                      Nov. 2013.
     in Cryptographyâ€”Eurocrypt â€™06. Springer, 2006, pp. 486â€“503.
                                                                                 [25] Y. Mansour, M. Mohri, and A. Rostamizadeh, â€œMultiple source adapta-
 [3] I. Mironov, O. Pandey, O. Reingold, and S. P. Vadhan, â€œComputa-
                                                                                      tion and the ReÌnyi divergence,â€ in UAI â€™09 Proceedings of the Twenty-
     tional differential privacy,â€ in Advances in Cryptologyâ€”CRYPTO 2009,
                                                                                      Fifth Conference on Uncertainty in Artificial Intelligence. AUAI Press,
     S. Halevi, Ed., 2009, pp. 126â€“142.
                                                                                      Jun. 2009, pp. 367â€“374.
 [4] A. De, â€œLower bounds in differential privacy,â€ in Theory of
     Cryptographyâ€”9th Theory of Cryptography Conference, TCC 2012,
     R. Cramer, Ed., 2012, pp. 321â€“338.                                                                          A PPENDIX
 [5] F. D. McSherry, â€œHow many secrets do you have?â€
     https://github.com/frankmcsherry/blog/blob/master/posts/2017-02-08.md,        For comprehensive exposition of properties of the ReÌnyi
     Feb. 2017.
 [6] C. Dwork, G. N. Rothblum, and S. Vadhan, â€œBoosting and differential         divergence we refer to two recent papers [19], [22]. Here we
     privacy,â€ in 51st Annual IEEE Symposium on Foundations of Computer          recall and re-prove several facts useful for our analysis.
     Science (FOCS), L. Trevisan, Ed. IEEE, Oct. 2010, pp. 51â€“60.
 [7] P. Kairouz, S. Oh, and P. Viswanath, â€œThe composition theorem for dif-      Proposition 8 (Non-negativity). For 1 â‰¤ Î± and arbitrary
     ferential privacy,â€ in Proceedings of the 32nd International Conference
     on Machine Learning (ICML), 2015, pp. 1376â€“1385.
                                                                                 distributions P, Q
 [8] J. Murtagh and S. Vadhan, â€œThe complexity of computing the optimal                                       DÎ± (P kQ) â‰¥ 0.
     composition of differential privacy,â€ in Theory of Cryptographyâ€”13th
     International Conference, TCC 2016-A, Part I, E. Kushilevitz and
     T. Malkin, Eds., 2016, pp. 157â€“175.                                         Proof. Assume that Î± > 1. Define Ï†(x) , x1âˆ’Î± and g(x) ,
 [9] C. Dwork and G. N. Rothblum, â€œConcentrated differential privacy,â€           Q(x)/P (x). Then
     CoRR, vol. abs/1603.01887, 2016.
[10] M. Bun and T. Steinke, â€œConcentrated differential privacy: Simplifica-                                      1
     tions, extensions, and lower bounds,â€ in Theory of Cryptographyâ€”14th                       DÎ± (P kQ) =         log EP [Ï†(g(x))]
     International Conference, TCC 2016-B, Part I, M. Hirt and A. D. Smith,                                     Î±âˆ’1
     Eds., 2016, pp. 635â€“658.                                                                                    1
[11] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov,
                                                                                                              â‰¥     log Ï†(EP [g(x)])
                                                                                                                Î±âˆ’1
     K. Talwar, and L. Zhang, â€œDeep learning with differential privacy,â€ in
     Proceedings of the 2016 ACM SIGSAC Conference on Computer and                                            =0
     Communications Security (CCS). ACM, 2016, pp. 308â€“318.
[12] A. McGregor, I. Mironov, T. Pitassi, O. Reingold, K. Talwar, and S. Vad-    by the Jensen inequality applied to the convex function Ï†. The
     han, â€œThe limits of two-party differential privacy,â€ in 51st Annual IEEE    case of Î± = 1 follows by letting Ï† to be log 1/x.
     Symposium on Foundations of Computer Science (FOCS), L. Trevisan,
     Ed. IEEE, 2010, pp. 81â€“90.
[13] A. Groce, J. Katz, and A. Yerukhimovich, â€œLimits of computa-                Proposition 9 (Monotonicity). For 1 â‰¤ Î± < Î² and arbitrary
     tional differential privacy in the client/server setting,â€ in Theory of     P, Q
     Cryptographyâ€”8th Theory of Cryptography Conference, TCC 2011,
     Y. Ishai, Ed., 2011, pp. 417â€“431.                                                                  DÎ± (P kQ) â‰¤ DÎ² (P kQ).
Proof (following [19]). Assume that Î± > 1. Observe that the         Proof. By HoÌˆlderâ€™s inequality we have:
                Î±âˆ’1
function x 7â†’ x Î²âˆ’1 is concave. By Jensenâ€™s inequality
                                                                      exp[(Î± âˆ’ 1)DÎ± (P kQ)]
                                        Î±âˆ’1                               Z
                       1           P (x)                                  =     P (x)Î± Q(x)1âˆ’Î± dx
       DÎ± (P kQ) =        log EP
                    Î±âˆ’1            Q(x)                                      R
                                                                                   P (x)Î± R(x)Î±âˆ’1/p
                                                                            Z
                                        (Î²âˆ’1) Î±âˆ’1
                       1           P (x)        Î²âˆ’1
                                                                          =                           dx
                 =        log EP                                             R R(x)
                                                                                      Î±âˆ’1/p Q(x)Î±âˆ’1
                    Î±âˆ’1            Q(x)                                                        1/p Z                1/q
                                                                                    P (x)pÎ±              R(x)qÎ±âˆ’q/p
                                                                            Z
                              (            Î²âˆ’1 ) Î±âˆ’1
                                                  Î²âˆ’1
                                                                          â‰¤                  dx                     dx
                                   
                       1             P (x)                                              pÎ±âˆ’1                  qÎ±âˆ’q
                 â‰¤        log EP                                               R R(x)                 R Q(x)
                    Î±âˆ’1              Q(x)
                                                                          = exp[(Î± âˆ’ 1/p)DpÎ± (P kR)]Â·
                   = DÎ² (P kQ).                                             exp[(Î± âˆ’ 1)DqÎ±âˆ’q/p (RkQ)].
                                                                    By taking the logarithm and dividing both sides by Î± âˆ’ 1 we
The case of Î± = 1 follows by continuity.                            establish the claim.
                                                                       Several important special cases of the weak triangle inequal-
  The following proposition appears in Langlois et al. [23],        ity can be obtained by fixing parameters p and q (compare it
generalizing Lyubashevsky et al. [24].                              with [25, Lemma 12] and [23, Lemma 4.1]):
Proposition 10 (Probability preservation [23]). Let Î± > 1,          Corollary 4. For P, Q, R with common support we have
P and Q be two distributions defined over R with identical
                                                                      1) DÎ± (P kQ) â‰¤ Î±âˆ’1/2
                                                                                        Î±âˆ’1 D2Î± (P kR) + D2Î±âˆ’1 (RkQ).
support, A âŠ‚ R be an arbitrary event. Then                                              Î±
                                                                      2) DÎ± (P kQ) â‰¤ Î±âˆ’1   Dâˆ (P kR) + DÎ± (RkQ).
                                               (Î±âˆ’1)/Î±                3) DÎ± (P kQ) â‰¤ DÎ± (P kR) + Dâˆ (RkQ).
          P (A) â‰¤ (exp[DÎ± (P kQ)] Â· Q(A))                .
                                                                      4) DÎ± (P kQ) â‰¤ Î±âˆ’Î±/Î²
                                                                                         Î±âˆ’1 DÎ² (P kR) + DÎ² (RkQ), for some
Proof. The result follows by application of HoÌˆlderâ€™s inequal-           explicit Î² = 2Î± âˆ’ .5 + O(1/Î±).
ity, which states that for real-valued functions f and g, and       Proof. All claims follow from the weak triangle inequality
real p, q > 1, such that 1/p + 1/q = 1,                             (Proposition 11) where p and q are chosen, respectively, as
                                                                      1) p = q = 2.
                        kf gk1 â‰¤ kf kpkgkq .
                                                                      2) p â†’ âˆ and q , p/(p âˆ’ 1) â†’ 1.
By setting p , Î±, q , Î±/(Î± âˆ’ 1), f (x) , P (x)/Q(x)1/q ,              3) q â†’ âˆ and p , q/(q âˆ’ 1) â†’ 1.
g(x) , Q(x)1/q , and applying HoÌˆlderâ€™s, we have                      4) such that Î±p = Î±q âˆ’ 1 and 1/p + 1/q = 1.
                                                                    In the last case Î² , pÎ± = 2Î± âˆ’ .5 + O(1/Î±).
 Z                Z                       Î±1 Z         Î±âˆ’1
                                                            Î±
                            Î±     1âˆ’Î±
     P (x) dx â‰¤        P (x) Q(x)       dx        Q(x) dx
  A                 A                           A
                                  (Î±âˆ’1)/Î±      (Î±âˆ’1)/Î±
             â‰¤ exp[DÎ± (P kQ)]               Q(A)         ,

completing the proof.

  The most salient feature of the bound is its (often non-
monotone) dependency on Î±: as Î± approaches 1, DÎ± (P kQ)
shrinks (by monotonicity of the ReÌnyi divergence) but the
power to which it is raised goes to 0, pushing the result in the
opposite direction. Several our proofs proceed by finding the
optimal, or approximately optimal, Î± minimizing the bound.
  The ReÌnyi divergence is not a metric: it is not symmetric
and it does not satisfy the triangle inequality. A weaker variant
of the triangle inequality tying together the ReÌnyi divergence
of different orders does hold. Its general version is presented
below.
Proposition 11 (Weak triangle inequality). Let P, Q, R be
distributions on R. Then for Î± > 1 and for any p, q > 1
satisfying 1/p + 1/q = 1 it holds that
                   Î± âˆ’ 1/p
     DÎ± (P kQ) â‰¤           DpÎ± (P kR) + Dq(Î±âˆ’1/p) (RkQ).
                    Î±âˆ’1
