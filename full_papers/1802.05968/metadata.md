# Information Theory: A Tutorial Introduction
## نظرية المعلومات: مقدمة تعليمية

**arXiv ID:** 1802.05968
**Authors:** James V Stone
**Year:** 2018
**Publication:** arXiv preprint
**Categories:** cs.IT (Information Theory)
**DOI:** N/A
**PDF:** https://arxiv.org/pdf/1802.05968.pdf

**Abstract Translation Quality:** 0.95 (from translations/)
**Full Paper Translation Quality:** 0.874

## Citation

```bibtex
@article{stone2018information,
  title={Information Theory: A Tutorial Introduction},
  author={Stone, James V},
  journal={arXiv preprint arXiv:1802.05968},
  year={2018}
}
```

## Translation Team
- Translator: Claude (Sonnet 4.5)
- Reviewer: TBD
- Started: 2025-11-15
- Completed: 2025-11-15

## Paper Description

This is an excellent educational tutorial paper on Shannon's information theory, covering fundamental concepts like entropy, mutual information, channel capacity, and the key theorems of information theory. Written in an accessible style with intuitive examples (like the "20 questions" game and dice examples), it's ideal for CS students learning these foundational concepts.

The paper includes:
- Clear explanations of bits, entropy, and information
- Shannon's source coding theorem
- Shannon's noisy channel coding theorem
- Gaussian channels and capacity
- Fourier analysis applications
- Historical context
- Comprehensive equation reference

## Translation Notes

Key technical terms:
- Entropy (إنتروبيا)
- Mutual information (المعلومات المشتركة)
- Channel capacity (سعة القناة)
- Shannon information (معلومات شانون)
- Conditional entropy (الإنتروبيا الشرطية)
- Signal-to-noise ratio (نسبة الإشارة إلى الضوضاء)
