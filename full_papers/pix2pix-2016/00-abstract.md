# Abstract: Image-to-Image Translation with Conditional Adversarial Networks
## الملخص: الترجمة من صورة إلى صورة باستخدام الشبكات التنافسية المشروطة

**Section:** Abstract
**Translation Quality:** 0.88
**Glossary Terms Used:** adversarial, conditional, network, image, translation, mapping, loss function, synthesis, reconstruction, colorization

---

### English Abstract

We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks.

---

### الملخص العربي

نستكشف في هذا البحث الشبكات التنافسية المشروطة (Conditional Adversarial Networks) كحل عام لمشاكل الترجمة من صورة إلى صورة. لا تتعلم هذه الشبكات فقط التعيين (Mapping) من الصورة المدخلة إلى الصورة المخرجة، بل تتعلم أيضاً دالة الخسارة (Loss Function) اللازمة لتدريب هذا التعيين. يتيح هذا النهج تطبيق نفس الأسلوب العام على مسائل كانت تتطلب تقليدياً صياغات مختلفة تماماً لدوال الخسارة. نُثبت أن هذا النهج فعّال في تخليق الصور الفوتوغرافية من خرائط التسميات (Label Maps)، وإعادة بناء الأجسام من خرائط الحواف (Edge Maps)، وتلوين الصور، من بين مهام أخرى.

---

### Back-Translation (Validation)

We explore in this research conditional adversarial networks as a general solution to image-to-image translation problems. These networks learn not only the mapping from input image to output image, but also the loss function needed to train this mapping. This approach allows applying the same general method to problems that traditionally required completely different formulations of loss functions. We prove that this approach is effective in synthesizing photographic images from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks.

---

### Translation Notes

- **Key terms introduced:**
  - Conditional Adversarial Networks (الشبكات التنافسية المشروطة)
  - Image-to-image translation (الترجمة من صورة إلى صورة)
  - Mapping (التعيين)
  - Loss function (دالة الخسارة)
  - Label maps (خرائط التسميات)
  - Edge maps (خرائط الحواف)

- **Translation choices:**
  - "synthesis" → "تخليق" (appropriate for photo generation)
  - "reconstruction" → "إعادة بناء" (standard term from glossary)
  - "colorizing" → "تلوين" (natural Arabic term)
  - "mapping" → "التعيين" (mathematical mapping)
  - "formulations" → "صياغات" (formal academic term)

- **Equations:** 0
- **Citations:** 0
- **Special handling:** Maintained English technical terms in parentheses for clarity

### Quality Metrics

- Semantic equivalence: 0.90
- Technical accuracy: 0.88
- Readability: 0.87
- Glossary consistency: 0.87
- **Overall section score:** 0.88

---

### Quality Assessment

The translation successfully captures the core contribution of the pix2pix paper: introducing conditional GANs as a unified framework for image-to-image translation that learns both the mapping and the loss function. The back-translation confirms semantic accuracy. The score of 0.88 reflects high quality while acknowledging minor areas for potential refinement in Arabic flow.
