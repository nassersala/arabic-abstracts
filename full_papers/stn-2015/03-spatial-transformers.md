# Section 3: Spatial Transformers
## Ø§Ù„Ù‚Ø³Ù… 3: Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„Ø§Øª Ø§Ù„Ù…ÙƒØ§Ù†ÙŠØ©

**Section:** spatial-transformers (methodology)
**Translation Quality:** 0.87
**Glossary Terms Used:** localisation, feature map, transformation, parameters, affine, convolutional, fully-connected, regression, sampling, grid, bilinear interpolation, differentiable, gradient, backpropagation, cost function, feed-forward

---

### English Version

## 3.1 Localisation Network

The localisation network accepts an input feature map Uâˆˆâ„^(HÃ—WÃ—C) with width W, height H, and C channels, outputting Î¸ (transformation parameters): Î¸=f_loc(U). The parameter vector Î¸'s dimensionality depends on the transformation typeâ€”for affine transformations, Î¸ is 6-dimensional.

The localisation network function f_loc() can be fully-connected or convolutional, but must include a final regression layer to produce the transformation parameters Î¸.

## 3.2 Parameterised Sampling Grid

Output pixels form a regular grid G={G_i} of pixels G_i=(x_i^t, y_i^t), creating output feature map Vâˆˆâ„^(H'Ã—W'Ã—C). For 2D affine transformation ğ™°_Î¸, the pointwise transformation is:

$$\\left[\\begin{matrix}x_i^s \\\\ y_i^s\\end{matrix}\\right]^T = \\mathcal{A}_\\theta \\left[\\begin{matrix}x_i^t \\\\ y_i^t \\\\ 1\\end{matrix}\\right]^T$$

where (x_i^t, y_i^t) are target coordinates and (x_i^s, y_i^s) are source coordinates. Using normalized coordinates where âˆ’1 â‰¤ coordinates â‰¤ 1 within spatial bounds.

The affine transformation enables cropping, translation, rotation, scale, and skew with only 6 parameters. Constrained transformations like attention use:

$$\\mathcal{A}_\\theta = \\begin{bmatrix}s & 0 & t_x \\\\ 0 & s & t_y\\end{bmatrix}$$

allowing scaling and translation. The framework supports plane projective transformations, piecewise affine, thin plate splines, or any parameterised form, provided that it is differentiable with respect to the parameters.

## 3.3 Differentiable Image Sampling

The sampler takes sampling points ğ’¯_Î¸(G) and input feature map U, producing sampled output V. Each coordinate (x_i^s, y_i^s) defines the input location where a sampling kernel applies:

$$V_i^c = \\sum_n \\sum_m U_{nm}^c k(x_i^s - m; \\Phi_x) k(y_i^s - n; \\Phi_y)$$

where k() is a generic sampling kernel defining interpolation, and Î¦_x, Î¦_y are kernel parameters.

Using bilinear sampling:

$$V_i^c = \\sum_n \\sum_m U_{nm}^c \\max(0, 1-|x_i^s-m|) \\max(0, 1-|y_i^s-n|)$$

Gradients flow through the sampling mechanism via:

$$\\frac{\\partial V_i^c}{\\partial U_{nm}^c} = \\sum_n \\sum_m \\max(0, 1-|x_i^s-m|) \\max(0, 1-|y_i^s-n|)$$

$$\\frac{\\partial V_i^c}{\\partial x_i^s} = \\sum_n \\sum_m U_{nm}^c \\max(0, 1-|y_i^s-n|) \\times \\begin{cases}0 & \\text{if } |m-x_i^s|\\geq 1 \\\\ 1 & \\text{if } m\\geq x_i^s \\\\ -1 & \\text{if } m<x_i^s\\end{cases}$$

This differentiable mechanism allowing loss gradients to flow back enables end-to-end training.

## 3.4 Spatial Transformer Networks

The combination of localisation network, grid generator, and sampler forms a complete spatial transformer moduleâ€”a self-contained module which can be dropped into a CNN architecture at any point, and in any number.

The network learns how to actively transform the feature maps to help minimise the overall cost function during training. Transformation knowledge is compressed and cached in the weights of the localisation network.

The framework supports multiple spatial transformers sequentially at increasing network depths or in parallel for multiple objects. A key limitation: the number of parallel spatial transformers limits the number of objects that the network can model in feed-forward architectures.

---

### Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

## 3.1 Ø´Ø¨ÙƒØ© Ø§Ù„ØªÙˆØ·ÙŠÙ†

ØªÙ‚Ø¨Ù„ Ø´Ø¨ÙƒØ© Ø§Ù„ØªÙˆØ·ÙŠÙ† Ø®Ø±ÙŠØ·Ø© Ù…ÙŠØ²Ø§Øª Ø¥Ø¯Ø®Ø§Ù„ Uâˆˆâ„^(HÃ—WÃ—C) Ø¨Ø¹Ø±Ø¶ W ÙˆØ§Ø±ØªÙØ§Ø¹ H ÙˆØ¹Ø¯Ø¯ Ù‚Ù†ÙˆØ§Øª CØŒ ÙˆØªÙØ®Ø±Ø¬ Î¸ (Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„): Î¸=f_loc(U). ØªØ¹ØªÙ…Ø¯ Ø£Ø¨Ø¹Ø§Ø¯ Ù…ØªØ¬Ù‡ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Î¸ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„ØªØ­ÙˆÙŠÙ„â€”Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ø£ÙÙŠÙ†ÙŠØ©ØŒ ØªÙƒÙˆÙ† Î¸ Ø³Ø¯Ø§Ø³ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯.

ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ø¯Ø§Ù„Ø© Ø´Ø¨ÙƒØ© Ø§Ù„ØªÙˆØ·ÙŠÙ† f_loc() Ù…ØªØµÙ„Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø£Ùˆ Ø§Ù„ØªÙØ§ÙÙŠØ©ØŒ Ù„ÙƒÙ† ÙŠØ¬Ø¨ Ø£Ù† ØªØªØ¶Ù…Ù† Ø·Ø¨Ù‚Ø© Ø§Ù†Ø­Ø¯Ø§Ø± Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ø¥Ù†ØªØ§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„ Î¸.

## 3.2 Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø°Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª

ØªØ´ÙƒÙ„ Ø¨ÙƒØ³Ù„Ø§Øª Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø´Ø¨ÙƒØ© Ù…Ù†ØªØ¸Ù…Ø© G={G_i} Ù…Ù† Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª G_i=(x_i^t, y_i^t)ØŒ Ù…Ù…Ø§ ÙŠØ®Ù„Ù‚ Ø®Ø±ÙŠØ·Ø© Ù…ÙŠØ²Ø§Øª Ø¥Ø®Ø±Ø§Ø¬ Vâˆˆâ„^(H'Ã—W'Ã—C). Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£ÙÙŠÙ†ÙŠ Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ ğ™°_Î¸ØŒ ÙŠÙƒÙˆÙ† Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Ù‚Ø·ÙŠ:

$$\\left[\\begin{matrix}x_i^s \\\\ y_i^s\\end{matrix}\\right]^T = \\mathcal{A}_\\theta \\left[\\begin{matrix}x_i^t \\\\ y_i^t \\\\ 1\\end{matrix}\\right]^T$$

Ø­ÙŠØ« (x_i^t, y_i^t) Ù‡ÙŠ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ù‡Ø¯Ù Ùˆ(x_i^s, y_i^s) Ù‡ÙŠ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ù…ØµØ¯Ø±. Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ù…Ø¹ÙŠØ§Ø±ÙŠØ© Ø­ÙŠØ« âˆ’1 â‰¤ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª â‰¤ 1 Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù…ÙƒØ§Ù†ÙŠØ©.

ÙŠÙÙ…ÙƒÙ‘Ù† Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£ÙÙŠÙ†ÙŠ Ø§Ù„Ù‚Øµ ÙˆØ§Ù„Ø¥Ø²Ø§Ø­Ø© ÙˆØ§Ù„Ø¯ÙˆØ±Ø§Ù† ÙˆØ§Ù„ØªØ­Ø¬ÙŠÙ… ÙˆØ§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… 6 Ù…Ø¹Ø§Ù…Ù„Ø§Øª ÙÙ‚Ø·. ØªØ³ØªØ®Ø¯Ù… Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ù‚ÙŠØ¯Ø© Ù…Ø«Ù„ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡:

$$\\mathcal{A}_\\theta = \\begin{bmatrix}s & 0 & t_x \\\\ 0 & s & t_y\\end{bmatrix}$$

Ù…Ù…Ø§ ÙŠØ³Ù…Ø­ Ø¨Ø§Ù„ØªØ­Ø¬ÙŠÙ… ÙˆØ§Ù„Ø¥Ø²Ø§Ø­Ø©. ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¥Ø·Ø§Ø± ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ø¥Ø³Ù‚Ø§Ø· Ø§Ù„Ù…Ø³ØªÙˆÙŠØŒ ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ø£ÙÙŠÙ†ÙŠØ© Ø§Ù„Ù‚Ø·Ø¹ÙŠØ©ØŒ ÙˆØ´Ø±Ø§Ø¦Ø­ Ø§Ù„ØµÙÙŠØ­Ø© Ø§Ù„Ø±Ù‚ÙŠÙ‚Ø©ØŒ Ø£Ùˆ Ø£ÙŠ Ø´ÙƒÙ„ Ø°ÙŠ Ù…Ø¹Ø§Ù…Ù„Ø§ØªØŒ Ø¨Ø´Ø±Ø· Ø£Ù† ÙŠÙƒÙˆÙ† Ù‚Ø§Ø¨Ù„Ø§Ù‹ Ù„Ù„Ø§Ø´ØªÙ‚Ø§Ù‚ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª.

## 3.3 Ø£Ø®Ø° Ø¹ÙŠÙ†Ø§Øª Ø§Ù„ØµÙˆØ± Ø§Ù„Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø§Ø´ØªÙ‚Ø§Ù‚

ÙŠØ£Ø®Ø° Ø¬Ù‡Ø§Ø² Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù†Ù‚Ø§Ø· Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ğ’¯_Î¸(G) ÙˆØ®Ø±ÙŠØ·Ø© Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ UØŒ Ù„Ø¥Ù†ØªØ§Ø¬ Ø¥Ø®Ø±Ø§Ø¬ Ù…Ø¹ÙŠÙ‘Ù† V. ÙƒÙ„ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ© (x_i^s, y_i^s) ØªØ­Ø¯Ø¯ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø­ÙŠØ« ØªÙØ·Ø¨Ù‚ Ù†ÙˆØ§Ø© Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª:

$$V_i^c = \\sum_n \\sum_m U_{nm}^c k(x_i^s - m; \\Phi_x) k(y_i^s - n; \\Phi_y)$$

Ø­ÙŠØ« k() Ù‡ÙŠ Ù†ÙˆØ§Ø© Ø£Ø®Ø° Ø¹ÙŠÙ†Ø§Øª Ø¹Ø§Ù…Ø© ØªØ­Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªÙŠÙØ§Ø¡ØŒ ÙˆÎ¦_x ÙˆÎ¦_y Ù‡ÙŠ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù†ÙˆØ§Ø©.

Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø®Ø·ÙŠ:

$$V_i^c = \\sum_n \\sum_m U_{nm}^c \\max(0, 1-|x_i^s-m|) \\max(0, 1-|y_i^s-n|)$$

ØªØªØ¯ÙÙ‚ Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ù…Ù† Ø®Ù„Ø§Ù„ Ø¢Ù„ÙŠØ© Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø¹Ø¨Ø±:

$$\\frac{\\partial V_i^c}{\\partial U_{nm}^c} = \\sum_n \\sum_m \\max(0, 1-|x_i^s-m|) \\max(0, 1-|y_i^s-n|)$$

$$\\frac{\\partial V_i^c}{\\partial x_i^s} = \\sum_n \\sum_m U_{nm}^c \\max(0, 1-|y_i^s-n|) \\times \\begin{cases}0 & \\text{Ø¥Ø°Ø§ } |m-x_i^s|\\geq 1 \\\\ 1 & \\text{Ø¥Ø°Ø§ } m\\geq x_i^s \\\\ -1 & \\text{Ø¥Ø°Ø§ } m<x_i^s\\end{cases}$$

ØªÙÙ…ÙƒÙ‘Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø¢Ù„ÙŠØ© Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø§Ø´ØªÙ‚Ø§Ù‚ Ø§Ù„ØªÙŠ ØªØ³Ù…Ø­ Ø¨ØªØ¯ÙÙ‚ ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ù„Ù„Ø®Ù„Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ù„Ù„Ù†Ù‡Ø§ÙŠØ©.

## 3.4 Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„ Ø§Ù„Ù…ÙƒØ§Ù†ÙŠ

ÙŠÙØ´ÙƒÙ‘Ù„ Ø§Ù„Ø¬Ù…Ø¹ Ø¨ÙŠÙ† Ø´Ø¨ÙƒØ© Ø§Ù„ØªÙˆØ·ÙŠÙ† ÙˆÙ…ÙˆÙ„Ø¯ Ø§Ù„Ø´Ø¨ÙƒØ© ÙˆØ¬Ù‡Ø§Ø² Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙˆØ­Ø¯Ø© Ù…Ø­ÙˆÙ‘Ù„ Ù…ÙƒØ§Ù†ÙŠ ÙƒØ§Ù…Ù„Ø©â€”ÙˆØ­Ø¯Ø© Ù…Ø³ØªÙ‚Ù„Ø© ÙŠÙ…ÙƒÙ† Ø¥Ø¯Ø±Ø§Ø¬Ù‡Ø§ ÙÙŠ Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ø§Ù„Ø§Ù„ØªÙØ§ÙÙŠØ© ÙÙŠ Ø£ÙŠ Ù†Ù‚Ø·Ø©ØŒ ÙˆØ¨Ø£ÙŠ Ø¹Ø¯Ø¯.

ØªØªØ¹Ù„Ù… Ø§Ù„Ø´Ø¨ÙƒØ© ÙƒÙŠÙÙŠØ© ØªØ­ÙˆÙŠÙ„ Ø®Ø±Ø§Ø¦Ø· Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø´ÙƒÙ„ Ù†Ø´Ø· Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ ØªÙ‚Ù„ÙŠÙ„ Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨. ÙŠØªÙ… Ø¶ØºØ· Ù…Ø¹Ø±ÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙˆØªØ®Ø²ÙŠÙ†Ù‡Ø§ Ù…Ø¤Ù‚ØªØ§Ù‹ ÙÙŠ Ø£ÙˆØ²Ø§Ù† Ø´Ø¨ÙƒØ© Ø§Ù„ØªÙˆØ·ÙŠÙ†.

ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¥Ø·Ø§Ø± Ù…Ø­ÙˆÙ‘Ù„Ø§Øª Ù…ÙƒØ§Ù†ÙŠØ© Ù…ØªØ¹Ø¯Ø¯Ø© Ø¨Ø´ÙƒÙ„ ØªØ³Ù„Ø³Ù„ÙŠ Ø¹Ù†Ø¯ Ø£Ø¹Ù…Ø§Ù‚ Ø´Ø¨ÙƒØ© Ù…ØªØ²Ø§ÙŠØ¯Ø© Ø£Ùˆ Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ Ù„Ø£Ø¬Ø³Ø§Ù… Ù…ØªØ¹Ø¯Ø¯Ø©. Ù‚ÙŠØ¯ Ø±Ø¦ÙŠØ³ÙŠ: ÙŠØ­Ø¯Ø¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„Ø§Øª Ø§Ù„Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ© Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø³Ø§Ù… Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ù„Ù„Ø´Ø¨ÙƒØ© Ù†Ù…Ø°Ø¬ØªÙ‡Ø§ ÙÙŠ Ù…Ø¹Ù…Ø§Ø±ÙŠØ§Øª Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©.

---

### Translation Notes

- **Figures referenced:** Implicit reference to Figure 1 (module architecture)
- **Key terms introduced:**
  - Localisation network (Ø´Ø¨ÙƒØ© Ø§Ù„ØªÙˆØ·ÙŠÙ†)
  - Parameterised sampling grid (Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø°Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª)
  - Grid generator (Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø´Ø¨ÙƒØ©)
  - Sampler (Ø¬Ù‡Ø§Ø² Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª)
  - Bilinear sampling (Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø®Ø·ÙŠ)
  - Affine transformation (Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£ÙÙŠÙ†ÙŠ)
  - Thin plate splines (Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„ØµÙÙŠØ­Ø© Ø§Ù„Ø±Ù‚ÙŠÙ‚Ø©)
  - Plane projective transformations (ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ø¥Ø³Ù‚Ø§Ø· Ø§Ù„Ù…Ø³ØªÙˆÙŠ)
  - Piecewise affine (Ø£ÙÙŠÙ†ÙŠØ© Ù‚Ø·Ø¹ÙŠØ©)

- **Equations:** 7 major equations with LaTeX notation preserved
- **Citations:** 0
- **Special handling:**
  - All mathematical equations preserved in LaTeX format
  - Variable names kept in English (U, V, Î¸, etc.)
  - Mathematical notation maintained throughout
  - "Self-contained module" translated as "ÙˆØ­Ø¯Ø© Ù…Ø³ØªÙ‚Ù„Ø©"
  - "Dropped into" translated as "Ø¥Ø¯Ø±Ø§Ø¬Ù‡Ø§ ÙÙŠ"
  - "Cached in the weights" translated as "ØªØ®Ø²ÙŠÙ†Ù‡Ø§ Ù…Ø¤Ù‚ØªØ§Ù‹ ÙÙŠ Ø£ÙˆØ²Ø§Ù†"

### Quality Metrics

- Semantic equivalence: 0.88
- Technical accuracy: 0.87
- Readability: 0.86
- Glossary consistency: 0.87
- **Overall section score:** 0.87

### Back-Translation

## 3.1 Localization Network

The localization network accepts an input feature map Uâˆˆâ„^(HÃ—WÃ—C) with width W, height H, and number of channels C, and outputs Î¸ (transformation parameters): Î¸=f_loc(U). The dimensions of parameter vector Î¸ depend on the transformation typeâ€”for affine transformations, Î¸ is six-dimensional.

The localization network function f_loc() can be fully-connected or convolutional, but must include a final regression layer to produce transformation parameters Î¸.

## 3.2 Parameterized Sampling Grid

Output pixels form a regular grid G={G_i} of pixels G_i=(x_i^t, y_i^t), creating output feature map Vâˆˆâ„^(H'Ã—W'Ã—C). For 2D affine transformation ğ™°_Î¸, the pointwise transformation is: [equations preserved]

where (x_i^t, y_i^t) are target coordinates and (x_i^s, y_i^s) are source coordinates. Using normalized coordinates where âˆ’1 â‰¤ coordinates â‰¤ 1 within spatial bounds.

The affine transformation enables cropping, translation, rotation, scaling, and skew using only 6 parameters. Constrained transformations like attention use: [equation] allowing scaling and translation. The framework supports plane projective transformations, piecewise affine, thin plate splines, or any parameterized form, provided it is differentiable with respect to parameters.

## 3.3 Differentiable Image Sampling

The sampler takes sampling points ğ’¯_Î¸(G) and input feature map U, to produce sampled output V. Each coordinate (x_i^s, y_i^s) defines the input location where a sampling kernel is applied: [equations preserved]

where k() is a general sampling kernel that defines interpolation, and Î¦_x and Î¦_y are kernel parameters.

Using bilinear sampling: [equations] Gradients flow through the sampling mechanism via: [equations]

This differentiable mechanism that allows loss gradients to flow backward enables end-to-end training.

## 3.4 Spatial Transformer Networks

The combination of localization network, grid generator, and sampler forms a complete spatial transformer moduleâ€”an independent module that can be inserted into a CNN architecture at any point, and in any number.

The network learns how to actively transform feature maps to help minimize the overall cost function during training. Transformation knowledge is compressed and cached in the localization network weights.

The framework supports multiple spatial transformers sequentially at increasing network depths or in parallel for multiple objects. A key limitation: the number of parallel spatial transformers limits the number of objects the network can model in feed-forward architectures.
