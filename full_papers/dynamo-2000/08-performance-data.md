# Section 8: Performance Data
## القسم 8: بيانات الأداء

**Section:** performance-data
**Translation Quality:** 0.87
**Glossary Terms Used:** benchmarks, SpecInt95, PA-8000, overhead, working set, bail-out, optimization level, profile-feedback compilation, interprocedural optimization

---

### English Version

For performance evaluation we present experiments on several integer benchmarks. Dynamo incurs a fixed startup overhead for allocating and initializing its internal data structures and the fragment cache. The startup overhead could probably be improved through more careful engineering. But for the purposes of this study, we use benchmarks that are long enough to allow the startup and initialization overhead to be recouped. This section presents data comparing the performance of running several integer benchmarks on Dynamo to the identical binary executing directly on the processor. Our benchmark set includes the SpecInt95 benchmarks² and a commercial C++ code called deltablue, which is an incremental constraint solver [28]. The programs were compiled at the +O2 optimization level (equivalent to the default –O option) using the product HP C/C++ compiler. This optimization level includes global intraprocedural optimization. Performance measurements were based on wall clock time on a lightly loaded single-processor HP PA-8000 workstation [21] running the HP-UX 10.20 operating system.

Figure 7 shows the speedup that Dynamo achieves over +O2 optimized native program binaries running without Dynamo. For these runs, Dynamo was configured to use a fixed size 150 Kbyte fragment cache, which is flushed when sharp changes occur to the trace selection rate or there is no room to generate new fragments. Details about the performance impact of varying the fragment cache size are outside the scope of this paper and can be found elsewhere [2]. As the figure indicates, Dynamo achieves considerable speedup in some cases, over 22% in li and m88ksim, about 18% in perl, and about 14% in compress. These four programs have relatively stable working sets, a fact that dynamic optimization can exploit very well. The average overall speedup is about 9%. A significant portion of the performance gains come from the act of selecting a trace and forming a fragment out of it, that is, from the implied partial procedure inlining and improved code layout in the fragment cache. Fragment optimization accounts for approximately 3% of the total gains on average, and one-third of this is due to conservative (signal and volatile-memory safe) optimizations. Note however, that if we ignore the inputs on which Dynamo bails out (as discussed shortly), the average contribution due to trace optimization is around 5%.

Dynamo does not achieve performance improvements on programs go, ijpeg and vortex. Dynamo's startup time is a non-negligible fraction of the total runtime of ijpeg, as ijpeg does not run long enough to recoup Dynamo's startup overhead before starting to provide any performance benefit. In the case of go and vortex that run for a long time, the problem is the lack of a stable working set. A relatively high number of distinct dynamic execution paths are executed in these benchmarks [4]. Frequently changing dynamic execution paths result in an unstable working set, and Dynamo spends too much time selecting traces without these traces being reused sufficiently in the cache to offset the overhead of its own operation.

Fortunately, since Dynamo is a native-to-native optimizer, it can use the original input program binary as a fallback when its overhead starts to get too high. Dynamo constantly monitors the ratio of time spent in Dynamo over time spent in the fragment cache. If this ratio stays above a tolerable threshold for a prolonged period of time, Dynamo assumes that the application cannot be profitably optimized at runtime. At that point Dynamo bails-out by loading the application's app-context to the machine registers and jumping to an application binary address. From that point on the application runs directly on the processor, without any further dynamic optimization. Bail-out allows Dynamo to come close to break-even performance even on "ill-behaved" programs with unstable working sets. This is illustrated in the graph in Figure 8 for the benchmark go. The Dynamo overhead for a relatively well-behaved application, m88ksim, is also shown for comparison.

Figure 9 shows Dynamo's performance on binaries compiled with higher optimization levels. The figure shows the program runtimes with and without Dynamo, for three optimization levels: +O2 (same as –O), +O4, and profile-based +O4 +P (i.e., +O4 with a prior profile collection run). At level +O4, the HP C compiler performs global interprocedural and link-time optimization. At level +O4 +P the compiler performs +O4 optimizations based on profile information gathered during a prior +O4 run. However, compile-time increases very significantly from +O2 to +O4, and the ability to debug the binary is lost. Because of this, most software vendors are reluctant to enable higher optimization levels, in spite of the performance advantages they offer.

The data in Figure 9 shows that Dynamo finds performance improvement opportunities even in highly optimized binaries. In fact, on this set of benchmarks, Dynamo is able to raise the average performance of +O2 compiled binaries to a level that slightly exceeds the performance of their +O4 compiled versions running without Dynamo! This performance boost comes in a transparent fashion, without the creator of the binary having to do anything special. The fact that Dynamo finds performance improvement opportunities even in +O4 optimized binaries is not as surprising as it first seems, because Dynamo primarily focuses on runtime performance opportunities that a static compiler would find difficult to exploit.

In some programs (such as li and perl), Dynamo is able to boost the performance of even profile-feedback compiled binaries (+O4 +P). On average however, the benefits of Dynamo disappear once static optimization is enhanced with profile information. This is to be expected, as the most beneficial inlining and other path-sensitive optimizations have been already made at compile-time.

As pointed out in the introduction, the goal of this study is to establish the limits of Dynamo's capabilities in an extreme setting, where the quality of the input program code is good. In compiling these benchmarks, the static compiler had all of the program sources available, and no dynamically linked libraries were used. Using good quality compiled code as input forced the development effort to focus on fine-tuning the engineering of the Dynamo system.

It should be emphasized that the performance data shown here is very specific to the quality of the code produced by the PA-8000 compiler, and to the PA-8000 processor implementation. Although the hot trace selection and dynamic optimization can be expected to provide benefits in general, the actual impact in terms of wall-clock performance improvement will vary from target to target. On the deeply pipelined PA-8000 for example, the branch misprediction penalty is 5 cycles, and indirect branches (including returns) are always mispredicted. Indirect branch removal therefore makes a big contribution toward Dynamo's performance gains on the PA-8000. On the other hand, the PA-8000 has a large instruction cache (1 Mbyte), so the gains from improved I-cache locality in the software fragment cache code are unlikely to be significant. However, the processor has a unified instruction and data TLB with only 96 entries, so the reduction in TLB pressure due to better locality of the working set in the fragment cache can contribute to a performance boost.

---

### النسخة العربية

للتقييم الأداء، نقدم تجارب على عدة معايير للأعداد الصحيحة. يتكبد دينامو تكلفة بدء تشغيل ثابتة لتخصيص وتهيئة بنى البيانات الداخلية وذاكرة الأجزاء المؤقتة. يمكن على الأرجح تحسين تكلفة بدء التشغيل من خلال هندسة أكثر دقة. لكن لأغراض هذه الدراسة، نستخدم معايير طويلة بما يكفي للسماح باسترداد تكلفة بدء التشغيل والتهيئة. يقدم هذا القسم بيانات تقارن أداء تشغيل عدة معايير للأعداد الصحيحة على دينامو بالملف الثنائي المطابق الذي يُنفَّذ مباشرة على المعالج. تتضمن مجموعة معاييرنا معايير SpecInt95² وشيفرة C++ تجارية تُسمى deltablue، وهي محلل قيود تزايدي [28]. تم ترجمة البرامج في مستوى التحسين +O2 (ما يعادل الخيار الافتراضي –O) باستخدام مترجم HP C/C++ للمنتج. يتضمن مستوى التحسين هذا التحسين العام داخل الإجراءات. استندت قياسات الأداء إلى وقت الساعة الحائطية على محطة عمل HP PA-8000 أحادية المعالج خفيفة التحميل [21] تعمل بنظام التشغيل HP-UX 10.20.

يوضح الشكل 7 التسريع الذي يحققه دينامو على الملفات الثنائية للبرامج الأصلية المحسَّنة بـ +O2 التي تعمل بدون دينامو. لهذه التشغيلات، تم تكوين دينامو لاستخدام ذاكرة أجزاء مؤقتة بحجم ثابت 150 كيلوبايت، والتي تُمسَح عند حدوث تغييرات حادة في معدل اختيار الأثر أو عندما لا توجد مساحة لتوليد أجزاء جديدة. التفاصيل حول تأثير الأداء لتغيير حجم ذاكرة الأجزاء المؤقتة خارج نطاق هذه الورقة ويمكن العثور عليها في مكان آخر [2]. كما يشير الشكل، يحقق دينامو تسريعاً كبيراً في بعض الحالات، أكثر من 22% في li و m88ksim، وحوالي 18% في perl، وحوالي 14% في compress. هذه البرامج الأربعة لديها مجموعات عمل مستقرة نسبياً، وهي حقيقة يمكن للتحسين الديناميكي استغلالها بشكل جيد. متوسط التسريع الإجمالي حوالي 9%. يأتي جزء كبير من مكاسب الأداء من فعل اختيار أثر وتكوين جزء منه، أي من التضمين الجزئي الضمني للإجراءات وتحسين تخطيط الشيفرة في ذاكرة الأجزاء المؤقتة. يمثل تحسين الجزء حوالي 3% من المكاسب الإجمالية في المتوسط، وثلث هذا يرجع إلى التحسينات المحافظة (الآمنة للإشارات والذاكرة المتطايرة). لاحظ مع ذلك، أنه إذا تجاهلنا المدخلات التي يخرج منها دينامو (كما نوقش قريباً)، فإن متوسط المساهمة بسبب تحسين الأثر يكون حوالي 5%.

لا يحقق دينامو تحسينات في الأداء على البرامج go و ijpeg و vortex. وقت بدء تشغيل دينامو جزء غير مهمل من إجمالي وقت تشغيل ijpeg، حيث لا يعمل ijpeg لفترة كافية لاسترداد تكلفة بدء تشغيل دينامو قبل البدء في توفير أي فائدة للأداء. في حالة go و vortex التي تعمل لفترة طويلة، المشكلة هي نقص مجموعة عمل مستقرة. يتم تنفيذ عدد مرتفع نسبياً من مسارات التنفيذ الديناميكية المتميزة في هذه المعايير [4]. تؤدي مسارات التنفيذ الديناميكية المتغيرة بشكل متكرر إلى مجموعة عمل غير مستقرة، ويقضي دينامو وقتاً طويلاً في اختيار الآثار دون إعادة استخدام هذه الآثار بشكل كافٍ في الذاكرة المؤقتة لتعويض تكلفة عمله.

لحسن الحظ، نظراً لأن دينامو محسِّن من أصلي إلى أصلي، يمكنه استخدام الملف الثنائي للبرنامج المدخل الأصلي كحل احتياطي عندما تبدأ تكلفته في الارتفاع بشكل كبير. يراقب دينامو باستمرار نسبة الوقت المقضي في دينامو على الوقت المقضي في ذاكرة الأجزاء المؤقتة. إذا بقيت هذه النسبة فوق عتبة محتملة لفترة طويلة من الوقت، يفترض دينامو أن التطبيق لا يمكن تحسينه بشكل مربح في وقت التشغيل. في تلك المرحلة، يخرج دينامو بتحميل app-context للتطبيق إلى سجلات الآلة والقفز إلى عنوان ملف ثنائي للتطبيق. من تلك النقطة فصاعداً، يعمل التطبيق مباشرة على المعالج، دون أي تحسين ديناميكي إضافي. يسمح الخروج لدينامو بالاقتراب من أداء التعادل حتى على البرامج "سيئة السلوك" مع مجموعات العمل غير المستقرة. يوضح هذا في الرسم البياني في الشكل 8 للمعيار go. تُظهَر أيضاً تكلفة دينامو لتطبيق جيد السلوك نسبياً، m88ksim، للمقارنة.

يوضح الشكل 9 أداء دينامو على الملفات الثنائية المترجمة بمستويات تحسين أعلى. يوضح الشكل أوقات تشغيل البرنامج مع وبدون دينامو، لثلاثة مستويات تحسين: +O2 (نفس –O)، و +O4، و +O4 +P القائم على ملف التعريف (أي +O4 مع تشغيل جمع ملف تعريف سابق). في مستوى +O4، يجري مترجم HP C التحسين العام بين الإجراءات ووقت الربط. في مستوى +O4 +P، يجري المترجم تحسينات +O4 استناداً إلى معلومات ملف التعريف المجمعة أثناء تشغيل +O4 سابق. مع ذلك، يزداد وقت الترجمة بشكل كبير جداً من +O2 إلى +O4، وتُفقَد القدرة على تصحيح الملف الثنائي. بسبب هذا، يتردد معظم موردي البرمجيات في تمكين مستويات تحسين أعلى، على الرغم من مزايا الأداء التي يقدمونها.

تُظهر البيانات في الشكل 9 أن دينامو يجد فرص تحسين الأداء حتى في الملفات الثنائية المحسَّنة بشكل كبير. في الواقع، على مجموعة المعايير هذه، دينامو قادر على رفع متوسط أداء الملفات الثنائية المترجمة بـ +O2 إلى مستوى يتجاوز قليلاً أداء نسخها المترجمة بـ +O4 التي تعمل بدون دينامو! تأتي دفعة الأداء هذه بطريقة شفافة، دون الحاجة إلى منشئ الملف الثنائي للقيام بأي شيء خاص. حقيقة أن دينامو يجد فرص تحسين الأداء حتى في الملفات الثنائية المحسَّنة بـ +O4 ليست مفاجئة كما تبدو في البداية، لأن دينامو يركز في المقام الأول على فرص أداء وقت التشغيل التي يصعب على المترجم الساكن استغلالها.

في بعض البرامج (مثل li و perl)، يستطيع دينامو تعزيز أداء حتى الملفات الثنائية المترجمة بردود فعل ملف التعريف (+O4 +P). في المتوسط ​​مع ذلك، تختفي فوائد دينامو بمجرد تحسين التحسين الساكن بمعلومات ملف التعريف. هذا متوقع، حيث تم إجراء أكثر التضمينات والتحسينات الحساسة للمسار فائدة بالفعل في وقت الترجمة.

كما أُشير في المقدمة، الهدف من هذه الدراسة هو تحديد حدود قدرات دينامو في بيئة متطرفة، حيث جودة شيفرة البرنامج المدخل جيدة. في ترجمة هذه المعايير، كان للمترجم الساكن جميع مصادر البرنامج متاحة، ولم تُستخدَم مكتبات مرتبطة ديناميكياً. أجبر استخدام شيفرة مترجمة عالية الجودة كمدخل جهد التطوير على التركيز على ضبط دقيق لهندسة نظام دينامو.

يجب التأكيد على أن بيانات الأداء المعروضة هنا خاصة جداً بجودة الشيفرة التي ينتجها مترجم PA-8000، وبتطبيق معالج PA-8000. على الرغم من أنه يمكن توقع أن يوفر اختيار الأثر الساخن والتحسين الديناميكي فوائد بشكل عام، فإن التأثير الفعلي من حيث تحسين أداء وقت الساعة الحائطية سيختلف من هدف لآخر. على PA-8000 ذو خط الأنابيب العميق على سبيل المثال، عقوبة التنبؤ الخاطئ بالتفريع هي 5 دورات، والتفريعات غير المباشرة (بما في ذلك العودة) تُتنبأ بشكل خاطئ دائماً. لذلك تساهم إزالة التفريع غير المباشر بشكل كبير في مكاسب أداء دينامو على PA-8000. من ناحية أخرى، يحتوي PA-8000 على ذاكرة تعليمات مؤقتة كبيرة (1 ميجابايت)، لذلك من غير المحتمل أن تكون المكاسب من تحسين موضعية I-cache في شيفرة ذاكرة الأجزاء المؤقتة البرمجية كبيرة. مع ذلك، يحتوي المعالج على TLB موحد للتعليمات والبيانات بـ 96 مدخلاً فقط، لذلك يمكن أن يساهم التقليل في ضغط TLB بسبب موضعية أفضل لمجموعة العمل في ذاكرة الأجزاء المؤقتة في دفعة الأداء.

---

### Translation Notes

- **Figures referenced:** Figure 7 (speedup chart), Figure 8 (bail-out illustration), Figure 9 (performance at different optimization levels)
- **Benchmarks:** SpecInt95 (compress, go, ijpeg, li, m88ksim, perl, vortex), deltablue
- **Key metrics:** 9% average speedup, 22% on li and m88ksim, 18% on perl, 14% on compress
- **Optimization levels:** +O2, +O4, +O4 +P (profile-feedback)
- **Architecture details:** PA-8000 with 5-cycle branch misprediction penalty, 1MB I-cache, 96-entry TLB
- **Bail-out mechanism:** Fallback to native execution when overhead is too high

### Quality Metrics

- Semantic equivalence: 0.88
- Technical accuracy: 0.87
- Readability: 0.86
- Glossary consistency: 0.87
- **Overall section score:** 0.87
