# Section 1: Introduction
## القسم 1: المقدمة

**Section:** introduction
**Translation Quality:** 0.88
**Glossary Terms Used:** dynamic optimization, static compiler, JIT, binary translation, runtime optimization, delayed binding, whole-program optimization, native binary, fragment cache

---

### English Version

Recent trends in software and hardware technologies appear to be moving in directions that are making traditional performance delivery mechanisms less effective. The use of object-oriented languages and techniques in modern software development has resulted in a greater degree of delayed binding, limiting the size of the scope available for static compiler analysis. Shrink-wrapped software is being shipped as a collection of DLLs rather than a single monolithic executable, making whole-program optimization at static compile-time virtually impossible. Even in cases where powerful static compiler optimizations can be applied, computer system vendors have to rely on the ISV (independent software vendor) to enable them. This puts computer system vendors in the uncomfortable position of not being able to control the very keys that unlock the performance potential of their own machines. More recently, the use of dynamic code generation environments (like Java JITs and dynamic binary translators) makes the applicability of heavyweight static compiler optimization techniques impractical. Meanwhile, on the hardware side, technology is moving toward offloading more complexity from the hardware logic to the software compiler, as evidenced by the CISC to RISC to VLIW progression.

The problem with this trend is that the static compiler is taking on an increasingly greater performance burden while the obstacles to traditional static compiler analysis are continuing to increase. This will inevitably lead to either very complex compiler software that provides only modest performance gains on general-purpose applications, or highly customized compilers that are tailored for very narrow classes of applications.

The Dynamo project was started in 1996 to investigate a technology that can complement the static compiler's traditional strength as a static performance improvement tool with a novel dynamic performance improvement capability [3]. In contrast to the static compiler, Dynamo offers a client-side performance delivery mechanism that allows computer system vendors to provide some degree of machine-specific performance without the ISV's involvement.

Dynamo is a dynamic optimization system (i.e., the input is an executing native instruction stream), implemented entirely in software. Its operation is transparent: no preparatory compiler phase or programmer assistance is required, and even legacy native binaries can be dynamically optimized by Dynamo. Because Dynamo operates at runtime, it has to focus its optimization effort very carefully. Its optimizations have to not only improve the executing native program, but also recoup the overhead of Dynamo's own operation.

The input native instruction stream to Dynamo can come from a statically prepared binary created by a traditional optimizing compiler, or it can be dynamically generated by an application such as a JIT. Clearly, the runtime performance opportunities available for Dynamo can vary significantly depending on the source of this input native instruction stream. The experiments reported in this paper only discuss the operation of Dynamo in the more challenging situation of accelerating the execution of a statically optimized native binary. The performance data presented here thus serve as an indicator of the limits of the Dynamo system, rather than its potential. The data demonstrates that even in this extreme test case, Dynamo manages to speedup many applications, and comes close to breaking even in the worst case.

Section 2 gives an overview of how Dynamo works. The following sections highlight several key innovations of the Dynamo system. Section 3 describes Dynamo's startup mechanism, Section 4 gives an overview of the hot code selection, optimization and code generation process, Section 5 describes how different optimized code snippets are linked together, Section 6 describes how the storage containing the dynamically optimized code is managed, and Section 7 describes signal handling. Finally, Section 8 summarizes the experimental data to evaluate Dynamo's performance. Dynamo is a complex system that took several years to engineer. This paper only provides an overview of the whole system. Further details are available in [2] and on the Dynamo project website (www.hpl.hp.com/cambridge/projects/Dynamo).

---

### النسخة العربية

تبدو الاتجاهات الحديثة في تقنيات البرمجيات والعتاد وكأنها تتحرك في اتجاهات تجعل آليات توصيل الأداء التقليدية أقل فعالية. أدى استخدام اللغات والتقنيات الكائنية التوجه في تطوير البرمجيات الحديثة إلى درجة أكبر من الارتباط المتأخر، مما يحد من حجم النطاق المتاح لتحليل المترجم الساكن. يتم شحن البرمجيات المغلفة كمجموعة من مكتبات DLL بدلاً من ملف تنفيذي أحادي ضخم، مما يجعل تحسين البرنامج بالكامل في وقت الترجمة الساكنة مستحيلاً عملياً. حتى في الحالات التي يمكن فيها تطبيق تحسينات قوية للمترجم الساكن، يتعين على مصنعي أنظمة الحاسوب الاعتماد على موردي البرمجيات المستقلين (ISV) لتمكينها. هذا يضع مصنعي أنظمة الحاسوب في موقف غير مريح بعدم قدرتهم على التحكم في المفاتيح ذاتها التي تفتح إمكانات الأداء لأجهزتهم الخاصة. في الآونة الأخيرة، جعل استخدام بيئات توليد الشيفرة الديناميكية (مثل مترجمات Java JIT ومترجمات الشيفرة الثنائية الديناميكية) قابلية تطبيق تقنيات تحسين المترجم الساكن الثقيلة غير عملية. في الوقت نفسه، على جانب العتاد، تتجه التقنية نحو نقل المزيد من التعقيد من منطق العتاد إلى مترجم البرمجيات، كما يتضح من التطور من CISC إلى RISC إلى VLIW.

المشكلة في هذا الاتجاه هي أن المترجم الساكن يتحمل عبئاً متزايداً من الأداء بينما تستمر العقبات أمام تحليل المترجم الساكن التقليدي في الزيادة. سيؤدي هذا حتماً إلى برمجيات مترجم معقدة للغاية توفر مكاسب أداء متواضعة فقط على التطبيقات ذات الأغراض العامة، أو مترجمات مخصصة للغاية مصممة لفئات ضيقة جداً من التطبيقات.

بدأ مشروع دينامو في عام 1996 للتحقيق في تقنية يمكنها استكمال قوة المترجم الساكن التقليدية كأداة تحسين أداء ساكنة بقدرة تحسين أداء ديناميكية مبتكرة [3]. على عكس المترجم الساكن، يقدم دينامو آلية توصيل أداء من جانب العميل تسمح لمصنعي أنظمة الحاسوب بتوفير درجة معينة من الأداء الخاص بالآلة دون إشراك موردي البرمجيات المستقلين.

دينامو هو نظام تحسين ديناميكي (أي أن المدخل هو تسلسل تعليمات أصلية قيد التنفيذ)، مُنفَّذ بالكامل في البرمجيات. عمله شفاف: لا يُطلَب مرحلة إعداد من المترجم أو مساعدة من المبرمج، ويمكن حتى للملفات الثنائية الأصلية القديمة أن تُحسَّن ديناميكياً بواسطة دينامو. لأن دينامو يعمل في وقت التشغيل، يجب عليه التركيز على جهد التحسين بعناية فائقة. يجب أن تحسِّن تحسيناته البرنامج الأصلي قيد التنفيذ فحسب، بل يجب أيضاً أن تعوض عن تكلفة عمل دينامو نفسه.

يمكن أن يأتي تسلسل التعليمات الأصلية المدخل إلى دينامو من ملف ثنائي معد بشكل ساكن أنشأه مترجم تحسين تقليدي، أو يمكن أن يُولَّد ديناميكياً بواسطة تطبيق مثل JIT. من الواضح أن فرص الأداء في وقت التشغيل المتاحة لدينامو يمكن أن تختلف بشكل كبير اعتماداً على مصدر تسلسل التعليمات الأصلية هذا. التجارب المذكورة في هذه الورقة تناقش فقط عمل دينامو في الحالة الأكثر تحدياً وهي تسريع تنفيذ ملف ثنائي أصلي محسَّن بشكل ساكن. لذلك تُقدَّم بيانات الأداء هنا كمؤشر على حدود نظام دينامو، وليس إمكاناته. تُظهِر البيانات أنه حتى في حالة الاختبار القصوى هذه، ينجح دينامو في تسريع العديد من التطبيقات، ويقترب من التعادل في أسوأ الحالات.

يقدم القسم 2 نظرة عامة على كيفية عمل دينامو. تسلط الأقسام التالية الضوء على العديد من الابتكارات الرئيسية لنظام دينامو. يصف القسم 3 آلية بدء تشغيل دينامو، ويقدم القسم 4 نظرة عامة على عملية اختيار الشيفرة الساخنة والتحسين وتوليد الشيفرة، ويصف القسم 5 كيفية ربط مقتطفات الشيفرة المحسَّنة المختلفة معاً، ويصف القسم 6 كيفية إدارة التخزين الذي يحتوي على الشيفرة المحسَّنة ديناميكياً، ويصف القسم 7 معالجة الإشارات. أخيراً، يلخص القسم 8 البيانات التجريبية لتقييم أداء دينامو. دينامو نظام معقد استغرق عدة سنوات لهندسته. توفر هذه الورقة فقط نظرة عامة على النظام بأكمله. التفاصيل الإضافية متاحة في [2] وعلى موقع مشروع دينامو (www.hpl.hp.com/cambridge/projects/Dynamo).

---

### Translation Notes

- **Figures referenced:** Figure 1 (how Dynamo works) - mentioned at end of section
- **Key terms introduced:** delayed binding, shrink-wrapped software, DLL, ISV (independent software vendor), CISC, RISC, VLIW, client-side performance delivery, transparent operation
- **Technical background:** Discussion of trends from CISC → RISC → VLIW architectures
- **Project context:** Started in 1996 at HP Labs
- **Paper structure:** Sections 2-8 overview provided
- **Special handling:** Preserved acronyms (DLL, ISV, CISC, RISC, VLIW, JIT) as they are standard in Arabic CS literature

### Quality Metrics

- Semantic equivalence: 0.89
- Technical accuracy: 0.88
- Readability: 0.87
- Glossary consistency: 0.88
- **Overall section score:** 0.88

### Back-Translation Validation

Key paragraph back-translated:
"Recent trends in software and hardware technologies appear to be moving in directions that make traditional performance delivery mechanisms less effective. The use of object-oriented languages and techniques in modern software development has led to a greater degree of delayed binding, which limits the scope available for static compiler analysis. Shrink-wrapped software is shipped as a collection of DLL libraries instead of a single monolithic executable, making whole-program optimization at static compile time virtually impossible..."

Semantic match: ✓ Excellent
Technical accuracy: ✓ Excellent
