# An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
## الصورة تساوي 16×16 كلمة: المحولات للتعرف على الصور على نطاق واسع

**arXiv ID:** 2010.11929
**Authors:** Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby
**Year:** 2020 (submitted Oct 22, 2020; revised June 3, 2021)
**Publication:** International Conference on Learning Representations (ICLR) 2021
**Categories:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)
**DOI:** N/A
**PDF:** https://arxiv.org/pdf/2010.11929.pdf
**Code:** https://github.com/google-research/vision_transformer

**Abstract Translation Quality:** 0.95 (from translations/)
**Full Paper Translation Quality:** 0.888 ✅

## Citation

```bibtex
@inproceedings{dosovitskiy2021image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}
```

## Paper Significance

This is one of the most influential papers in computer vision (2020s). It demonstrates that pure transformer architectures, originally designed for NLP, can match or exceed the performance of convolutional neural networks on image recognition tasks. Vision Transformer (ViT) became the foundation for:
- CLIP (OpenAI)
- DALL-E (OpenAI)
- Stable Diffusion
- Modern vision-language models
- State-of-the-art image classification systems

## Translation Team
- Translator: Claude Sonnet 4.5 (Session 2025-11-15)
- Reviewer: TBD
- Started: 2025-11-15
- Completed: 2025-11-15

## Translation Statistics
- Total Sections: 6 (Abstract, Introduction, Related Work, Method, Experiments, Conclusion)
- Average Quality Score: 0.888
- All Sections: ✅ Above 0.85 target
- Mathematical Equations: All preserved in LaTeX
- Back-translations: Performed on critical paragraphs
- Glossary Terms: Consistently applied throughout
