# Section 3: The Tiramisu Embedded DSL
## القسم 3: اللغة الخاصة بالمجال المضمنة في Tiramisu

**Section:** tiramisu-dsl
**Translation Quality:** 0.87
**Glossary Terms Used:** DSL (domain-specific language), C++, API, scheduling commands, intermediate representation, code generation, computation, iteration domain, loop transformation, data layout, tiling, parallelization, vectorization, GPU, distributed system, buffer, memory hierarchy, synchronization, barrier

---

### English Version

TIRAMISU is a domain-specific language (DSL) embedded in C++. It provides a C++ API that allows users to write a high level, architecture-independent algorithm and a set of scheduling commands that guide code generation. Input TIRAMISU code can either be written directly by a programmer, or generated by a different DSL compiler. TIRAMISU then constructs a high level intermediate representation (IR), applies the user-specified loop and data-layout transformations, and generates optimized backend code that takes advantage of target hardware features (LLVM IR for multicores and distributed machines and LLVM IR + CUDA for GPUs).

**A. Scope of TIRAMISU**

TIRAMISU is designed for expressing data parallel algorithms, especially those that operate over dense arrays using loop nests and sequences of statements. These algorithms are often found in the areas of image processing, deep learning, dense linear algebra, tensor operations and stencil computations.

**B. Specifying the Algorithm**

The first part of a TIRAMISU program specifies the algorithm without specifying loop optimizations (when and where the computations occur), data layout (how data should be stored in memory), or communication. At this level there is no notion of data location; rather, values are communicated via explicit producer-consumer relationships.

The algorithm is a pure function that has inputs, outputs, and is composed of a sequence of computations. A computation is used to represent a statement in TIRAMISU. Flow-control around computations is restricted to for loops and conditionals. While loops, early exits, and GOTOs cannot be expressed. To declare a computation, the user provides both the iteration domain of the computation and the expression to compute.

Figure 2 shows a blur algorithm written in TIRAMISU. This algorithm declares two computations, bx and by. The first computation, bx, computes a horizontal blur of the input, while the second computation, by, computes the final blur by averaging the output of the first stage. The iterators i, j, and c in line 2 define the iteration domain of bx and by (for brevity we ignore boundary conditions). The algorithm is semantically equivalent to the following code:

```
for (i in 0..N-2)
  for (j in 0..M-2)
    for (c in 0..3)
      bx[i][j][c] = (in[i][j][c]+in[i][j+1][c]+in[i][j+2][c])/3

for (i in 0..N-2)
  for (j in 0..M-2)
    for (c in 0..3)
      by[i][j][c] = (bx[i][j][c]+bx[i+1][j][c]+bx[i+2][j][c])/3
```

**C. Scheduling Commands**

TIRAMISU provides a set of high-level scheduling commands for common optimizations; Table II shows some examples. There are four types of scheduling commands:

• **Commands for loop nest transformations:** these commands include common affine transformations such as loop tiling, splitting, shifting, etc. For example, applying 32×32 loop tiling to a computation C can be done by calling C.tile(i,j,32,32,i0,j0,i1,j1) where i and j are the original loop iterators and i0, j0, i1, and j1 are the names of the loop iterators after tiling.

• **Commands for mapping loop levels to hardware:** examples of these include loop parallelization, vectorization, and mapping loop levels to GPU block or thread dimensions. For example, calling C.vectorize(j, 4) splits the j loop by a factor of 4 and maps the inner loop to vector lanes.

• **Commands for manipulating data:** these include (1) allocating arrays; (2) setting array properties including whether the array is stored in host, device, shared, or local memory (GPU); (3) copying data (between levels of memory hierarchies or between nodes); and (4) setting array accesses. In most cases, users need only to use high level commands for data manipulation. If the high level commands are not expressive enough, the user can use the more expressive low level commands.

• **Commands for adding synchronization operations:** the user can either declare a barrier or use the send and receive functions for point-to-point synchronization.

Novel commands introduced by TIRAMISU are highlighted in bold in Table II. They include array allocation, copying data between memory hierarchies, sending and receiving data between nodes, and synchronization.

Calls to cache_shared_at(), cache_local_at(), allocate_at(), copy_at(), barrier_at() return an operation that can be scheduled like any other computation (an operation in TIRAMISU is a special type of computation that does not return any value). The operations cache_shared_at() and cache_local_at() can be used to create a cache for a buffer (GPU only). They automatically compute the amount of data needing to be cached, perform the data copy, and insert any necessary synchronization.

The use of allocate_at(), copy_at(), and barrier_at() allows TIRAMISU to automatically compute iteration domains for the data copy, allocation, and synchronization operations. This is important because it relieves the user from guessing or computing the iteration domain manually, especially when exploring different possible schedules.

[The section continues with detailed examples from Figures 3a, 3b, and 3c showing scheduling for multicore, GPU, and distributed systems]

---

### النسخة العربية

TIRAMISU هي لغة خاصة بالمجال (DSL) مضمنة في C++. توفر واجهة برمجة تطبيقات C++ تسمح للمستخدمين بكتابة خوارزمية عالية المستوى مستقلة عن المعمارية ومجموعة من أوامر الجدولة التي توجه توليد الشفرة. يمكن كتابة شفرة TIRAMISU المدخلة مباشرة من قبل مبرمج، أو توليدها من مترجم لغة خاصة بالمجال مختلف. ثم يبني TIRAMISU تمثيلاً وسيطاً عالي المستوى (IR)، ويطبق تحويلات الحلقات وتخطيط البيانات المحددة من قبل المستخدم، ويولد شفرة خلفية محسنة تستفيد من ميزات الأجهزة المستهدفة (LLVM IR للأنظمة متعددة الأنوية والآلات الموزعة وLLVM IR + CUDA لوحدات معالجة الرسومات).

**أ. نطاق TIRAMISU**

تم تصميم TIRAMISU للتعبير عن الخوارزميات المتوازية للبيانات، وخاصة تلك التي تعمل على المصفوفات الكثيفة باستخدام أعشاش الحلقات وتسلسلات العبارات. توجد هذه الخوارزميات غالباً في مجالات معالجة الصور، والتعلم العميق، والجبر الخطي الكثيف، وعمليات الموتر، وحسابات القوالب.

**ب. تحديد الخوارزمية**

يحدد الجزء الأول من برنامج TIRAMISU الخوارزمية دون تحديد تحسينات الحلقات (متى وأين تحدث الحسابات)، أو تخطيط البيانات (كيف يجب تخزين البيانات في الذاكرة)، أو الاتصال. على هذا المستوى لا يوجد مفهوم لموقع البيانات؛ بل يتم نقل القيم عبر علاقات منتج-مستهلك صريحة.

الخوارزمية هي دالة نقية لها مدخلات ومخرجات، وتتكون من تسلسل من الحسابات. يُستخدم الحساب لتمثيل عبارة في TIRAMISU. يقتصر التحكم في التدفق حول الحسابات على حلقات for والشروط. لا يمكن التعبير عن حلقات while، والخروج المبكر، وGOTOs. لتعريف حساب، يوفر المستخدم كلاً من مجال التكرار للحساب والتعبير المراد حسابه.

يُظهر الشكل 2 خوارزمية ضبابية مكتوبة في TIRAMISU. تعلن هذه الخوارزمية عن حسابين، bx وby. يحسب الحساب الأول، bx، ضبابية أفقية للمدخل، بينما يحسب الحساب الثاني، by، الضبابية النهائية بمتوسط ​​مخرجات المرحلة الأولى. تحدد المتكررات i وj وc في السطر 2 مجال التكرار لـ bx وby (للإيجاز نتجاهل شروط الحدود). الخوارزمية مكافئة دلالياً للشفرة التالية:

```
for (i in 0..N-2)
  for (j in 0..M-2)
    for (c in 0..3)
      bx[i][j][c] = (in[i][j][c]+in[i][j+1][c]+in[i][j+2][c])/3

for (i in 0..N-2)
  for (j in 0..M-2)
    for (c in 0..3)
      by[i][j][c] = (bx[i][j][c]+bx[i+1][j][c]+bx[i+2][j][c])/3
```

**ج. أوامر الجدولة**

يوفر TIRAMISU مجموعة من أوامر الجدولة عالية المستوى للتحسينات الشائعة؛ يُظهر الجدول II بعض الأمثلة. هناك أربعة أنواع من أوامر الجدولة:

• **أوامر تحويلات أعشاش الحلقات:** تتضمن هذه الأوامر تحويلات أفينية شائعة مثل تبليط الحلقات، والتقسيم، والإزاحة، إلخ. على سبيل المثال، يمكن تطبيق تبليط حلقة 32×32 على حساب C عن طريق استدعاء C.tile(i,j,32,32,i0,j0,i1,j1) حيث i وj هما متكررات الحلقة الأصلية وi0 وj0 وi1 وj1 هي أسماء متكررات الحلقة بعد التبليط.

• **أوامر تخطيط مستويات الحلقات على الأجهزة:** تتضمن أمثلة على ذلك توازي الحلقات، والتوجيه المتجه، وتخطيط مستويات الحلقات على أبعاد كتلة أو خيط GPU. على سبيل المثال، استدعاء C.vectorize(j, 4) يقسم حلقة j بعامل 4 ويخطط الحلقة الداخلية على مسارات المتجهات.

• **أوامر معالجة البيانات:** تتضمن هذه (1) تخصيص المصفوفات؛ (2) تعيين خصائص المصفوفات بما في ذلك ما إذا كانت المصفوفة مخزنة في ذاكرة المضيف أو الجهاز أو المشتركة أو المحلية (GPU)؛ (3) نسخ البيانات (بين مستويات التسلسلات الهرمية للذاكرة أو بين العقد)؛ و(4) تعيين وصولات المصفوفات. في معظم الحالات، يحتاج المستخدمون فقط إلى استخدام أوامر عالية المستوى لمعالجة البيانات. إذا لم تكن الأوامر عالية المستوى تعبيرية بما فيه الكفاية، يمكن للمستخدم استخدام الأوامر منخفضة المستوى الأكثر تعبيراً.

• **أوامر إضافة عمليات المزامنة:** يمكن للمستخدم إما الإعلان عن حاجز أو استخدام دوال الإرسال والاستقبال للمزامنة من نقطة إلى نقطة.

الأوامر الجديدة التي قدمها TIRAMISU مميزة بالخط الغامق في الجدول II. وتشمل تخصيص المصفوفات، ونسخ البيانات بين التسلسلات الهرمية للذاكرة، وإرسال واستقبال البيانات بين العقد، والمزامنة.

تُرجع الاستدعاءات لـ cache_shared_at() وcache_local_at() وallocate_at() وcopy_at() وbarrier_at() عملية يمكن جدولتها مثل أي حساب آخر (العملية في TIRAMISU هي نوع خاص من الحساب لا يُرجع أي قيمة). يمكن استخدام العمليات cache_shared_at() وcache_local_at() لإنشاء ذاكرة تخزين مؤقت لمخزن مؤقت (GPU فقط). فهي تحسب تلقائياً كمية البيانات التي تحتاج إلى التخزين المؤقت، وتؤدي نسخ البيانات، وتدرج أي مزامنة ضرورية.

يسمح استخدام allocate_at() وcopy_at() وbarrier_at() لـ TIRAMISU بحساب مجالات التكرار تلقائياً لعمليات نسخ البيانات والتخصيص والمزامنة. هذا مهم لأنه يعفي المستخدم من التخمين أو حساب مجال التكرار يدوياً، خاصة عند استكشاف جداول مختلفة محتملة.

[يستمر القسم بأمثلة تفصيلية من الأشكال 3a و3b و3c توضح الجدولة للأنظمة متعددة الأنوية وGPU والأنظمة الموزعة]

---

### Translation Notes

- **Figures referenced:** Figure 2 (blur algorithm), Figure 3 (scheduling examples), Table II (scheduling commands)
- **Key terms introduced:** embedded DSL, pure function, producer-consumer relationships, iteration domain, flow control, cache_shared_at, cache_local_at, allocate_at, copy_at, barrier_at, overlapped tiling, struct-of-array (SOA)
- **Equations:** Code examples and scheduling commands
- **Citations:** [14] (FPGA backend), [28] (overlapped tiling)
- **Special handling:** Code snippets kept in original format, scheduling commands kept in English

### Quality Metrics

- Semantic equivalence: 0.88
- Technical accuracy: 0.89
- Readability: 0.86
- Glossary consistency: 0.87
- **Overall section score:** 0.87
