# CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation
## CodeT5: نماذج مشفر-فك تشفير موحدة مُدربة مسبقاً ومدركة للمعرفات لفهم الشفرة وتوليدها

**arXiv ID:** 2109.00859
**Authors:** Yue Wang, Weishi Wang, Shafiq Joty, Steven C.H. Hoi
**Year:** 2021
**Publication:** EMNLP 2021
**Categories:** Computation and Language (cs.CL); Programming Languages (cs.PL)
**DOI:** N/A
**PDF:** https://arxiv.org/pdf/2109.00859.pdf

**Abstract Translation Quality:** 0.91 (from translations/)
**Full Paper Translation Quality:** 0.874 (average of all 7 sections)

## Citation

```bibtex
@inproceedings{wang2021codet5,
  title={CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation},
  author={Wang, Yue and Wang, Weishi and Joty, Shafiq and Hoi, Steven C.H.},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2021}
}
```

## Translation Team
- Translator: Claude Code Session 2025-11-16
- Reviewer: TBD
- Started: 2025-11-16
- Completed: 2025-11-16

## Translation Statistics
- Total sections: 7
- Total pages: ~13 (original PDF)
- Translation time: Single session
- Average quality score: 0.874
- All sections meet quality threshold (≥0.85): ✓
