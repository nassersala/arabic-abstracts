# Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks
## الترجمة غير المقترنة من صورة إلى صورة باستخدام الشبكات التنافسية ذات الاتساق الدوري

**arXiv ID:** 1703.10593
**Authors:** Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros
**Year:** 2017
**Publication:** IEEE International Conference on Computer Vision (ICCV) 2017
**Categories:** cs.CV (Computer Vision and Pattern Recognition)
**DOI:** https://doi.org/10.48550/arXiv.1703.10593
**PDF:** https://arxiv.org/pdf/1703.10593.pdf

**Abstract Translation Quality:** 0.92
**Full Paper Translation Quality:** 0.886

## Citation

```bibtex
@InProceedings{CycleGAN2017,
  title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  year={2017}
}
```

## Translation Team
- Translator: Claude (Sonnet 4.5)
- Reviewer: TBD
- Started: 2025-11-15
- Completed: 2025-11-15

## Paper Overview

This seminal paper introduces CycleGAN, a method for learning image-to-image translation between two domains without paired training examples. The key innovation is the cycle consistency loss, which ensures that translating an image from domain X to Y and back to X returns the original image. The method has been widely influential in computer vision, with applications in style transfer, object transfiguration, season transfer, and photo enhancement.

**Key Contributions:**
1. A method for unpaired image-to-image translation using cycle-consistent adversarial networks
2. Introduction of cycle consistency loss to constrain the mapping
3. Extensive qualitative and quantitative evaluation on multiple tasks
4. Open-source implementation that has become widely adopted

**Pages:** 18
**Figures:** Multiple (including architecture diagrams and extensive visual results)
**Citations:** 10,000+ (highly influential paper)
