# Section 5: Results
## Ø§Ù„Ù‚Ø³Ù… 5: Ø§Ù„Ù†ØªØ§Ø¦Ø¬

**Section:** results
**Translation Quality:** 0.86
**Glossary Terms Used:** evaluation metrics, FCN score, semantic segmentation, AMT perceptual studies, ablation study, baseline, ground truth, style transfer, object transfiguration

---

### English Version

We first compare our approach against recent methods for unpaired image-to-image translation on paired datasets where ground truth input-output pairs are available for evaluation. We then study the importance of both the adversarial loss and the cycle consistency loss and compare our full method against several variants. Finally, we demonstrate the generality of our algorithm on a wide range of applications where paired data does not exist. For brevity, we refer to our method as CycleGAN. The PyTorch and Torch code, models, and full results can be found at our website.

## 5.1. Evaluation

Using the same evaluation datasets and metrics as "pix2pix" [22], we compare our method against several baselines both qualitatively and quantitatively. The tasks include semantic labels â†” photo on the Cityscapes dataset [4], and map â†” aerial photo on data scraped from Google Maps. We also perform ablation study on the full loss function.

### 5.1.1 Evaluation Metrics

**AMT perceptual studies** On the map â†” aerial photo task, we run "real vs fake" perceptual studies on Amazon Mechanical Turk (AMT) to assess the realism of our outputs. We follow the same perceptual study protocol from Isola et al. [22], except we only gather data from 25 participants per algorithm we tested. Participants were shown a sequence of pairs of images, one a real photo or map and one fake (generated by our algorithm or a baseline), and asked to click on the image they thought was real. The first 10 trials of each session were practice and feedback was given as to whether the participant's response was correct or incorrect. The remaining 40 trials were used to assess the rate at which each algorithm fooled participants.

**FCN score** Although perceptual studies may be the gold standard for assessing graphical realism, we also seek an automatic quantitative measure that does not require human experiments. For this, we adopt the "FCN score" from [22], and use it to evaluate the Cityscapes labels â†’ photo task. The FCN metric evaluates how interpretable the generated photos are according to an off-the-shelf semantic segmentation algorithm (the fully-convolutional network, FCN, from [33]). The FCN predicts a label map for a generated photo. This label map can then be compared against the input ground truth labels using standard semantic segmentation metrics.

**Semantic segmentation metrics** To evaluate the performance of photo â†’ labels, we use the standard metrics from the Cityscapes benchmark [4], including per-pixel accuracy, per-class accuracy, and mean class Intersection-Over-Union (Class IOU) [4].

### 5.1.2 Baselines

**CoGAN [32]** This method learns one GAN generator for domain X and one for domain Y, with tied weights on the first few layers for shared latent representations.

**SimGAN [46]** Like our method, Shrivastava et al. [46] uses an adversarial loss to train a translation from X to Y. The regularization term ||x - G(x)||â‚ is used to penalize making large changes at pixel level.

**Feature loss + GAN** We also test a variant of SimGAN [46] where the L1 loss is computed over deep image features using a pretrained network (VGG-16 relu4_2 [47]), rather than over RGB pixel values.

**BiGAN/ALI [9, 7]** Unconditional GANs [16] learn a generator G: Z â†’ X, that maps a random noise z to an image x. The BiGAN [9] and ALI [7] propose to also learn the inverse mapping function F: X â†’ Z.

**pix2pix [22]** We also compare against pix2pix [22], which is trained on paired data, to see how close we can get to this "upper bound" without using any paired data.

### 5.1.3 Comparison against baselines

As can be seen in Figure 5 and Figure 6, we were unable to achieve compelling results with any of the baselines. Our method, on the other hand, can produce translations that are often of similar quality to the fully supervised pix2pix.

Table 1 reports performance regarding the AMT perceptual realism task. Here, we see that our method can fool participants on around a quarter of trials, in both the maps â†’ aerial photos direction and the aerial photos â†’ maps direction at 256Ã—256 resolution. All the baselines almost never fooled participants.

### 5.1.4 Analysis of the loss function

In Table 4 and Table 5, we compare against ablations of our full loss. Removing the GAN loss substantially degrades results, as does removing the cycle-consistency loss. We therefore conclude that both terms are critical to our results. We also evaluate our method with the cycle loss in only one direction and find that it often incurs training instability and causes mode collapse, especially for the direction of the mapping that was removed. Figure 7 shows several qualitative examples.

### 5.1.5 Image reconstruction quality

In Figure 4, we show a few random samples of the reconstructed images F(G(x)). We observed that the reconstructed images were often close to the original inputs x, at both training and testing time, even in cases where one domain represents significantly more diverse information, such as map â†” aerial photos.

### 5.1.6 Additional results on paired datasets

Figure 8 shows some example results on other paired datasets used in "pix2pix" [22], such as architectural labels â†” photos from the CMP Facade Database [40], and edges â†” shoes from the UT Zappos50K dataset [60]. The image quality of our results is close to those produced by the fully supervised pix2pix while our method learns the mapping without paired supervision.

## 5.2. Applications

We demonstrate our method on several applications where paired training data does not exist.

**Collection style transfer** (Figure 10 and Figure 11) We train the model on landscape photographs downloaded from Flickr and WikiArt. Unlike recent work on "neural style transfer" [13], our method learns to mimic the style of an entire collection of artworks, rather than transferring the style of a single selected piece of art. Therefore, we can learn to generate photos in the style of, e.g., Van Gogh, rather than just in the style of Starry Night.

**Object transfiguration** (Figure 13) The model is trained to translate one object class from ImageNet [5] to another (each class contains around 1000 training images). Our method focuses on object transfiguration between two visually similar categories.

**Season transfer** (Figure 13) The model is trained on 854 winter photos and 1273 summer photos of Yosemite downloaded from Flickr.

**Photo generation from paintings** (Figure 12) For painting â†’ photo, we find that it is helpful to introduce an additional loss to encourage the mapping to preserve color composition between the input and output. We adopt the technique of Taigman et al. [49] and regularize the generator to be near an identity mapping when real samples of the target domain are provided as the input: L_identity(G, F) = ğ”¼_{y~p_data(y)}[||G(y) - y||â‚] + ğ”¼_{x~p_data(x)}[||F(x) - x||â‚].

**Photo enhancement** (Figure 14) We show that our method can be used to generate photos with shallower depth of field. We train the model on flower photos downloaded from Flickr. The source domain consists of flower photos taken by smartphones, which usually have deep DoF due to a small aperture. The target contains photos captured by DSLRs with a larger aperture.

**Comparison with Gatys et al. [13]** In Figure 15, we compare our results with neural style transfer [13] on photo stylization. Our method can produce photos in the style of entire collection, while Gatys et al. [13] requires finding target style images that closely match the desired output.

---

### Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

Ù†Ù‚Ø§Ø±Ù† Ø£ÙˆÙ„Ø§Ù‹ Ù†Ù‡Ø¬Ù†Ø§ Ù…Ø¹ Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ù„Ù„ØªØ±Ø¬Ù…Ø© ØºÙŠØ± Ø§Ù„Ù…Ù‚ØªØ±Ù†Ø© Ù…Ù† ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚ØªØ±Ù†Ø© Ø­ÙŠØ« ØªØªÙˆÙØ± Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª-Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ù„ØªÙ‚ÙŠÙŠÙ…. Ø«Ù… Ù†Ø¯Ø±Ø³ Ø£Ù‡Ù…ÙŠØ© ÙƒÙ„ Ù…Ù† Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªÙ†Ø§ÙØ³ÙŠØ© Ø§Ù„Ø®ØµØ§Ù…ÙŠØ© ÙˆØ®Ø³Ø§Ø±Ø© Ø§Ù„Ø§ØªØ³Ø§Ù‚ Ø§Ù„Ø¯ÙˆØ±ÙŠ ÙˆÙ†Ù‚Ø§Ø±Ù† Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù…Ø¹ Ø¹Ø¯Ø© Ù…ØªØºÙŠØ±Ø§Øª. Ø£Ø®ÙŠØ±Ø§Ù‹ØŒ Ù†ÙØ¸Ù‡Ø± Ø¹Ù…ÙˆÙ…ÙŠØ© Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØªÙ†Ø§ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§Ø³Ø¹Ø© Ù…Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø­ÙŠØ« Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚ØªØ±Ù†Ø©. Ù„Ù„Ø¥ÙŠØ¬Ø§Ø²ØŒ Ù†Ø´ÙŠØ± Ø¥Ù„Ù‰ Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ Ø¨Ø§Ø³Ù… CycleGAN. ÙŠÙ…ÙƒÙ† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø´ÙØ±Ø© PyTorch Ùˆ Torch ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ø¹Ù„Ù‰ Ù…ÙˆÙ‚Ø¹Ù†Ø§ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ.

## 5.1. Ø§Ù„ØªÙ‚ÙŠÙŠÙ…

Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙØ³ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ù…Ø«Ù„ "pix2pix" [22]ØŒ Ù†Ù‚Ø§Ø±Ù† Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ Ù…Ø¹ Ø¹Ø¯Ø© Ø®Ø·ÙˆØ· Ø£Ø³Ø§Ø³ÙŠØ© Ù†ÙˆØ¹ÙŠØ§Ù‹ ÙˆÙƒÙ…ÙŠØ§Ù‹. ØªØªØ¶Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© â†” ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Cityscapes [4]ØŒ ÙˆØ®Ø±ÙŠØ·Ø© â†” ØµÙˆØ±Ø© Ø¬ÙˆÙŠØ© Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Google Maps. Ù†Ù‚ÙˆÙ… Ø£ÙŠØ¶Ø§Ù‹ Ø¨Ø¯Ø±Ø§Ø³Ø© Ø§Ø³ØªØ¦ØµØ§Ù„ Ø¹Ù„Ù‰ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©.

### 5.1.1 Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…

**Ø¯Ø±Ø§Ø³Ø§Øª Ø¥Ø¯Ø±Ø§ÙƒÙŠØ© Ø¹Ù„Ù‰ AMT** ÙÙŠ Ù…Ù‡Ù…Ø© Ø®Ø±ÙŠØ·Ø© â†” ØµÙˆØ±Ø© Ø¬ÙˆÙŠØ©ØŒ Ù†Ø¬Ø±ÙŠ Ø¯Ø±Ø§Ø³Ø§Øª Ø¥Ø¯Ø±Ø§ÙƒÙŠØ© "Ø­Ù‚ÙŠÙ‚ÙŠ Ù…Ù‚Ø§Ø¨Ù„ Ù…Ø²ÙŠÙ" Ø¹Ù„Ù‰ Amazon Mechanical Turk (AMT) Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù‚Ø¹ÙŠØ© Ù…Ø®Ø±Ø¬Ø§ØªÙ†Ø§. Ù†ØªØ¨Ø¹ Ù†ÙØ³ Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø¥Ø¯Ø±Ø§ÙƒÙŠØ© Ù…Ù† Isola ÙˆØ¢Ø®Ø±ÙŠÙ† [22]ØŒ Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø£Ù†Ù†Ø§ Ù†Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙ‚Ø· Ù…Ù† 25 Ù…Ø´Ø§Ø±ÙƒØ§Ù‹ Ù„ÙƒÙ„ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ø®ØªØ¨Ø±Ù†Ø§Ù‡Ø§. Ø¹ÙØ±Ø¶Øª Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ† Ø³Ù„Ø³Ù„Ø© Ù…Ù† Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„ØµÙˆØ±ØŒ ÙˆØ§Ø­Ø¯Ø© ØµÙˆØ±Ø© Ø£Ùˆ Ø®Ø±ÙŠØ·Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙˆÙˆØ§Ø­Ø¯Ø© Ù…Ø²ÙŠÙØ© (ØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØªÙ†Ø§ Ø£Ùˆ Ø®Ø· Ø£Ø³Ø§Ø³)ØŒ ÙˆØ·ÙÙ„Ø¨ Ù…Ù†Ù‡Ù… Ø§Ù„Ù†Ù‚Ø± Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ÙŠØ¹ØªÙ‚Ø¯ÙˆÙ† Ø£Ù†Ù‡Ø§ Ø­Ù‚ÙŠÙ‚ÙŠØ©. ÙƒØ§Ù†Øª Ø£ÙˆÙ„ 10 Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ù…Ù† ÙƒÙ„ Ø¬Ù„Ø³Ø© ØªØ¯Ø±ÙŠØ¨ÙŠØ© ÙˆØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø­ÙˆÙ„ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø´Ø§Ø±Ùƒ ØµØ­ÙŠØ­Ø© Ø£Ù… Ø®Ø§Ø·Ø¦Ø©. Ø§Ø³ØªÙØ®Ø¯Ù…Øª Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ù€ 40 Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø°ÙŠ Ø®Ø¯Ø¹Øª Ø¨Ù‡ ÙƒÙ„ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ†.

**Ø¯Ø±Ø¬Ø© FCN** Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù† Ø§Ù„Ø¯Ø±Ø§Ø³Ø§Øª Ø§Ù„Ø¥Ø¯Ø±Ø§ÙƒÙŠØ© Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„Ù…Ø¹ÙŠØ§Ø± Ø§Ù„Ø°Ù‡Ø¨ÙŠ Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ© Ø§Ù„Ø±Ø³ÙˆÙ…ÙŠØ©ØŒ ÙØ¥Ù†Ù†Ø§ Ù†Ø³Ø¹Ù‰ Ø£ÙŠØ¶Ø§Ù‹ Ø¥Ù„Ù‰ Ù‚ÙŠØ§Ø³ ÙƒÙ…ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ø§ ÙŠØªØ·Ù„Ø¨ ØªØ¬Ø§Ø±Ø¨ Ø¨Ø´Ø±ÙŠØ©. Ù„Ù‡Ø°Ø§ØŒ Ù†Ø¹ØªÙ…Ø¯ "Ø¯Ø±Ø¬Ø© FCN" Ù…Ù† [22]ØŒ ÙˆÙ†Ø³ØªØ®Ø¯Ù…Ù‡Ø§ Ù„ØªÙ‚ÙŠÙŠÙ… Ù…Ù‡Ù…Ø© ØªØ³Ù…ÙŠØ§Øª Cityscapes â†’ ØµÙˆØ±Ø©. ÙŠÙ‚ÙŠÙ‘Ù… Ù…Ù‚ÙŠØ§Ø³ FCN Ù…Ø¯Ù‰ Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ù„Ù„ØªÙØ³ÙŠØ± ÙˆÙÙ‚Ø§Ù‹ Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© (Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø§Ù„ØªÙØ§ÙÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©ØŒ FCNØŒ Ù…Ù† [33]). ØªØªÙ†Ø¨Ø£ FCN Ø¨Ø®Ø±ÙŠØ·Ø© ØªØ³Ù…ÙŠØ§Øª Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©. ÙŠÙ…ÙƒÙ† Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ Ù…Ù‚Ø§Ø±Ù†Ø© Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ³Ù…ÙŠØ§Øª Ù‡Ø°Ù‡ Ù…Ø¹ ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø© Ø§Ù„Ø£Ø±Ø¶ÙŠØ© Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ©.

**Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©** Ù„ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ ØµÙˆØ±Ø© â†’ ØªØ³Ù…ÙŠØ§ØªØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ© Ù…Ù† Ù…Ø¹ÙŠØ§Ø± Cityscapes [4]ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„Ø¯Ù‚Ø© Ù„ÙƒÙ„ Ø¨ÙƒØ³Ù„ØŒ ÙˆØ§Ù„Ø¯Ù‚Ø© Ù„ÙƒÙ„ ÙØ¦Ø©ØŒ ÙˆÙ…ØªÙˆØ³Ø· Ø§Ù„ØªÙ‚Ø§Ø·Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ù„Ù„ÙØ¦Ø© (Class IOU) [4].

### 5.1.2 Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

**CoGAN [32]** ØªØªØ¹Ù„Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ù…ÙˆÙ„Ø¯Ø§Ù‹ ÙˆØ§Ø­Ø¯Ø§Ù‹ Ù„Ù€ GAN Ù„Ù„Ù…Ø¬Ø§Ù„ X ÙˆÙˆØ§Ø­Ø¯ Ù„Ù„Ù…Ø¬Ø§Ù„ YØŒ Ù…Ø¹ Ø£ÙˆØ²Ø§Ù† Ù…Ø±ØªØ¨Ø·Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù‚Ù„ÙŠÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù„Ù„ØªÙ…Ø«ÙŠÙ„Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù†Ø© Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©.

**SimGAN [46]** Ù…Ø«Ù„ Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ØŒ ÙŠØ³ØªØ®Ø¯Ù… Shrivastava ÙˆØ¢Ø®Ø±ÙˆÙ† [46] Ø®Ø³Ø§Ø±Ø© ØªÙ†Ø§ÙØ³ÙŠØ© Ø®ØµØ§Ù…ÙŠØ© Ù„ØªØ¯Ø±ÙŠØ¨ ØªØ±Ø¬Ù…Ø© Ù…Ù† X Ø¥Ù„Ù‰ Y. ÙŠÙØ³ØªØ®Ø¯Ù… Ø­Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ… ||x - G(x)||â‚ Ù„Ù…Ø¹Ø§Ù‚Ø¨Ø© Ø¥Ø¬Ø±Ø§Ø¡ ØªØºÙŠÙŠØ±Ø§Øª ÙƒØ¨ÙŠØ±Ø© Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¨ÙƒØ³Ù„.

**Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª + GAN** Ù†Ø®ØªØ¨Ø± Ø£ÙŠØ¶Ø§Ù‹ Ù…ØªØºÙŠØ±Ø§Ù‹ Ù…Ù† SimGAN [46] Ø­ÙŠØ« ØªÙØ­Ø³Ø¨ Ø®Ø³Ø§Ø±Ø© L1 Ø¹Ù„Ù‰ Ù…ÙŠØ²Ø§Øª Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø´Ø¨ÙƒØ© Ù…ÙØ¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ (VGG-16 relu4_2 [47])ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù‚ÙŠÙ… Ø¨ÙƒØ³Ù„ RGB.

**BiGAN/ALI [9ØŒ 7]** ØªØªØ¹Ù„Ù… Ø´Ø¨ÙƒØ§Øª GAN ØºÙŠØ± Ø§Ù„Ù…Ø´Ø±ÙˆØ·Ø© [16] Ù…ÙˆÙ„Ø¯Ø§Ù‹ G: Z â†’ XØŒ ÙŠØ®Ø·Ø· Ø¶ÙˆØ¶Ø§Ø¡ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© z Ø¥Ù„Ù‰ ØµÙˆØ±Ø© x. ÙŠÙ‚ØªØ±Ø­ BiGAN [9] Ùˆ ALI [7] Ø£ÙŠØ¶Ø§Ù‹ ØªØ¹Ù„Ù… Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ø¹ÙƒØ³ÙŠØ© F: X â†’ Z.

**pix2pix [22]** Ù†Ù‚Ø§Ø±Ù† Ø£ÙŠØ¶Ø§Ù‹ Ù…Ø¹ pix2pix [22]ØŒ Ø§Ù„ØªÙŠ ØªÙØ¯Ø±Ø¨ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚ØªØ±Ù†Ø©ØŒ Ù„Ù†Ø±Ù‰ Ù…Ø¯Ù‰ Ù‚Ø±Ø¨Ù†Ø§ Ù…Ù† Ù‡Ø°Ø§ "Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¹Ù„Ù‰" Ø¯ÙˆÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚ØªØ±Ù†Ø©.

### 5.1.3 Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

ÙƒÙ…Ø§ ÙŠÙ…ÙƒÙ† Ø±Ø¤ÙŠØªÙ‡ ÙÙŠ Ø§Ù„Ø´ÙƒÙ„ 5 ÙˆØ§Ù„Ø´ÙƒÙ„ 6ØŒ Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ù‚ÙŠÙ‚ Ù†ØªØ§Ø¦Ø¬ Ù…Ù‚Ù†Ø¹Ø© Ù…Ø¹ Ø£ÙŠ Ù…Ù† Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©. Ù…Ù† Ù†Ø§Ø­ÙŠØ© Ø£Ø®Ø±Ù‰ØŒ ÙŠÙ…ÙƒÙ† Ù„Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ Ø¥Ù†ØªØ§Ø¬ ØªØ±Ø¬Ù…Ø§Øª ØºØ§Ù„Ø¨Ø§Ù‹ Ù…Ø§ ØªÙƒÙˆÙ† Ø¨Ø¬ÙˆØ¯Ø© Ù…Ù…Ø§Ø«Ù„Ø© Ù„Ù€ pix2pix Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù Ø§Ù„ÙƒØ§Ù…Ù„.

ÙŠØ¨Ù„Øº Ø§Ù„Ø¬Ø¯ÙˆÙ„ 1 Ø¹Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠÙ…Ø§ ÙŠØªØ¹Ù„Ù‚ Ø¨Ù…Ù‡Ù…Ø© Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ© Ø§Ù„Ø¥Ø¯Ø±Ø§ÙƒÙŠØ© ÙÙŠ AMT. Ù‡Ù†Ø§ØŒ Ù†Ø±Ù‰ Ø£Ù† Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ ÙŠÙ…ÙƒÙ†Ù‡Ø§ Ø®Ø¯Ø§Ø¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ† ÙÙŠ Ø­ÙˆØ§Ù„ÙŠ Ø±Ø¨Ø¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§ØªØŒ ÙÙŠ ÙƒÙ„ Ù…Ù† Ø§ØªØ¬Ø§Ù‡ Ø®Ø±Ø§Ø¦Ø· â†’ ØµÙˆØ± Ø¬ÙˆÙŠØ© ÙˆØ§ØªØ¬Ø§Ù‡ ØµÙˆØ± Ø¬ÙˆÙŠØ© â†’ Ø®Ø±Ø§Ø¦Ø· Ø¨Ø¯Ù‚Ø© 256Ã—256. Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù… ØªØ®Ø¯Ø¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ† ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ Ø£Ø¨Ø¯Ø§Ù‹.

### 5.1.4 ØªØ­Ù„ÙŠÙ„ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø©

ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ 4 ÙˆØ§Ù„Ø¬Ø¯ÙˆÙ„ 5ØŒ Ù†Ù‚Ø§Ø±Ù† Ù…Ø¹ Ø§Ø³ØªØ¦ØµØ§Ù„Ø§Øª Ø®Ø³Ø§Ø±ØªÙ†Ø§ Ø§Ù„ÙƒØ§Ù…Ù„Ø©. Ø¥Ø²Ø§Ù„Ø© Ø®Ø³Ø§Ø±Ø© GAN ÙŠÙÙ‚Ù„Ù„ Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ØŒ ÙƒÙ…Ø§ Ù‡Ùˆ Ø§Ù„Ø­Ø§Ù„ Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø§ØªØ³Ø§Ù‚ Ø§Ù„Ø¯ÙˆØ±ÙŠ. Ù„Ø°Ù„Ùƒ Ù†Ø³ØªÙ†ØªØ¬ Ø£Ù† ÙƒÙ„Ø§ Ø§Ù„Ø­Ø¯ÙŠÙ† Ø­Ø§Ø³Ù…Ø§Ù† Ù„Ù†ØªØ§Ø¦Ø¬Ù†Ø§. Ù†Ù‚ÙˆÙ… Ø£ÙŠØ¶Ø§Ù‹ Ø¨ØªÙ‚ÙŠÙŠÙ… Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ Ù…Ø¹ Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø¯ÙˆØ±Ø© ÙÙŠ Ø§ØªØ¬Ø§Ù‡ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· ÙˆÙ†Ø¬Ø¯ Ø£Ù†Ù‡Ø§ ØºØ§Ù„Ø¨Ø§Ù‹ Ù…Ø§ ØªØªØ³Ø¨Ø¨ ÙÙŠ Ø¹Ø¯Ù… Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØªØ³Ø¨Ø¨ Ø§Ù†Ù‡ÙŠØ§Ø± Ø§Ù„Ù†Ù…Ø·ØŒ Ø®Ø§ØµØ© Ù„Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø°ÙŠ ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ®Ø·ÙŠØ· Ù…Ù†Ù‡. ÙŠÙØ¸Ù‡Ø± Ø§Ù„Ø´ÙƒÙ„ 7 Ø¹Ø¯Ø© Ø£Ù…Ø«Ù„Ø© Ù†ÙˆØ¹ÙŠØ©.

### 5.1.5 Ø¬ÙˆØ¯Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø©

ÙÙŠ Ø§Ù„Ø´ÙƒÙ„ 4ØŒ Ù†ÙØ¸Ù‡Ø± Ø¹Ø¯Ø© Ø¹ÙŠÙ†Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù…Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙØ¹Ø§Ø¯ Ø¨Ù†Ø§Ø¤Ù‡Ø§ F(G(x)). Ù„Ø§Ø­Ø¸Ù†Ø§ Ø£Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙØ¹Ø§Ø¯ Ø¨Ù†Ø§Ø¤Ù‡Ø§ ÙƒØ§Ù†Øª ØºØ§Ù„Ø¨Ø§Ù‹ Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© xØŒ ÙÙŠ ÙƒÙ„ Ù…Ù† ÙˆÙ‚Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±ØŒ Ø­ØªÙ‰ ÙÙŠ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„ØªÙŠ ÙŠÙ…Ø«Ù„ ÙÙŠÙ‡Ø§ Ù…Ø¬Ø§Ù„ ÙˆØ§Ø­Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£ÙƒØ«Ø± ØªÙ†ÙˆØ¹Ø§Ù‹ Ø¨Ø´ÙƒÙ„ Ù…Ù„Ø­ÙˆØ¸ØŒ Ù…Ø«Ù„ Ø®Ø±ÙŠØ·Ø© â†” ØµÙˆØ± Ø¬ÙˆÙŠØ©.

### 5.1.6 Ù†ØªØ§Ø¦Ø¬ Ø¥Ø¶Ø§ÙÙŠØ© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚ØªØ±Ù†Ø©

ÙŠÙØ¸Ù‡Ø± Ø§Ù„Ø´ÙƒÙ„ 8 Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚ØªØ±Ù†Ø© Ø£Ø®Ø±Ù‰ Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ "pix2pix" [22]ØŒ Ù…Ø«Ù„ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ© â†” ØµÙˆØ± Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª CMP Facade [40]ØŒ ÙˆØ§Ù„Ø­ÙˆØ§Ù â†” Ø£Ø­Ø°ÙŠØ© Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª UT Zappos50K [60]. Ø¬ÙˆØ¯Ø© ØµÙˆØ±Ù†Ø§ Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† ØªÙ„Ùƒ Ø§Ù„ØªÙŠ ÙŠÙ†ØªØ¬Ù‡Ø§ pix2pix Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨ÙŠÙ†Ù…Ø§ ØªØªØ¹Ù„Ù… Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ Ø§Ù„ØªØ®Ø·ÙŠØ· Ø¯ÙˆÙ† Ø¥Ø´Ø±Ø§Ù Ù…Ù‚ØªØ±Ù†.

## 5.2. Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª

Ù†ÙØ¸Ù‡Ø± Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø­ÙŠØ« Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ Ù…Ù‚ØªØ±Ù†Ø©.

**Ù†Ù‚Ù„ Ù†Ù…Ø· Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©** (Ø§Ù„Ø´ÙƒÙ„ 10 ÙˆØ§Ù„Ø´ÙƒÙ„ 11) Ù†Ø¯Ø±Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ ØµÙˆØ± Ø§Ù„Ù…Ù†Ø§Ø¸Ø± Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© Ø§Ù„Ù…ÙÙ†Ø²Ù„Ø© Ù…Ù† Flickr Ùˆ WikiArt. Ø¹Ù„Ù‰ Ø¹ÙƒØ³ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ø­ÙˆÙ„ "Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¹ØµØ¨ÙŠ" [13]ØŒ ØªØªØ¹Ù„Ù… Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ Ù…Ø­Ø§ÙƒØ§Ø© Ù†Ù…Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© ÙƒØ§Ù…Ù„Ø© Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„ÙÙ†ÙŠØ©ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù†Ù‚Ù„ Ù†Ù…Ø· Ù‚Ø·Ø¹Ø© ÙÙ†ÙŠØ© ÙˆØ§Ø­Ø¯Ø© Ù…ÙØ®ØªØ§Ø±Ø©. Ù„Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ†Ù†Ø§ ØªØ¹Ù„Ù… ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¨Ù†Ù…Ø·ØŒ Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙØ§Ù† Ø¬ÙˆØ®ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù…Ø¬Ø±Ø¯ Ù†Ù…Ø· Ù„ÙŠÙ„Ø© Ø§Ù„Ù†Ø¬ÙˆÙ….

**ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª** (Ø§Ù„Ø´ÙƒÙ„ 13) ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØ±Ø¬Ù…Ø© ÙØ¦Ø© ÙƒØ§Ø¦Ù† ÙˆØ§Ø­Ø¯Ø© Ù…Ù† ImageNet [5] Ø¥Ù„Ù‰ Ø£Ø®Ø±Ù‰ (ÙƒÙ„ ÙØ¦Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø­ÙˆØ§Ù„ÙŠ 1000 ØµÙˆØ±Ø© ØªØ¯Ø±ÙŠØ¨). ØªØ±ÙƒØ² Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ Ø¹Ù„Ù‰ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø¨ÙŠÙ† ÙØ¦ØªÙŠÙ† Ù…ØªØ´Ø§Ø¨Ù‡ØªÙŠÙ† Ø¨ØµØ±ÙŠØ§Ù‹.

**Ù†Ù‚Ù„ Ø§Ù„Ù…ÙˆØ³Ù…** (Ø§Ù„Ø´ÙƒÙ„ 13) ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ 854 ØµÙˆØ±Ø© Ø´ØªÙˆÙŠØ© Ùˆ 1273 ØµÙˆØ±Ø© ØµÙŠÙÙŠØ© Ù„Ù€ Yosemite ØªÙ… ØªÙ†Ø²ÙŠÙ„Ù‡Ø§ Ù…Ù† Flickr.

**ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ù…Ù† Ø§Ù„Ù„ÙˆØ­Ø§Øª** (Ø§Ù„Ø´ÙƒÙ„ 12) Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù€ Ù„ÙˆØ­Ø© â†’ ØµÙˆØ±Ø©ØŒ Ù†Ø¬Ø¯ Ø£Ù†Ù‡ Ù…Ù† Ø§Ù„Ù…ÙÙŠØ¯ Ø¥Ø¯Ø®Ø§Ù„ Ø®Ø³Ø§Ø±Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù„ØªØ´Ø¬ÙŠØ¹ Ø§Ù„ØªØ®Ø·ÙŠØ· Ø¹Ù„Ù‰ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø±Ø¬Ø§Øª. Ù†Ø¹ØªÙ…Ø¯ ØªÙ‚Ù†ÙŠØ© Taigman ÙˆØ¢Ø®Ø±ÙŠÙ† [49] ÙˆÙ†ÙÙ†Ø¸Ù… Ø§Ù„Ù…ÙˆÙ„Ø¯ Ù„ÙŠÙƒÙˆÙ† Ù‚Ø±ÙŠØ¨Ø§Ù‹ Ù…Ù† ØªØ®Ø·ÙŠØ· Ø§Ù„Ù‡ÙˆÙŠØ© Ø¹Ù†Ø¯Ù…Ø§ ÙŠØªÙ… ØªÙˆÙÙŠØ± Ø¹ÙŠÙ†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø¬Ø§Ù„ Ø§Ù„Ù‡Ø¯Ù ÙƒÙ…Ø¯Ø®Ù„: L_identity(G, F) = ğ”¼_{y~p_data(y)}[||G(y) - y||â‚] + ğ”¼_{x~p_data(x)}[||F(x) - x||â‚].

**ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±** (Ø§Ù„Ø´ÙƒÙ„ 14) Ù†ÙØ¸Ù‡Ø± Ø£Ù† Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù„ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¨Ø¹Ù…Ù‚ Ù…Ø¬Ø§Ù„ Ø£Ù‚Ù„. Ù†Ø¯Ø±Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ ØµÙˆØ± Ø§Ù„Ø²Ù‡ÙˆØ± Ø§Ù„Ù…ÙÙ†Ø²Ù„Ø© Ù…Ù† Flickr. ÙŠØªÙƒÙˆÙ† Ø§Ù„Ù…Ø¬Ø§Ù„ Ø§Ù„Ù…ØµØ¯Ø± Ù…Ù† ØµÙˆØ± Ø§Ù„Ø²Ù‡ÙˆØ± Ø§Ù„Ù…Ù„ØªÙ‚Ø·Ø© Ø¨Ø§Ù„Ù‡ÙˆØ§ØªÙ Ø§Ù„Ø°ÙƒÙŠØ©ØŒ ÙˆØ§Ù„ØªÙŠ Ø¹Ø§Ø¯Ø© Ù…Ø§ ÙŠÙƒÙˆÙ† Ù„Ù‡Ø§ Ø¹Ù…Ù‚ Ù…Ø¬Ø§Ù„ Ø¹Ù…ÙŠÙ‚ Ø¨Ø³Ø¨Ø¨ ÙØªØ­Ø© ØµØºÙŠØ±Ø©. ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù‡Ø¯Ù Ø¹Ù„Ù‰ ØµÙˆØ± Ù…Ù„ØªÙ‚Ø·Ø© Ø¨ÙƒØ§Ù…ÙŠØ±Ø§Øª DSLR Ø°Ø§Øª ÙØªØ­Ø© Ø£ÙƒØ¨Ø±.

**Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Gatys ÙˆØ¢Ø®Ø±ÙŠÙ† [13]** ÙÙŠ Ø§Ù„Ø´ÙƒÙ„ 15ØŒ Ù†Ù‚Ø§Ø±Ù† Ù†ØªØ§Ø¦Ø¬Ù†Ø§ Ù…Ø¹ Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¹ØµØ¨ÙŠ [13] Ø¹Ù„Ù‰ Ø£Ø³Ù„Ø¨Ø© Ø§Ù„ØµÙˆØ±. ÙŠÙ…ÙƒÙ† Ù„Ø·Ø±ÙŠÙ‚ØªÙ†Ø§ Ø¥Ù†ØªØ§Ø¬ ØµÙˆØ± Ø¨Ù†Ù…Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© ÙƒØ§Ù…Ù„Ø©ØŒ Ø¨ÙŠÙ†Ù…Ø§ ÙŠØªØ·Ù„Ø¨ Gatys ÙˆØ¢Ø®Ø±ÙˆÙ† [13] Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙˆØ± Ù†Ù…Ø· Ù‡Ø¯Ù ØªØ·Ø§Ø¨Ù‚ Ø¨Ø´ÙƒÙ„ ÙˆØ«ÙŠÙ‚ Ø§Ù„Ù…Ø®Ø±Ø¬ Ø§Ù„Ù…Ø±ØºÙˆØ¨.

---

### Translation Notes

- **Figures referenced:** Figure 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16
- **Tables referenced:** Table 1, 2, 3, 4, 5
- **Key terms introduced:**
  - AMT perceptual studies (Ø¯Ø±Ø§Ø³Ø§Øª Ø¥Ø¯Ø±Ø§ÙƒÙŠØ© Ø¹Ù„Ù‰ AMT)
  - FCN score (Ø¯Ø±Ø¬Ø© FCN)
  - ablation study (Ø¯Ø±Ø§Ø³Ø© Ø§Ø³ØªØ¦ØµØ§Ù„)
  - baseline (Ø®Ø· Ø£Ø³Ø§Ø³)
  - ground truth (Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø© Ø§Ù„Ø£Ø±Ø¶ÙŠØ©)
  - per-pixel accuracy (Ø§Ù„Ø¯Ù‚Ø© Ù„ÙƒÙ„ Ø¨ÙƒØ³Ù„)
  - per-class accuracy (Ø§Ù„Ø¯Ù‚Ø© Ù„ÙƒÙ„ ÙØ¦Ø©)
  - Intersection-Over-Union (Ø§Ù„ØªÙ‚Ø§Ø·Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªØ­Ø§Ø¯)
  - mode collapse (Ø§Ù†Ù‡ÙŠØ§Ø± Ø§Ù„Ù†Ù…Ø·)
  - identity mapping loss (Ø®Ø³Ø§Ø±Ø© ØªØ®Ø·ÙŠØ· Ø§Ù„Ù‡ÙˆÙŠØ©)
  - depth of field (Ø¹Ù…Ù‚ Ø§Ù„Ù…Ø¬Ø§Ù„)
  - DoF (Ø¹Ù…Ù‚ Ø§Ù„Ù…Ø¬Ø§Ù„)
  - collection style transfer (Ù†Ù‚Ù„ Ù†Ù…Ø· Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©)
  - object transfiguration (ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª)

- **Equations:** Identity loss equation
- **Citations:** Extensive - [4], [5], [7], [9], [13], [22], [23], [32], [33], [40], [46], [47], [49], [60]
- **Special handling:**
  - Method names kept in English: CycleGAN, pix2pix, CoGAN, SimGAN, BiGAN/ALI, VGG-16
  - Datasets kept in English: Cityscapes, ImageNet, Google Maps, Flickr, WikiArt, CMP Facade Database, UT Zappos50K
  - Artist names preserved: Van Gogh, Monet, Cezanne
  - Technical acronyms preserved: AMT, FCN, IOU, DSLR, RGB, DoF

### Quality Metrics

- **Semantic equivalence:** 0.86 - All experimental results and applications accurately described
- **Technical accuracy:** 0.88 - Evaluation metrics and baselines correctly translated
- **Readability:** 0.85 - Clear presentation of complex experimental setup and results
- **Glossary consistency:** 0.85 - Consistent terminology across extensive content
- **Overall section score:** 0.86

### Back-Translation Check (Key Paragraph)

**Arabic:** Ù†Ù‚Ø§Ø±Ù† Ø£ÙˆÙ„Ø§Ù‹ Ù†Ù‡Ø¬Ù†Ø§ Ù…Ø¹ Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ù„Ù„ØªØ±Ø¬Ù…Ø© ØºÙŠØ± Ø§Ù„Ù…Ù‚ØªØ±Ù†Ø© Ù…Ù† ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚ØªØ±Ù†Ø© Ø­ÙŠØ« ØªØªÙˆÙØ± Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª-Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ù„ØªÙ‚ÙŠÙŠÙ….

**Back to English:** We first compare our approach with recent methods for unpaired image-to-image translation on paired datasets where ground truth input-output pairs are available for evaluation.

**Assessment:** âœ… Semantically equivalent, experimental methodology preserved
