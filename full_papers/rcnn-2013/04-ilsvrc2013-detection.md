# Section 4: The ILSVRC2013 detection dataset
## القسم 4: مجموعة بيانات كشف ILSVRC2013

**Section:** ilsvrc2013-detection
**Translation Quality:** 0.86
**Glossary Terms Used:** dataset, detection, region proposals, selective search, fine-tuning, validation, annotation, bounding box, ground truth

---

### English Version

## 4. The ILSVRC2013 detection dataset

In Section 2 we presented results on the ILSVRC2013 detection dataset. This dataset is less homogeneous than PASCAL VOC, requiring choices about how to use it. Since these decisions are non-trivial, we cover them in this section.

### 4.1. Dataset overview

The ILSVRC2013 detection dataset is split into three sets: train (395,918), val (20,121), and test (40,152), where the number of images in each set is in parentheses. The val and test splits are drawn from the same image distribution. These images are scene-like and similar in complexity (number of objects, amount of clutter, pose variability, etc.) to PASCAL VOC images. The val and test splits are exhaustively annotated, meaning that in each image all instances from all 200 classes are labeled with bounding boxes. The train set, in contrast, is drawn from the ILSVRC2013 classification image distribution. These images have more variable complexity with a skew towards images of a single centered object. Unlike val and test, the train images (due to their large number) are not exhaustively annotated. In any given train image, instances from the 200 classes may or may not be labeled. In addition to these image sets, each class has an extra set of negative images. Negative images are manually checked to validate that they do not contain any instances of their associated class. The negative image sets were not used in this work. More information on how ILSVRC was collected and annotated can be found in [11, 36].

The nature of these splits presents a number of choices for training R-CNN. The train images cannot be used for hard negative mining, because annotations are not exhaustive. Where should negative examples come from? Also, the train images have different statistics than val and test. Should the train images be used at all, and if so, to what extent? While we have not thoroughly evaluated a large number of choices, we present what seemed like the most obvious path based on previous experience.

Our general strategy is to rely heavily on the val set and use some of the train images as an auxiliary source of positive examples. To use val for both training and validation, we split it into roughly equally sized "val1" and "val2" sets. Since some classes have very few examples in val (the smallest has only 31 and half have fewer than 110), it is important to produce an approximately class-balanced partition. To do this, a large number of candidate splits were generated and the one with the smallest maximum relative class imbalance was selected. Each candidate split was generated by clustering val images using their class counts as features, followed by a randomized local search that may improve the split balance. The particular split used here has a maximum relative imbalance of about 11% and a median relative imbalance of 4%. The val1/val2 split and code used to produce them will be publicly available to allow other researchers to compare their methods on the val splits used in this report.

### 4.2. Region proposals

We followed the same region proposal approach that was used for detection on PASCAL. Selective search [39] was run in "fast mode" on each image in val1, val2, and test (but not on images in train). One minor modification was required to deal with the fact that selective search is not scale invariant and so the number of regions produced depends on the image resolution. ILSVRC image sizes range from very small to a few that are several mega-pixels, and so we resized each image to a fixed width (500 pixels) before running selective search. On val, selective search resulted in an average of 2403 region proposals per image with a 91.6% recall of all ground-truth bounding boxes (at 0.5 IoU threshold). This recall is notably lower than in PASCAL, where it is approximately 98%, indicating significant room for improvement in the region proposal stage.

### 4.3. Training data

For training data, we formed a set of images and boxes that includes all selective search and ground-truth boxes from val1 together with up to N ground-truth boxes per class from train (if a class has fewer than N ground-truth boxes in train, then we take all of them). We'll call this dataset of images and boxes val1+trainN. In an ablation study, we show mAP on val2 for N ∈ {0, 500, 1000} (Section 4.5).

Training data is required for three procedures in R-CNN: (1) CNN fine-tuning, (2) detector SVM training, and (3) bounding-box regressor training. CNN fine-tuning was run for 50k SGD iteration on val1+trainN using the exact same settings as were used for PASCAL. Fine-tuning on a single NVIDIA Tesla K20 took 13 hours using Caffe. For SVM training, all ground-truth boxes from val1+trainN were used as positive examples for their respective classes. Hard negative mining was performed on a randomly selected subset of 5000 images from val1. An initial experiment indicated that mining negatives from all of val1, versus a 5000 image subset (roughly half of it), resulted in only a 0.5 percentage point drop in mAP, while cutting SVM training time in half. No negative examples were taken from train because the annotations are not exhaustive. The extra sets of verified negative images were not used. The bounding-box regressors were trained on val1.

### 4.4. Validation and evaluation

Before submitting results to the evaluation server, we validated data usage choices and the effect of fine-tuning and bounding-box regression on the val2 set using the training data described above. All system hyperparameters (e.g., SVM C hyperparameters, padding used in region warping, NMS thresholds, bounding-box regression hyperparameters) were fixed at the same values used for PASCAL. Undoubtedly some of these hyperparameter choices are slightly suboptimal for ILSVRC, however the goal of this work was to produce a preliminary R-CNN result on ILSVRC without extensive dataset tuning. After selecting the best choices on val2, we submitted exactly two result files to the ILSVRC2013 evaluation server. The first submission was without bounding-box regression and the second submission was with bounding-box regression. For these submissions, we expanded the SVM and bounding-box regressor training sets to use val+train1k and val, respectively. We used the CNN that was fine-tuned on val1+train1k to avoid re-running fine-tuning and feature computation.

### 4.5. Ablation study

Table 4 shows an ablation study of the effects of different amounts of training data, fine-tuning, and bounding-box regression. A first observation is that mAP on val2 matches mAP on test very closely. This gives us confidence that mAP on val2 is a good indicator of test set performance. The first result, 20.9%, is what R-CNN achieves using a CNN pre-trained on the ILSVRC2012 classification dataset (no fine-tuning) and given access to the small amount of training data in val1 (recall that half of the classes in val1 have between 15 and 55 examples). Expanding the training set to val1+trainN improves performance to 24.1%, with essentially no difference between N=500 and N=1000. Fine-tuning the CNN using examples from just val1 gives a modest improvement to 26.5%, however there is likely significant overfitting due to the small number of positive training examples. Expanding the fine-tuning set to val1+train1k, which adds up to 1000 positive examples per class from the train set, helps significantly, boosting mAP to 29.7%. Bounding-box regression improves results to 31.0%, which is a smaller relative gain that what was observed in PASCAL.

### 4.6. Relationship to OverFeat

There is an interesting relationship between R-CNN and OverFeat: OverFeat can be seen (roughly) as a special case of R-CNN. If one were to replace selective search region proposals with a multi-scale pyramid of regular square regions and change the per-class bounding-box regressors to a single bounding-box regressor, then the systems would be very similar (modulo some potentially significant differences in how they are trained: CNN detection fine-tuning, using SVMs, etc.). It is worth noting that OverFeat has a significant speed advantage over R-CNN: it is about 9x faster, based on a figure of 2 seconds per image quoted from [34]. This speed comes from the fact that OverFeat's sliding windows (i.e., region proposals) are not warped at the image level and therefore computation can be easily shared between overlapping windows. Sharing is implemented by running the entire network in a convolutional fashion over arbitrary-sized inputs. Speeding up R-CNN should be possible in a variety of ways and remains as future work.

---

### النسخة العربية

## 4. مجموعة بيانات كشف ILSVRC2013

في القسم 2 عرضنا النتائج على مجموعة بيانات كشف ILSVRC2013. هذه المجموعة أقل تجانساً من PASCAL VOC، مما يتطلب اختيارات حول كيفية استخدامها. نظراً لأن هذه القرارات ليست تافهة، نغطيها في هذا القسم.

### 4.1. نظرة عامة على مجموعة البيانات

تنقسم مجموعة بيانات كشف ILSVRC2013 إلى ثلاث مجموعات: train (395,918)، وval (20,121)، وtest (40,152)، حيث يكون عدد الصور في كل مجموعة بين قوسين. يتم استخلاص مجموعتي val وtest من نفس توزيع الصور. هذه الصور شبيهة بالمشاهد ومماثلة في التعقيد (عدد الأجسام، كمية الفوضى، تنوع الوضعية، إلخ) لصور PASCAL VOC. مجموعتي val وtest مُشروحتان بشكل شامل، مما يعني أنه في كل صورة يتم تسمية جميع الحالات من جميع الـ 200 صنف بصناديق التحديد. مجموعة train، على النقيض، مستخلصة من توزيع صور تصنيف ILSVRC2013. هذه الصور لها تعقيد أكثر تبايناً مع انحراف نحو صور جسم واحد في المركز. على عكس val وtest، صور train (بسبب عددها الكبير) ليست مُشروحة بشكل شامل. في أي صورة train معينة، قد يتم أو لا يتم تسمية الحالات من 200 صنف. بالإضافة إلى مجموعات الصور هذه، كل صنف لديه مجموعة إضافية من الصور السلبية. يتم فحص الصور السلبية يدوياً للتحقق من أنها لا تحتوي على أي حالات من صنفها المرتبط. لم يتم استخدام مجموعات الصور السلبية في هذا العمل. يمكن العثور على مزيد من المعلومات حول كيفية جمع ILSVRC والتعليق عليها في [11، 36].

تقدم طبيعة هذه الانقسامات عدداً من الخيارات لتدريب R-CNN. لا يمكن استخدام صور train لتعدين السلبيات الصعبة، لأن التعليقات التوضيحية ليست شاملة. من أين يجب أن تأتي الأمثلة السلبية؟ أيضاً، صور train لها إحصائيات مختلفة عن val وtest. هل يجب استخدام صور train على الإطلاق، وإذا كان الأمر كذلك، إلى أي مدى؟ بينما لم نقيّم بدقة عدداً كبيراً من الخيارات، نقدم ما بدا وكأنه المسار الأكثر وضوحاً بناءً على الخبرة السابقة.

استراتيجيتنا العامة هي الاعتماد بشكل كبير على مجموعة val واستخدام بعض صور train كمصدر مساعد للأمثلة الإيجابية. لاستخدام val لكل من التدريب والتحقق، قسمناها إلى مجموعتين "val1" و"val2" متساويتين تقريباً في الحجم. نظراً لأن بعض الأصناف لديها أمثلة قليلة جداً في val (الأصغر لديه 31 فقط ونصفها لديه أقل من 110)، فمن المهم إنتاج تقسيم متوازن تقريباً حسب الصنف. للقيام بذلك، تم إنشاء عدد كبير من التقسيمات المرشحة وتم اختيار التقسيم بأقل عدم توازن نسبي أقصى للصنف. تم إنشاء كل تقسيم مرشح من خلال تجميع صور val باستخدام عدد أصنافها كميزات، يليه بحث محلي عشوائي قد يحسن توازن التقسيم. التقسيم المحدد المستخدم هنا لديه عدم توازن نسبي أقصى حوالي 11% وعدم توازن نسبي متوسط 4%. سيكون تقسيم val1/val2 والشفرة المستخدمة لإنتاجها متاحين للعامة للسماح للباحثين الآخرين بمقارنة طرقهم على تقسيمات val المستخدمة في هذا التقرير.

### 4.2. مقترحات المناطق

اتبعنا نفس نهج مقترحات المناطق الذي استخدم للكشف على PASCAL. تم تشغيل البحث الانتقائي [39] في "الوضع السريع" على كل صورة في val1 وval2 وtest (ولكن ليس على الصور في train). كان مطلوباً تعديل طفيف للتعامل مع حقيقة أن البحث الانتقائي ليس ثابتاً للمقياس وبالتالي يعتمد عدد المناطق المنتجة على دقة الصورة. تتراوح أحجام صور ILSVRC من صغيرة جداً إلى عدد قليل بعدة ميجابكسلات، وبالتالي قمنا بتغيير حجم كل صورة إلى عرض ثابت (500 بكسل) قبل تشغيل البحث الانتقائي. على val، أسفر البحث الانتقائي عن متوسط 2403 مقترح منطقة لكل صورة مع استدعاء 91.6% من جميع صناديق التحديد للحقيقة الأرضية (عند عتبة 0.5 IoU). هذا الاستدعاء أقل بشكل ملحوظ من PASCAL، حيث يبلغ حوالي 98%، مما يشير إلى مجال كبير للتحسين في مرحلة مقترحات المناطق.

### 4.3. بيانات التدريب

لبيانات التدريب، شكّلنا مجموعة من الصور والصناديق التي تتضمن جميع صناديق البحث الانتقائي والحقيقة الأرضية من val1 مع ما يصل إلى N صندوق حقيقة أرضية لكل صنف من train (إذا كان لدى صنف أقل من N صندوق حقيقة أرضية في train، فإننا نأخذها جميعاً). سنطلق على مجموعة البيانات هذه من الصور والصناديق val1+trainN. في دراسة استئصالية، نُظهر mAP على val2 لـ N ∈ {0، 500، 1000} (القسم 4.5).

بيانات التدريب مطلوبة لثلاث إجراءات في R-CNN: (1) الضبط الدقيق للشبكة العصبية الالتفافية، (2) تدريب آلة المتجهات الداعمة للكاشف، و(3) تدريب منحدر صندوق التحديد. تم تشغيل الضبط الدقيق للشبكة العصبية الالتفافية لـ 50 ألف تكرار SGD على val1+trainN باستخدام نفس الإعدادات المستخدمة لـ PASCAL. استغرق الضبط الدقيق على NVIDIA Tesla K20 واحدة 13 ساعة باستخدام Caffe. لتدريب آلة المتجهات الداعمة، تم استخدام جميع صناديق الحقيقة الأرضية من val1+trainN كأمثلة إيجابية لأصنافها المعنية. تم إجراء تعدين السلبيات الصعبة على مجموعة فرعية مختارة عشوائياً من 5000 صورة من val1. أشارت تجربة أولية إلى أن تعدين السلبيات من كل val1، مقابل مجموعة فرعية من 5000 صورة (نصفها تقريباً)، أدى إلى انخفاض 0.5 نقطة مئوية فقط في mAP، بينما قطع وقت تدريب آلة المتجهات الداعمة إلى النصف. لم يتم أخذ أمثلة سلبية من train لأن التعليقات التوضيحية ليست شاملة. لم يتم استخدام المجموعات الإضافية من الصور السلبية المحققة. تم تدريب منحدرات صندوق التحديد على val1.

### 4.4. التحقق والتقييم

قبل تقديم النتائج إلى خادم التقييم، قمنا بالتحقق من خيارات استخدام البيانات وتأثير الضبط الدقيق وانحدار صندوق التحديد على مجموعة val2 باستخدام بيانات التدريب الموصوفة أعلاه. تم تثبيت جميع المعاملات الفائقة للنظام (مثل المعاملات الفائقة C لآلة المتجهات الداعمة، والحشو المستخدم في تشويه المناطق، وعتبات NMS، والمعاملات الفائقة لانحدار صندوق التحديد) بنفس القيم المستخدمة لـ PASCAL. بلا شك بعض هذه الخيارات للمعاملات الفائقة دون المستوى الأمثل قليلاً لـ ILSVRC، ومع ذلك كان الهدف من هذا العمل هو إنتاج نتيجة R-CNN أولية على ILSVRC دون ضبط واسع النطاق لمجموعة البيانات. بعد اختيار الخيارات الأفضل على val2، قدمنا بالضبط ملفي نتائج إلى خادم تقييم ILSVRC2013. التقديم الأول كان بدون انحدار صندوق التحديد والتقديم الثاني كان مع انحدار صندوق التحديد. لهذه التقديمات، قمنا بتوسيع مجموعات تدريب آلة المتجهات الداعمة ومنحدر صندوق التحديد لاستخدام val+train1k وval، على التوالي. استخدمنا الشبكة العصبية الالتفافية التي تم ضبطها بدقة على val1+train1k لتجنب إعادة تشغيل الضبط الدقيق وحساب الميزات.

### 4.5. دراسة استئصالية

يُظهر الجدول 4 دراسة استئصالية لتأثيرات كميات مختلفة من بيانات التدريب، والضبط الدقيق، وانحدار صندوق التحديد. الملاحظة الأولى هي أن mAP على val2 يطابق mAP على test بشكل وثيق جداً. هذا يعطينا ثقة بأن mAP على val2 هو مؤشر جيد لأداء مجموعة الاختبار. النتيجة الأولى، 20.9%، هي ما يحققه R-CNN باستخدام شبكة عصبية التفافية مدربة مسبقاً على مجموعة بيانات تصنيف ILSVRC2012 (بدون ضبط دقيق) ومع إمكانية الوصول إلى كمية صغيرة من بيانات التدريب في val1 (تذكر أن نصف الأصناف في val1 لديها بين 15 و55 مثالاً). توسيع مجموعة التدريب إلى val1+trainN يحسن الأداء إلى 24.1%، مع عدم وجود فرق جوهري بين N=500 وN=1000. الضبط الدقيق للشبكة العصبية الالتفافية باستخدام أمثلة من val1 فقط يعطي تحسناً متواضعاً إلى 26.5%، ومع ذلك من المحتمل أن يكون هناك فرط تدريب كبير بسبب العدد الصغير من الأمثلة التدريبية الإيجابية. توسيع مجموعة الضبط الدقيق إلى val1+train1k، التي تضيف ما يصل إلى 1000 مثال إيجابي لكل صنف من مجموعة train، يساعد بشكل كبير، مما يعزز mAP إلى 29.7%. يحسن انحدار صندوق التحديد النتائج إلى 31.0%، وهو مكسب نسبي أصغر مما لوحظ في PASCAL.

### 4.6. العلاقة مع OverFeat

هناك علاقة مثيرة للاهتمام بين R-CNN وOverFeat: يمكن رؤية OverFeat (تقريباً) كحالة خاصة من R-CNN. إذا كان على المرء استبدال مقترحات مناطق البحث الانتقائي بهرم متعدد المقاييس من المناطق المربعة المنتظمة وتغيير منحدرات صندوق التحديد لكل صنف إلى منحدر صندوق تحديد واحد، فستكون الأنظمة متشابهة جداً (باستثناء بعض الاختلافات المحتملة الهامة في كيفية تدريبها: الضبط الدقيق لكشف الشبكة العصبية الالتفافية، واستخدام آلات المتجهات الداعمة، إلخ). تجدر الإشارة إلى أن OverFeat لديه ميزة سرعة كبيرة على R-CNN: إنه أسرع بحوالي 9 مرات، بناءً على رقم ثانيتين لكل صورة المذكور من [34]. تأتي هذه السرعة من حقيقة أن نوافذ OverFeat المنزلقة (أي، مقترحات المناطق) لا تتشوه على مستوى الصورة وبالتالي يمكن مشاركة الحساب بسهولة بين النوافذ المتداخلة. يتم تنفيذ المشاركة من خلال تشغيل الشبكة بأكملها بطريقة التفافية على مدخلات ذات حجم تعسفي. يجب أن يكون تسريع R-CNN ممكناً بعدة طرق ويبقى كعمل مستقبلي.

---

### Translation Notes

- **Figures referenced:** Table 4 (ablation study results)
- **Key terms introduced:** exhaustive annotation (التعليق الشامل), hard negative mining (تعدين السلبيات الصعبة), class imbalance (عدم توازن الصنف), ablation study (دراسة استئصالية), overfitting (فرط التدريب)
- **Equations:** Set notation N ∈ {0, 500, 1000}
- **Citations:** References [11, 34, 36, 39] cited
- **Special handling:**
  - Preserved dataset split names: train, val, test, val1, val2
  - Maintained notation: val1+trainN, val+train1k
  - Kept percentage values and statistics
  - Preserved hyperparameter details and technical specifications
  - Maintained comparison with OverFeat system

### Quality Metrics

- Semantic equivalence: 0.87
- Technical accuracy: 0.88
- Readability: 0.85
- Glossary consistency: 0.85
- **Overall section score:** 0.86
