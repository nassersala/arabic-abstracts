# Communication-Efficient Learning of Deep Networks from Decentralized Data
## التعلم الفعّال اتصالياً للشبكات العميقة من البيانات اللامركزية

**arXiv ID:** 1602.05629
**Authors:** H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Agüera y Arcas
**Year:** 2016 (submitted February 17, 2016; last revised January 26, 2023)
**Publication:** Proceedings of AISTATS 2017 (20th International Conference on Artificial Intelligence and Statistics)
**Categories:** cs.LG (Machine Learning)
**DOI:** TBD
**PDF:** https://arxiv.org/pdf/1602.05629.pdf

**Abstract Translation Quality:** 0.88 (from translations/)
**Full Paper Translation Quality:** 0.866 (average across all sections)

## Citation

```bibtex
@inproceedings{mcmahan2017communication,
  title={Communication-Efficient Learning of Deep Networks from Decentralized Data},
  author={McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Ag{\"u}era y},
  booktitle={Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  year={2017}
}
```

## Translation Team
- Translator: Claude (Sonnet 4.5)
- Reviewer: TBD
- Started: 2025-11-15
- Completed: 2025-11-15

## Paper Significance

This is the foundational paper that introduced **Federated Learning**, a groundbreaking paradigm for training machine learning models on decentralized data while preserving privacy. The paper has become highly influential in privacy-preserving machine learning, mobile computing, and distributed systems research.
