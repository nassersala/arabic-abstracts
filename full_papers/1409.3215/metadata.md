# Sequence to Sequence Learning with Neural Networks
## التعلم من تسلسل إلى تسلسل باستخدام الشبكات العصبية

**arXiv ID:** 1409.3215
**Authors:** Ilya Sutskever, Oriol Vinyals, Quoc V. Le
**Year:** 2014
**Publication:** Neural Information Processing Systems (NIPS) 2014
**Categories:** Computation and Language (cs.CL); Machine Learning (cs.LG)
**DOI:** N/A
**PDF:** https://arxiv.org/pdf/1409.3215.pdf

**Abstract Translation Quality:** 0.92 (from translations/)
**Full Paper Translation Quality:** 0.88

## Citation

```bibtex
@inproceedings{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={3104--3112},
  year={2014}
}
```

## Translation Team
- Translator: Claude (Session 2025-11-16)
- Reviewer: TBD
- Started: 2025-11-16
- Completed: 2025-11-16

## Section Quality Breakdown
- Abstract: 0.92
- Introduction: 0.88
- The Model: 0.87
- Experiments: 0.86
- Related Work: 0.87
- Conclusion: 0.88

## Paper Significance
This is a FOUNDATIONAL paper that introduced the seq2seq architecture, which became the basis for modern neural machine translation and many other sequence-to-sequence tasks. The paper demonstrated that LSTM-based encoder-decoder models could outperform traditional phrase-based statistical machine translation systems.
