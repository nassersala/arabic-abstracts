# Section 5: Experiments
## القسم 5: التجارب

**Section:** Experiments
**Translation Quality:** 0.87
**Glossary Terms Used:** dataset, rectifier linear activations, sigmoid activations, maxout, dropout, Gaussian Parzen window, log-likelihood, cross validation, generative models

---

### English Version

We trained adversarial nets an a range of datasets including MNIST[23], the Toronto Face Database (TFD) [28], and CIFAR-10 [21]. The generator nets used a mixture of rectifier linear activations [19, 9] and sigmoid activations, while the discriminator net used maxout [10] activations. Dropout [17] was applied in training the discriminator net. While our theoretical framework permits the use of dropout and other noise at intermediate layers of the generator, we used noise as the input to only the bottommost layer of the generator network.

We estimate probability of the test set data under $p_g$ by fitting a Gaussian Parzen window to the samples generated with $G$ and reporting the log-likelihood under this distribution. The $\sigma$ parameter of the Gaussians was obtained by cross validation on the validation set. This procedure was introduced in Breuleux et al. [8] and used for various generative models for which the exact likelihood is not tractable [25, 3, 5]. Results are reported in Table 1. This method of estimating the likelihood has somewhat high variance and does not perform well in high dimensional spaces but it is the best method available to our knowledge. Advances in generative models that can sample but not estimate likelihood directly motivate further research into how to evaluate such models.

In Figures 2 and 3 we show samples drawn from the generator net after training. While we make no claim that these samples are better than samples generated by existing methods, we believe that these samples are at least competitive with the better generative models in the literature and highlight the potential of the adversarial framework.

**Table 1:** Parzen window-based log-likelihood estimates. The reported numbers on MNIST are the mean log-likelihood of samples on test set, with the standard error of the mean computed across examples. On TFD, we computed the standard error across folds of the dataset, with a different $\sigma$ chosen using the validation set of each fold. On TFD, $\sigma$ was cross validated on each fold and mean log-likelihood on each fold were computed. For MNIST we compare against other models of the real-valued (rather than binary) version of dataset.

| Model | MNIST | TFD |
|-------|-------|-----|
| DBN [3] | 138 ± 2 | 1909 ± 66 |
| Stacked CAE [3] | 121 ± 1.6 | 2110 ± 50 |
| Deep GSN [6] | 214 ± 1.1 | 1890 ± 29 |
| Adversarial nets | 225 ± 2 | 2057 ± 26 |

---

### النسخة العربية

قمنا بتدريب الشبكات التنافسية الخصامية على مجموعة من مجموعات البيانات بما في ذلك MNIST [23]، وقاعدة بيانات وجوه تورنتو (TFD) [28]، و CIFAR-10 [21]. استخدمت شبكات المولد مزيجاً من تفعيلات المقوم الخطي [19، 9] وتفعيلات سيغمويد، بينما استخدمت شبكة المميز تفعيلات maxout [10]. تم تطبيق dropout [17] في تدريب شبكة المميز. بينما يسمح إطارنا النظري باستخدام dropout وضوضاء أخرى في الطبقات الوسيطة للمولد، استخدمنا الضوضاء كمدخل فقط للطبقة السفلى من شبكة المولد.

نقدر احتمالية بيانات مجموعة الاختبار تحت $p_g$ عن طريق ملاءمة نافذة بارزن الغاوسية للعينات المولدة بـ $G$ والإبلاغ عن اللوغاريتم الاحتمالي تحت هذا التوزيع. تم الحصول على معامل $\sigma$ للغاوسيين عن طريق التحقق المتقاطع على مجموعة التحقق. تم تقديم هذا الإجراء في Breuleux وآخرون [8] واستخدم لنماذج توليدية مختلفة لا يمكن تتبع احتماليتها الدقيقة [25، 3، 5]. يتم الإبلاغ عن النتائج في الجدول 1. هذه الطريقة لتقدير الاحتمالية لها تباين مرتفع إلى حد ما ولا تعمل بشكل جيد في الفضاءات عالية الأبعاد ولكنها أفضل طريقة متاحة على حد علمنا. تحفز التطورات في النماذج التوليدية التي يمكنها أخذ العينات ولكن لا يمكنها تقدير الاحتمالية بشكل مباشر مزيداً من البحث حول كيفية تقييم هذه النماذج.

في الشكلين 2 و 3 نعرض عينات مسحوبة من شبكة المولد بعد التدريب. بينما لا ندعي أن هذه العينات أفضل من العينات المولدة بواسطة الأساليب الموجودة، نعتقد أن هذه العينات على الأقل منافسة للنماذج التوليدية الأفضل في الأدبيات وتسلط الضوء على إمكانات الإطار التنافسي الخصامي.

**الجدول 1:** تقديرات اللوغاريتم الاحتمالي القائمة على نافذة بارزن. الأرقام المبلغ عنها على MNIST هي متوسط اللوغاريتم الاحتمالي للعينات في مجموعة الاختبار، مع حساب الخطأ المعياري للمتوسط عبر الأمثلة. على TFD، قمنا بحساب الخطأ المعياري عبر طيات مجموعة البيانات، مع اختيار $\sigma$ مختلف باستخدام مجموعة التحقق من كل طية. على TFD، تم التحقق المتقاطع من $\sigma$ على كل طية وتم حساب متوسط اللوغاريتم الاحتمالي على كل طية. بالنسبة لـ MNIST نقارن بنماذج أخرى من النسخة ذات القيمة الحقيقية (بدلاً من الثنائية) من مجموعة البيانات.

| النموذج | MNIST | TFD |
|-------|-------|-----|
| DBN [3] | 138 ± 2 | 1909 ± 66 |
| Stacked CAE [3] | 121 ± 1.6 | 2110 ± 50 |
| Deep GSN [6] | 214 ± 1.1 | 1890 ± 29 |
| الشبكات التنافسية الخصامية | 225 ± 2 | 2057 ± 26 |

---

### Translation Notes

- **Figures referenced:** Figure 2, Figure 3 (showing generated samples)
- **Key terms introduced:**
  - Parzen window (نافذة بارزن)
  - rectifier linear activations (تفعيلات المقوم الخطي)
  - maxout (maxout - kept as transliteration)
  - cross validation (التحقق المتقاطع)
  - folds (طيات)
- **Equations:** None (only table)
- **Citations:** [23], [28], [21], [19, 9], [10], [17], [8], [25, 3, 5]
- **Special handling:**
  - Dataset names (MNIST, TFD, CIFAR-10) kept in English
  - Table 1 translated with Arabic headers but preserved numerical data
  - "Gaussian" → "الغاوسية" (standard Arabic mathematical term)
  - dropout kept in English as per glossary convention

### Quality Metrics

- Semantic equivalence: 0.88
- Technical accuracy: 0.87
- Readability: 0.87
- Glossary consistency: 0.86
- **Overall section score:** 0.87

### Back-Translation (Key Paragraph)

"We estimate the probability of test set data under $p_g$ by fitting a Gaussian Parzen window to the samples generated with $G$ and reporting the log-likelihood under this distribution. The $\sigma$ parameter for the Gaussians was obtained through cross validation on the validation set. This procedure was introduced in Breuleux et al. [8] and used for various generative models whose exact likelihood cannot be tracked [25, 3, 5]."

**Validation:** ✅ Technical methodology accurately conveyed. Statistical terminology preserved.
