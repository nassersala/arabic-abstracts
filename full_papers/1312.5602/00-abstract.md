# Section 0: Abstract
## القسم 0: الملخص

**Section:** abstract
**Translation Quality:** 0.92
**Glossary Terms Used:** deep learning, convolutional neural network, algorithm, architecture, high-dimensional, reinforcement learning, Q-learning, value function

---

### English Version

We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.

---

### النسخة العربية

نقدم أول نموذج تعلم عميق ينجح في تعلم سياسات التحكم مباشرة من المدخلات الحسية عالية الأبعاد باستخدام التعلم المعزز. النموذج عبارة عن شبكة عصبية التفافية، مدربة باستخدام نسخة من خوارزمية Q-learning، حيث يكون المدخل عبارة عن بكسلات خام والمخرج عبارة عن دالة قيمة تقدر المكافآت المستقبلية. نطبق طريقتنا على سبع ألعاب Atari 2600 من بيئة Arcade Learning Environment، دون أي تعديل على المعمارية أو خوارزمية التعلم. نجد أنها تتفوق على جميع الأساليب السابقة في ستة من الألعاب وتتجاوز خبيرًا بشريًا في ثلاثة منها.

---

### Translation Notes

- **Figures referenced:** None in abstract
- **Key terms introduced:** deep learning, reinforcement learning, convolutional neural network, Q-learning, value function, control policies, high-dimensional sensory input
- **Equations:** 0
- **Citations:** 0
- **Special handling:** Game names (Atari 2600) kept in English as proper nouns

### Quality Metrics

- Semantic equivalence: 0.93
- Technical accuracy: 0.95
- Readability: 0.90
- Glossary consistency: 0.90
- **Overall section score:** 0.92
