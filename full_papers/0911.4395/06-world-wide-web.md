# Section 6: World Wide Web - A Massive Distributed System
## القسم 6: الشبكة العنكبوتية العالمية - نظام موزع ضخم

**Section:** World Wide Web
**Translation Quality:** 0.85
**Glossary Terms Used:** Internet, World Wide Web, distributed system, HTTP, URL, DNS, HTML, server, client, browser, search engine

---

### English Version

The Internet - a massive network of networks, connects millions of computers together worldwide, forming a network in which any computer can communicate with any other computer provided that they are both connected to the Internet. The World Wide Web (WWW), or simply Web, is a way of accessing information over the medium of the Internet. WWW consists of billions of web pages, spread across thousands and thousands of servers all over the world. It is an information-sharing model that is built on top of the Internet. The most well-known example of a distributed system is the collection of web servers. Hypertext is a document containing words that bond to other documents in the Web. These words are known as links and are selectable by the user. A single hypertext document can hold links to many documents.

The backbone of WWW are its files, called pages or Web pages, containing information and links to resources - both text and multimedia - throughout the Internet. Internet protocols are sets of rules that allow for inter-machine communication on the Internet. HTTP (HyperText Transfer Protocol) transmits hypertext over networks. This is the protocol of the Web. Simple Mail Transport Protocol or SMTP distributes e-mail messages and attached files to one or more electronic mailboxes. VoIP (Voice over Internet Protocol) allows delivery of voice communications over IP networks, for example, phone calls. A web server accepts HTTP requests from clients, and serving them HTTP responses along with optional data contents such as web pages.

The operation of the web relies primarily on hypertext as its means of information retrieval. Web pages can be created by user activity. Creating hypertext for the Web is accomplished by creating documents with a language called hypertext markup language, or HTML. With HTML, tags are placed within the text to achieve document formatting, visual features such as font size, italics and bold, and the creation of hypertext links. Servers implementing the HTTP protocol jointly provide the distributed database of hypertext and multimedia documents. The clients access the web through the browser software installed on their system. The URL (uniform resource locator) indicates the internet address of a file stored on a host computer, or server, connected to the internet. URLs are translated into numeric addresses using the domain name system (DNS). The DNS is a worldwide system of servers that stores location pointers to web sites. The numeric address, called the IP (Internet Protocol) address, is actually the "real" URL. Once the translation is made by the DNS, the browser can contact the web server and ask for a specific file located on its site. Web browsers use the URL to retrieve the file from the server. Then the file is downloaded to the user's computer, or client, and displayed on the monitor connected to the machine. Due to this correlation between clients and servers, the web is a client-server network. The web is used by millions of people everyday for different purposes including email, reading news, downloading music, online shopping or simply accessing information about anything. In fact, the web symbolizes a massive distributed system that materializes as a single resource to the user accessible at the click of a button. In order for the web to be accessible to anyone, some agreed-upon standards must be pursued in the formation and delivery of its content. An organization leading the efforts to standardize the web is the World Wide Web (W3C) Consortium.

**Web Information Retrieval**

Web information retrieval [AMI08, AMY04, AMY06, DIRK05, MONI03, VENK97] is the process of searching the world's largest and linked document collection – the World Wide Web, for information most relevant to a user's query. The various challenges of information retrieval on the web are: (i) data is distributed - data spans over many computers, of a variety of platforms, (ii) data is volatile - computers and files are added and removed frequently and unpredictably, (iii) volume of data is very huge - growth continues exponentially, (iv) data quality is inconsistent - data may be false, error-ridden, invalid, outdated, ambiguous and multiplicity of sources introduces inconsistency and (v) heterogeneous data - multiple media types and media formats and multiple languages and alphabets. As a result, it would be physically unfeasible for an individual to sift through and examine all these pages to find the required information. Usually, in order to search for information on the internet a software tool called Search Engine is used. When a user enters a query into a search engine from their browser software, their input is processed and used to search the database for occurrences of particular keywords. A variety of search engines such as Google, Yahoo! Search, are available to make the web retrieval process very faster. Two main architectures used for web searching are centralised and distributed search.

**[Figure 7: Centralised Search Engine Architecture showing Users - Interface - Query Engine - Index - Crawler - Indexer - Web]**

**Centralised Architecture:** The aim of centralised approach is to index sizeable portion of Web, independently of topic and domain. The centralised architecture based search engine has main three parts: a crawler, an indexer, and query handler. The crawler (spider or robot) retrieves web pages, compress and store into a page repository. This process is called crawling (sometimes known as robot spidering, gathering or harvesting). Some of the most well known crawlers include Googlebot (from Google) MSNBot (from MSN) and Slurp (from Yahoo!). Crawlers are directed by a crawler control module that gives the URLs to visit next. The indexer processes the web pages collected by the crawler and builds an index, which is the main data structure used by the search engine and represents the crawled web pages. The inverted index contains for each word a sorted list of couples such as docID and position in the document. The query engine processes the user queries and returns matching results using the index. The results are returned to the user in an order determined by a ranking algorithm. Each search engine may have a different ranking algorithm, which parses the pages in the engine's database to determine relevant responses to search queries. Some search engines keep a local cache copy of many popular pages indexed in their database, to allow for faster access and in case the destination server is temporarily inaccessible.

**[Figure 8: Distributed Search Engine Architecture showing Users - Brokers - Gatherers - Web Sites]**

**Distributed architecture:** Searching is a coordinated effort of many information gatherers and brokers. Gatherer extracts information (called summaries) from the documents stored on one or more web servers. It can handle documents in many formats: HTML, PDF, Postscript, etc. Broker obtains summaries from gatherers, stores them locally, and indexes the data. It can search the data; fetch data from other brokers and makes data available for user queries and to other brokers. The advantages of distributed architecture are the gatherer running on a server reduces the external traffic on that server and evading of gatherer sending information to multiple brokers reduces work repetition.

---

### النسخة العربية

الإنترنت - شبكة ضخمة من الشبكات، يربط ملايين الحواسيب معًا في جميع أنحاء العالم، مشكلاً شبكة يمكن فيها لأي حاسوب التواصل مع أي حاسوب آخر بشرط أن يكونا متصلين بالإنترنت. الشبكة العنكبوتية العالمية (WWW)، أو ببساطة الويب، هي طريقة للوصول إلى المعلومات عبر وسيط الإنترنت. يتكون WWW من مليارات صفحات الويب، منتشرة عبر آلاف الخوادم في جميع أنحاء العالم. إنه نموذج لتبادل المعلومات مبني على قمة الإنترنت. المثال الأكثر شهرة للنظام الموزع هو مجموعة خوادم الويب. النص التشعبي هو مستند يحتوي على كلمات ترتبط بمستندات أخرى في الويب. تُعرف هذه الكلمات بالروابط ويمكن للمستخدم اختيارها. يمكن لمستند نص تشعبي واحد أن يحتوي على روابط للعديد من المستندات.

العمود الفقري لـ WWW هو ملفاته، تسمى الصفحات أو صفحات الويب، التي تحتوي على معلومات وروابط لموارد - نصية ومتعددة الوسائط - في جميع أنحاء الإنترنت. بروتوكولات الإنترنت هي مجموعات من القواعد التي تسمح بالاتصال بين الآلات على الإنترنت. HTTP (بروتوكول نقل النص التشعبي) ينقل النص التشعبي عبر الشبكات. هذا هو بروتوكول الويب. بروتوكول نقل البريد البسيط أو SMTP يوزع رسائل البريد الإلكتروني والملفات المرفقة إلى صندوق بريد إلكتروني واحد أو أكثر. VoIP (بروتوكول الصوت عبر الإنترنت) يسمح بتوصيل الاتصالات الصوتية عبر شبكات IP، على سبيل المثال، المكالمات الهاتفية. يقبل خادم الويب طلبات HTTP من العملاء، ويقدم لهم استجابات HTTP مع محتويات بيانات اختيارية مثل صفحات الويب.

يعتمد تشغيل الويب بشكل أساسي على النص التشعبي كوسيلة لاسترجاع المعلومات. يمكن إنشاء صفحات الويب من خلال نشاط المستخدم. يتم إنشاء نص تشعبي للويب من خلال إنشاء مستندات بلغة تسمى لغة ترميز النص التشعبي، أو HTML. مع HTML، يتم وضع علامات داخل النص لتحقيق تنسيق المستند، والميزات المرئية مثل حجم الخط والمائل والعريض، وإنشاء روابط النص التشعبي. تقدم الخوادم التي تطبق بروتوكول HTTP بشكل مشترك قاعدة البيانات الموزعة للنص التشعبي والمستندات متعددة الوسائط. يصل العملاء إلى الويب من خلال برنامج المتصفح المثبت على نظامهم. يشير URL (محدد موقع الموارد الموحد) إلى عنوان الإنترنت لملف مخزن على حاسوب مضيف، أو خادم، متصل بالإنترنت. تتم ترجمة عناوين URL إلى عناوين رقمية باستخدام نظام اسم النطاق (DNS). DNS هو نظام عالمي من الخوادم يخزن مؤشرات الموقع لمواقع الويب. العنوان الرقمي، المسمى عنوان IP (بروتوكول الإنترنت)، هو في الواقع "URL" الحقيقي. بمجرد إجراء الترجمة بواسطة DNS، يمكن للمتصفح الاتصال بخادم الويب وطلب ملف معين موجود على موقعه. تستخدم متصفحات الويب URL لاسترجاع الملف من الخادم. ثم يتم تنزيل الملف إلى حاسوب المستخدم، أو العميل، ويتم عرضه على الشاشة المتصلة بالجهاز. بسبب هذا الارتباط بين العملاء والخوادم، الويب هو شبكة عميل-خادم. يستخدم الويب من قبل ملايين الأشخاص يوميًا لأغراض مختلفة بما في ذلك البريد الإلكتروني، وقراءة الأخبار، وتنزيل الموسيقى، والتسوق عبر الإنترنت أو ببساطة الوصول إلى معلومات حول أي شيء. في الواقع، يرمز الويب إلى نظام موزع ضخم يتجسد كمورد واحد للمستخدم يمكن الوصول إليه بنقرة زر. لكي يكون الويب متاحًا لأي شخص، يجب اتباع بعض المعايير المتفق عليها في تكوين وتقديم محتواه. المنظمة التي تقود الجهود لتوحيد الويب هي اتحاد الشبكة العنكبوتية العالمية (W3C).

**استرجاع معلومات الويب**

استرجاع معلومات الويب [AMI08, AMY04, AMY06, DIRK05, MONI03, VENK97] هو عملية البحث في أكبر مجموعة مستندات مرتبطة في العالم - الشبكة العنكبوتية العالمية، عن المعلومات الأكثر صلة باستعلام المستخدم. التحديات المختلفة لاسترجاع المعلومات على الويب هي: (1) البيانات موزعة - تمتد البيانات عبر العديد من الحواسيب، من مجموعة متنوعة من المنصات، (2) البيانات متقلبة - يتم إضافة وإزالة الحواسيب والملفات بشكل متكرر ولا يمكن التنبؤ به، (3) حجم البيانات ضخم جدًا - يستمر النمو بشكل أسي، (4) جودة البيانات غير متسقة - قد تكون البيانات خاطئة، مليئة بالأخطاء، غير صالحة، قديمة، غامضة وتعدد المصادر يقدم عدم الاتساق و(5) البيانات غير المتجانسة - أنواع وسائط متعددة وتنسيقات وسائط ولغات وأبجديات متعددة. ونتيجة لذلك، سيكون من غير الممكن ماديًا للفرد أن يتصفح ويفحص كل هذه الصفحات للعثور على المعلومات المطلوبة. عادة، من أجل البحث عن معلومات على الإنترنت يتم استخدام أداة برمجية تسمى محرك البحث. عندما يدخل المستخدم استعلامًا في محرك بحث من برنامج المتصفح الخاص به، تتم معالجة مدخلاته واستخدامها للبحث في قاعدة البيانات عن حدوث كلمات رئيسية معينة. مجموعة متنوعة من محركات البحث مثل Google و Yahoo! Search متاحة لجعل عملية استرجاع الويب أسرع بكثير. هناك معماريتان رئيسيتان تُستخدمان للبحث على الويب هما البحث المركزي والموزع.

**[الشكل 7: معمارية محرك البحث المركزي يُظهر المستخدمون - الواجهة - محرك الاستعلام - الفهرس - الزاحف - المُفهرس - الويب]**

**المعمارية المركزية:** الهدف من النهج المركزي هو فهرسة جزء كبير من الويب، بشكل مستقل عن الموضوع والمجال. محرك البحث القائم على المعمارية المركزية له ثلاثة أجزاء رئيسية: الزاحف، والمُفهرس، ومعالج الاستعلام. يسترجع الزاحف (العنكبوت أو الروبوت) صفحات الويب، ويضغطها ويخزنها في مستودع صفحات. تسمى هذه العملية الزحف (تُعرف أحيانًا باسم زحف الروبوت، أو الجمع أو الحصاد). بعض أشهر الزواحف تشمل Googlebot (من Google) و MSNBot (من MSN) و Slurp (من Yahoo!). يتم توجيه الزواحف بواسطة وحدة تحكم الزاحف التي تعطي عناوين URL للزيارة التالية. يعالج المُفهرس صفحات الويب التي جمعها الزاحف ويبني فهرسًا، وهو بنية البيانات الرئيسية المستخدمة من قبل محرك البحث ويمثل صفحات الويب المزحوفة. يحتوي الفهرس المعكوس لكل كلمة على قائمة مرتبة من الأزواج مثل docID والموضع في المستند. يعالج محرك الاستعلام استعلامات المستخدم ويعيد النتائج المطابقة باستخدام الفهرس. يتم إرجاع النتائج إلى المستخدم بترتيب تحدده خوارزمية ترتيب. قد يكون لكل محرك بحث خوارزمية ترتيب مختلفة، تحلل الصفحات في قاعدة بيانات المحرك لتحديد الاستجابات ذات الصلة باستعلامات البحث. تحتفظ بعض محركات البحث بنسخة ذاكرة تخزين مؤقت محلية من العديد من الصفحات الشائعة المفهرسة في قاعدة بياناتها، للسماح بوصول أسرع وفي حالة عدم إمكانية الوصول إلى الخادم الوجهة مؤقتًا.

**[الشكل 8: معمارية محرك البحث الموزع يُظهر المستخدمون - الوسطاء - الجامعون - مواقع الويب]**

**المعمارية الموزعة:** البحث هو جهد منسق للعديد من جامعي المعلومات والوسطاء. يستخرج الجامع المعلومات (تسمى الملخصات) من المستندات المخزنة على خادم ويب واحد أو أكثر. يمكنه التعامل مع المستندات في العديد من التنسيقات: HTML و PDF و Postscript وما إلى ذلك. يحصل الوسيط على ملخصات من الجامعين، ويخزنها محليًا، ويفهرس البيانات. يمكنه البحث في البيانات؛ جلب البيانات من وسطاء آخرين وجعل البيانات متاحة لاستعلامات المستخدم وللوسطاء الآخرين. مزايا المعمارية الموزعة هي أن تشغيل الجامع على خادم يقلل من حركة المرور الخارجية على ذلك الخادم وتجنب إرسال الجامع معلومات إلى وسطاء متعددين يقلل من تكرار العمل.

---

### Translation Notes

- **Figures referenced:** Figure 7 (Centralized Search Engine), Figure 8 (Distributed Search Engine)
- **Key terms introduced:** World Wide Web, HTTP, HTML, URL, DNS, hypertext, web crawler, search engine
- **Equations:** None
- **Citations:** Multiple citations for web information retrieval
- **Special handling:** Discussion of web protocols and search architectures

### Quality Metrics

- Semantic equivalence: 0.86
- Technical accuracy: 0.85
- Readability: 0.84
- Glossary consistency: 0.85
- **Overall section score:** 0.85
