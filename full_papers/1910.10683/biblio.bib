@article{hestness2017deep,
  title={Deep learning scaling is predictable, empirically},
  author={Hestness, Joel and Narang, Sharan and Ardalani, Newsha and Diamos, Gregory and Jun, Heewoo and Kianinejad, Hassan and Patwary, Md. Mostofa Ali and Yang, Yang and Zhou, Yanqi},
  journal={arXiv preprint arXiv:1712.00409},
  year={2017}
}

@article{shazeer2017outrageously,
  title={Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal={arXiv preprint arXiv:1701.06538},
  year={2017}
}

@article{jozefowicz2016exploring,
  title={Exploring the limits of language modeling},
  author={Jozefowicz, Rafal and Vinyals, Oriol and Schuster, Mike and Shazeer, Noam and Wu, Yonghui},
  journal={arXiv preprint arXiv:1602.02410},
  year={2016}
}

@inproceedings{mahajan2018exploring,
  title={Exploring the limits of weakly supervised pretraining},
  author={Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and van der Maaten, Laurens},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2018}
}

@misc{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@inproceedings{oliver2018realistic,
  title={Realistic evaluation of deep semi-supervised learning algorithms},
  author={Oliver, Avital and Odena, Augustus and Raffel, Colin and Cubuk, Ekin Dogus and Goodfellow, Ian},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}

@article{russakovsky2015imagenet,
  title={{ImageNet} large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  year={2015}
}

@inproceedings{deng2009imagenet,
  title={{ImageNet}: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  year={2009}
}

@inproceedings{oquab2014learning,
  title={Learning and transferring mid-level image representations using convolutional neural networks},
  author={Oquab, Maxime and Bottou, Leon and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2014}
}

@inproceedings{jia2014caffe,
  title={Caffe: Convolutional architecture for fast feature embedding},
  author={Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  booktitle={Proceedings of the 22nd ACM international conference on Multimedia},
  year={2014}
}

@inproceedings{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={Advances in neural information processing systems},
  year={2014}
}

@article{huh2016makes,
  title={What makes {ImageNet} good for transfer learning?},
  author={Huh, Minyoung and Agrawal, Pulkit and Efros, Alexei A.},
  journal={arXiv preprint arXiv:1608.08614},
  year={2016}
}

@inproceedings{dai2015semi,
  title={Semi-supervised sequence learning},
  author={Dai, Andrew M. and Le, Quoc V.},
  booktitle={Advances in neural information processing systems},
  year={2015}
}

@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018}
}

@article{peters2018deep,
  title={Deep contextualized word representations},
  author={Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1802.05365},
  year={2018}
}

@article{howard2018universal,
  title={Universal language model fine-tuning for text classification},
  author={Howard, Jeremy and Ruder, Sebastian},
  journal={arXiv preprint arXiv:1801.06146},
  year={2018}
}

@article{devlin2018bert,
  title={{BERT}: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{baevski2019cloze,
  title={Cloze-driven Pretraining of Self-attention Networks},
  author={Baevski, Alexei and Edunov, Sergey and Liu, Yinhan and Zettlemoyer, Luke and Auli, Michael},
  journal={arXiv preprint arXiv:1903.07785},
  year={2019}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  year={2017}
}

@article{mccann2018natural,
  title={The natural language decathlon: Multitask learning as question answering},
  author={McCann, Bryan and Keskar, Nitish Shirish and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1806.08730},
  year={2018}
}

@article{yu2018qanet,
  title={{QAnet}: Combining local convolution with global self-attention for reading comprehension},
  author={Yu, Adams Wei and Dohan, David and Luong, Minh-Thang and Zhao, Rui and Chen, Kai and Norouzi, Mohammad and Le, Quoc V.},
  journal={arXiv preprint arXiv:1804.09541},
  year={2018}
}

@article{graves2013generating,
  title={Generating sequences with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1308.0850},
  year={2013}
}

@inproceedings{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={Third International Conference on Learning Representations},
  year={2015}
}

@article{cheng2016long,
  title={Long short-term memory-networks for machine reading},
  author={Cheng, Jianpeng and Dong, Li and Lapata, Mirella},
  journal={arXiv preprint arXiv:1601.06733},
  year={2016}
}

@article{ba2016layer,
  title={Layer Normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2016}
}

@article{krizhevsky2014one,
  title={One weird trick for parallelizing convolutional neural networks},
  author={Krizhevsky, Alex},
  journal={arXiv preprint arXiv:1404.5997},
  year={2014}
}

@inproceedings{shazeer2018mesh,
  title={Mesh-tensorflow: Deep learning for supercomputers},
  author={Shazeer, Noam and Cheng, Youlong and Parmar, Niki and Tran, Dustin and Vaswani, Ashish and Koanantakool, Penporn and Hawkins, Peter and Lee, HyoukJoong and Hong, Mingsheng and Young, Cliff and Sepassi, Ryan and Hechtman, Blake},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}

@techreport{page1999pagerank,
  title={The PageRank citation ranking: Bringing order to the web},
  author={Page, Lawrence and Brin, Sergey and Motwani, Rajeev and Winograd, Terry},
  year={1999},
  institution={Stanford InfoLab}
}

@article{taylor1953cloze,
  title={``{Cloze} procedure'': A new tool for measuring readability},
  author={Taylor, Wilson L.},
  journal={Journalism Bulletin},
  year={1953},
}

@article{fedus2018maskgan,
  title={Maskgan: Better text generation via filling in the \_},
  author={Fedus, William and Goodfellow, Ian and Dai, Andrew M.},
  journal={arXiv preprint arXiv:1801.07736},
  year={2018}
}

@article{williams2017broad,
  title={A broad-coverage challenge corpus for sentence understanding through inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel R.},
  journal={arXiv preprint arXiv:1704.05426},
  year={2017}
}

@inproceedings{banko2001scaling,
  title={Scaling to very very large corpora for natural language disambiguation},
  author={Banko, Michele and Brill, Eric},
  booktitle={Proceedings of the 39th annual meeting on association for computational linguistics},
  year={2001},
}

@article{chelba2013one,
  title={One billion word benchmark for measuring progress in statistical language modeling},
  author={Chelba, Ciprian and Mikolov, Tomas and Schuster, Mike and Ge, Qi and Brants, Thorsten and Koehn, Phillipp and Robinson, Tony},
  journal={arXiv preprint arXiv:1312.3005},
  year={2013}
}

@inproceedings{buck2014n,
  title={N-gram Counts and Language Models from the Common Crawl.},
  author={Buck, Christian and Heafield, Kenneth and Van Ooyen, Bas},
  booktitle={LREC},
  year={2014},
}

@article{trinh2018simple,
  title={A simple method for commonsense reasoning},
  author={Trinh, Trieu H. and Le, Quoc V.},
  journal={arXiv preprint arXiv:1806.02847},
  year={2018}
}

@inproceedings{smith2013dirt,
  title={Dirt cheap web-scale parallel text from the common crawl},
  author={Smith, Jason R. and Saint-Amand, Herve and Plamada, Magdalena and Koehn, Philipp and Callison-Burch, Chris and Lopez, Adam},
  booktitle={Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics},
  year={2013}
}

@article{anil2019memory,
  title={Memory-Efficient Adaptive Optimization for Large-Scale Learning},
  author={Anil, Rohan and Gupta, Vineet and Koren, Tomer and Singer, Yoram},
  journal={arXiv preprint arXiv:1901.11150},
  year={2019}
}

@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S. and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  year={2013}
}

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@inproceedings{pennington2014glove,
  title={{GloVe}: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  year={2014}
}

@inproceedings{kiros2015skip,
  title={Skip-thought vectors},
  author={Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Ruslan R. and Zemel, Richard and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  booktitle={Advances in neural information processing systems},
  year={2015}
}

@article{ramachandran2016unsupervised,
  title={Unsupervised pretraining for sequence to sequence learning},
  author={Ramachandran, Prajit and Liu, Peter J. and Le, Quoc V.},
  journal={arXiv preprint arXiv:1611.02683},
  year={2016}
}

@article{radford2017learning,
  title={Learning to generate reviews and discovering sentiment},
  author={Radford, Alec and Jozefowicz, Rafal and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1704.01444},
  year={2017}
}

@article{kornblith2018better,
  title={Do better {ImageNet} models transfer better?},
  author={Kornblith, Simon and Shlens, Jonathon and Le, Quoc V.},
  journal={arXiv preprint arXiv:1805.08974},
  year={2018}
}

@article{he2018rethinking,
  title={Rethinking {ImageNet} pre-training},
  author={He, Kaiming and Girshick, Ross and Doll{\'a}r, Piotr},
  journal={arXiv preprint arXiv:1811.08883},
  year={2018}
}

@article{wang2018glue,
  title={{GLUE}: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amapreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}

@article{wang2019superglue,
  title={{SuperGLUE}: A Stickier Benchmark for General-Purpose Language Understanding Systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
  journal={arXiv preprint arXiv:1905.00537},
  year={2019}
}

@article{liu2019multi,
  title={Multi-Task Deep Neural Networks for Natural Language Understanding},
  author={Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},
  journal={arXiv preprint arXiv:1901.11504},
  year={2019}
}

@inproceedings{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  booktitle={Advances in neural information processing systems},
  year={2015}
}

@article{williams1989learning,
  title={A learning algorithm for continually running fully recurrent neural networks},
  author={Williams, Ronald J. and Zipser, David},
  journal={Neural computation},
  year={1989}
}

@article{shazeer2018adafactor,
  title={Adafactor: Adaptive learning rates with sublinear memory cost},
  author={Shazeer, Noam and Stern, Mitchell},
  journal={arXiv preprint arXiv:1804.04235},
  year={2018}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The Journal of Machine Learning Research},
  year={2014}
}

@article{kudo2018sentencepiece,
  title={{SentencePiece}: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing},
  author={Kudo, Taku and Richardson, John},
  journal={arXiv preprint arXiv:1808.06226},
  year={2018}
}

@article{kudo2018subword,
  title={Subword regularization: Improving neural network translation models with multiple subword candidates},
  author={Kudo, Taku},
  journal={arXiv preprint arXiv:1804.10959},
  year={2018}
}

@inproceedings{dagan2005pascal,
  title={The {PASCAL} recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine Learning Challenges Workshop},
  year={2005},
}

@inproceedings{levesque2012winograd,
  title={The {Winograd} schema challenge},
  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
  booktitle={Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning},
  year={2012}
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D. and Ng, Andrew and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  year={2013}
}

@inproceedings{dolan2005automatically,
  title={Automatically constructing a corpus of sentential paraphrases},
  author={Dolan, William B. and Brockett, Chris},
  booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},
  year={2005}
}

@article{warstadt2018neural,
  title={Neural Network Acceptability Judgments},
  author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R.},
  journal={arXiv preprint arXiv:1805.12471},
  year={2018}
}

@article{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}

@article{cer2017semeval,
  title={Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation},
  author={Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia},
  journal={arXiv preprint arXiv:1708.00055},
  year={2017}
}


@misc{shankar2017first,
  author={Iyer, Shankar and Dandekar, Nikhil and Csernai, Kornel},
  title={First {Quora} Dataset Release: Question Pairs},
  year={2017},
  howpublished={\url{https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs}}
}

@inproceedings{roemmele2011choice,
  title={Choice of plausible alternatives: An evaluation of commonsense causal reasoning},
  author={Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S},
  booktitle={2011 AAAI Spring Symposium Series},
  year={2011}
}

@inproceedings{khashabi2018looking,
    author={Daniel Khashabi and Snigdha Chaturvedi and Michael Roth and Shyam Upadhyay and Dan Roth},
    title={Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences},
    booktitle={Proceedings of North American Chapter of the Association for Computational Linguistics (NAACL)},
    year={2018}
}

@inproceedings{de2019commitmentbank,
  title={The {CommitmentBank}: Investigating projection in naturally occurring discourse},
  booktitle={Sinn und Bedeutung 23},
  author={De Marneff, Marie-Catherine and Simons, Mandy and Tonhauser, Judith},
  year={2019}
}

@article{pilehvar2018wic,
  title={{WIC}: 10,000 example pairs for evaluating context-sensitive representations},
  author={Pilehvar, Mohammad Taher and Camacho-Collados, Jose},
  journal={arXiv preprint arXiv:1808.09121},
  year={2018}
}

@article{aharoni2019massively,
  title={Massively Multilingual Neural Machine Translation},
  author={Aharoni, Roee and Johnson, Melvin and Firat, Orhan},
  journal={arXiv preprint arXiv:1903.00089},
  year={2019}
}

@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V. and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}

@article{yang2019xlnet,
  title={{XLNet}: Generalized Autoregressive Pretraining for Language Understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V.},
  journal={arXiv preprint arXiv:1906.08237},
  year={2019}
}

@article{dong2019unified,
  title={Unified Language Model Pre-training for Natural Language Understanding and Generation},
  author={Dong, Li and Yang, Nan and Wang, Wenhui and Wei, Furu and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Zhou, Ming and Hon, Hsiao-Wuen},
  journal={arXiv preprint arXiv:1905.03197},
  year={2019}
}

@article{liu2019roberta,
  title={{RoBERTa}: A Robustly Optimized {BERT} Pretraining Approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{zellers2019defending,
  title={Defending Against Neural Fake News},
  author={Zellers, Rowan and Holtzman, Ari and Rashkin, Hannah and Bisk, Yonatan and Farhadi, Ali and Roesner, Franziska and Choi, Yejin},
  journal={arXiv preprint arXiv:1905.12616},
  year={2019}
}

@article{houlsby2019parameter,
  title={Parameter-Efficient Transfer Learning for {NLP}},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  journal={arXiv preprint arXiv:1902.00751},
  year={2019}
}

@article{peters2019tune,
  title={To tune or not to tune? adapting pretrained representations to diverse tasks},
  author={Peters, Matthew and Ruder, Sebastian and Smith, Noah A.},
  journal={arXiv preprint arXiv:1903.05987},
  year={2019}
}

@inproceedings{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
  booktitle={Advances in neural information processing systems},
  year={2014}
}

@inproceedings{kalchbrenner2014convolutional,
  title={A Convolutional Neural Network for Modelling Sentences},
  author={Kalchbrenner, Nal and Grefenstette, Edward and Blunsom, Phil},
  booktitle={Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics},
  year={2014}
}

@article{battaglia2018relational,
  title={Relational inductive biases, deep learning, and graph networks},
  author={Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others},
  journal={arXiv preprint arXiv:1806.01261},
  year={2018}
}

@inproceedings{huang2018music,
  title={Music transformer: Generating music with long-term structure},
  author={Huang, Cheng-Zhi Anna and Vaswani, Ashish and Uszkoreit, Jakob and Simon, Ian and Hawthorne, Curtis and Shazeer, Noam and Dai, Andrew M. and Hoffman, Matthew D. and Dinculescu, Monica and Eck, Douglas},
  booktitle={Seventh International Conference on Learning Representations},
  year={2018}
}

@article{shaw2018self,
  title={Self-attention with relative position representations},
  author={Shaw, Peter and Uszkoreit, Jakob and Vaswani, Ashish},
  journal={arXiv preprint arXiv:1803.02155},
  year={2018}
}

@inproceedings{al2019character,
  title={Character-level language modeling with deeper self-attention},
  author={Al-Rfou, Rami and Choe, Dokook and Constant, Noah and Guo, Mandy and Jones, Llion},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2019}
}

@article{song2019mass,
  title={{MASS}: Masked sequence to sequence pre-training for language generation},
  author={Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1905.02450},
  year={2019}
}

@inproceedings{papineni2002bleu,
  title={{BLEU}: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting on association for computational linguistics},
  year={2002},
  organization={Association for Computational Linguistics}
}

@article{post2018call,
  title={A call for clarity in reporting {BLEU} scores},
  author={Post, Matt},
  journal={arXiv preprint arXiv:1804.08771},
  year={2018}
}

@inproceedings{lin2004rouge,
  title={{ROUGE}: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  year={2004}
}

@article{liu2018generating,
  title={Generating {Wikipedia} by summarizing long sequences},
  author={Liu, Peter J. and Saleh, Mohammad and Pot, Etienne and Goodrich, Ben and Sepassi, Ryan and Kaiser, Lukasz and Shazeer, Noam},
  journal={arXiv preprint arXiv:1801.10198},
  year={2018}
}

@article{liu2019summae,
  title={{SummAE}: Zero-Shot Abstractive Text Summarization using Length-Agnostic Auto-Encoders},
  author={Liu, Peter J. and Chung, Yu-An and Ren, Jie},
  journal={arXiv preprint arXiv:1910.00998},
  year={2019}
}

@inproceedings{wang2019can,
  title={Can You Tell Me How to Get Past {Sesame Street? Sentence}-Level Pretraining Beyond Language Modeling},
  author={Wang, Alex and Hula, Jan and Xia, Patrick and Pappagari, Raghavendra and McCoy, R. Thomas and Patel, Roma and Kim, Najoung and Tenney, Ian and Huang, Yinghui and Yu, Katherin and others},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}

@article{lan2019albert,
  title={{ALBERT}: A Lite {BERT} for Self-supervised Learning of Language Representations},
  author={Zhenzhong Lan and Mingda Chen and Sebastian Goodman and Kevin Gimpel and Piyush Sharma and Radu Soricut},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@inproceedings{zhu2015aligning,
  title={Aligning books and movies: Towards story-like visual explanations by watching movies and reading books},
  author={Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  year={2015}
}

@article{stickland2019bert,
  title={{BERT} and {PALs}: Projected Attention Layers for Efficient Adaptation in Multi-Task Learning},
  author={Stickland, Asa Cooper and Murray, Iain},
  journal={arXiv preprint arXiv:1902.02671},
  year={2019}
}

@article{bapna2019simple,
  title={Simple, Scalable Adaptation for Neural Machine Translation},
  author={Ankur Bapna and Naveen Arivazhagan and Orhan Firat},
  journal={arXiv preprint arXiv:1909.08478},
  year={2019}
}

@article{ruder2017overview,
  title={An overview of multi-task learning in deep neural networks},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1706.05098},
  year={2017}
}

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  number={1},
  year={1997},
}

@article{bowman2015generating,
  title={Generating sentences from a continuous space},
  author={Bowman, Samuel R. and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew M. and Jozefowicz, Rafal and Bengio, Samy},
  journal={arXiv preprint arXiv:1511.06349},
  year={2015}
}

@misc{sutton2019bitter,
  title={The Bitter Lesson},
  howpublished={\url{http://www.incompleteideas.net/IncIdeas/BitterLesson.html}},
  author={Richard S. Sutton},
  year={2019}
}

@article{shallue2018measuring,
  title={Measuring the effects of data parallelism on neural network training},
  author={Shallue, Christopher J and Lee, Jaehoon and Antognini, Joe and Sohl-Dickstein, Jascha and Frostig, Roy and Dahl, George E.},
  journal={arXiv preprint arXiv:1811.03600},
  year={2018}
}

@article{joshi2019spanbert,
  title={{SpanBERT}: Improving pre-training by representing and predicting spans},
  author={Joshi, Mandar and Chen, Danqi and Liu, Yinhan and Weld, Daniel S. and Zettlemoyer, Luke and Levy, Omer},
  journal={arXiv preprint arXiv:1907.10529},
  year={2019}
}

@inproceedings{liu2015representation,
  title={Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval},
  author={Liu, Xiaodong and Gao, Jianfeng and He, Xiaodong and Deng, Li and Duh, Kevin and Wang, Ye-Yi},
  booktitle={Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  year={2015}
}

@article{clark2020electra,
  title={Electra: Pre-training text encoders as discriminators rather than generators},
  author={Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D},
  journal={arXiv preprint arXiv:2003.10555},
  year={2020}
}

@article{sanh2019distilbert,
  title={{DistilBERT}, a distilled version of {BERT}: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{phang2018sentence,
  title={Sentence encoders on {STILTs}: Supplementary training on intermediate labeled-data tasks},
  author={Phang, Jason and F{\'e}vry, Thibault and Bowman, Samuel R.},
  journal={arXiv preprint arXiv:1811.01088},
  year={2018}
}

@inproceedings{ruder2019transfer,
  title={Transfer Learning in Natural Language Processing},
  author={Ruder, Sebastian and Peters, Matthew E. and Swayamdipta, Swabha and Wolf, Thomas},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials},
  pages={15--18},
  year={2019}
}

@article{arivazhagan2019massively,
  title={Massively Multilingual Neural Machine Translation in the Wild: Findings and Challenges},
  author={Arivazhagan, Naveen and Bapna, Ankur and Firat, Orhan and Lepikhin, Dmitry and Johnson, Melvin and Krikun, Maxim and Chen, Mia Xu and Cao, Yuan and Foster, George and Cherry, Colin and others},
  journal={arXiv preprint arXiv:1907.05019},
  year={2019}
}

@inproceedings{bojar2014findings,
  title={Findings of the 2014 Workshop on Statistical Machine Translation},
  author={Bojar, Ond{\v{r}}ej and Buck, Christian and Federmann, Christian and Haddow, Barry and Koehn, Philipp and Leveling, Johannes and Monz, Christof and Pecina, Pavel and Post, Matt and Saint-Amand, Herve and others},
  booktitle={Proceedings of the Ninth Workshop on Statistical Machine Translation},
  year={2014},
}

@inproceedings{bojar2015findings,
  title={Findings of the 2015 Workshop on Statistical Machine Translation},
  author={Bojar, Ond{\v{r}}ej and Chatterjee, Rajen and Federmann, Christian and Haddow, Barry and Huck, Matthias and Hokamp, Chris and Koehn, Philipp and Logacheva, Varvara and Monz, Christof and Negri, Matteo and others},
  booktitle={Proceedings of the Tenth Workshop on Statistical Machine Translation},
  year={2015}
}

@inproceedings{bojar2016findings,
  title={Findings of the 2016 conference on machine translation},
  author={Bojar, Ond{\v{r}}ej and Chatterjee, Rajen and Federmann, Christian and Graham, Yvette and Haddow, Barry and Huck, Matthias and Yepes, Antonio Jimeno and Koehn, Philipp and Logacheva, Varvara and Monz, Christof and others},
  booktitle={Proceedings of the First Conference on Machine Translation},
  year={2016}
}

@article{subramanian2018learning,
  title={Learning general purpose distributed sentence representations via large scale multi-task learning},
  author={Subramanian, Sandeep and Trischler, Adam and Bengio, Yoshua and Pal, Christopher J.},
  journal={arXiv preprint arXiv:1804.00079},
  year={2018}
}

@article{logeswaran2018efficient,
  title={An efficient framework for learning sentence representations},
  author={Logeswaran, Lajanugen and Lee, Honglak},
  journal={arXiv preprint arXiv:1803.02893},
  year={2018}
}

@article{hill2016learning,
  title={Learning distributed representations of sentences from unlabelled data},
  author={Hill, Felix and Cho, Kyunghyun and Korhonen, Anna},
  journal={arXiv preprint arXiv:1602.03483},
  year={2016}
}

@article{conneau2017supervised,
  title={Supervised learning of universal sentence representations from natural language inference data},
  author={Conneau, Alexis and Kiela, Douwe and Schwenk, Holger and Barrault, Loic and Bordes, Antoine},
  journal={arXiv preprint arXiv:1705.02364},
  year={2017}
}

@article{edunov2018understanding,
  title={Understanding back-translation at scale},
  author={Edunov, Sergey and Ott, Myle and Auli, Michael and Grangier, David},
  journal={arXiv preprint arXiv:1808.09381},
  year={2018}
}

@article{lample2019cross,
  title={Cross-lingual language model pretraining},
  author={Lample, Guillaume and Conneau, Alexis},
  journal={arXiv preprint arXiv:1901.07291},
  year={2019}
}

@article{wang2019structbert,
  title={{StructBERT}: Incorporating Language Structures into Pre-training for Deep Language Understanding},
  author={Wang, Wei and Bi, Bin and Yan, Ming and Wu, Chen and Bao, Zuyi and Peng, Liwei and Si, Luo},
  journal={arXiv preprint arXiv:1908.04577},
  year={2019}
}

@article{jiao2019tinybert,
  title={{TinyBERT}: Distilling {BERT} for Natural Language Understanding},
  author={Jiao, Xiaoqi and Yin, Yichun and Shang, Lifeng and Jiang, Xin and Chen, Xiao and Li, Linlin and Wang, Fang and Liu, Qun},
  journal={arXiv preprint arXiv:1909.10351},
  year={2019}
}

@article{zhu2019freelb,
  title={FreeLB: Enhanced Adversarial Training for Language Understanding},
  author={Zhu, Chen and Cheng, Yu and Gan, Zhe and Sun, Siqi and Goldstein, Thomas and Liu, Jingjing},
  journal={arXiv preprint arXiv:1909.11764},
  year={2019}
}

@article{kocijan2019surprisingly,
  title={A Surprisingly Robust Trick for {Winograd} Schema Challenge},
  author={Kocijan, Vid and Cretu, Ana-Maria and Camburu, Oana-Maria and Yordanov, Yordan and Lukasiewicz, Thomas},
  journal={arXiv preprint arXiv:1905.06290},
  year={2019}
}

@inproceedings{rahman2012resolving,
  title={Resolving complex cases of definite pronouns: the {Winograd} schema challenge},
  author={Rahman, Altaf and Ng, Vincent},
  booktitle={Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
  year={2012},
  organization={Association for Computational Linguistics}
}

@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}

@article{conneau2018senteval,
  title={{SentEval}: An evaluation toolkit for universal sentence representations},
  author={Conneau, Alexis and Kiela, Douwe},
  journal={arXiv preprint arXiv:1803.05449},
  year={2018}
}

@article{nallapati2016abstractive,
  title={Abstractive text summarization using sequence-to-sequence {RNN}s and beyond},
  author={Ramesh Nallapati and Bowen Zhou and Cicero Nogueira dos santos and Caglar Gulcehre and Bing Xiang},
  journal={arXiv preprint arXiv:1602.06023},
  year={2016}
}

@article{see2017get,
  title={Get to the point: Summarization with pointer-generator networks},
  author={See, Abigail and Liu, Peter J. and Manning, Christopher D.},
  journal={arXiv preprint arXiv:1704.04368},
  year={2017}
}

@article{he2019hybrid,
  title={A Hybrid Neural Network Model for Commonsense Reasoning},
  author={He, Pengcheng and Liu, Xiaodong and Chen, Weizhu and Gao, Jianfeng},
  journal={arXiv preprint arXiv:1907.11983},
  year={2019}
}

@article{joshi2017triviaqa,
  title={{TriviaQA}: A large scale distantly supervised challenge dataset for reading comprehension},
  author={Joshi, Mandar and Choi, Eunsol and Weld, Daniel S. and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1705.03551},
  year={2017}
}

@article{trischler2016newsqa,
  title={{NewsQA}: A machine comprehension dataset},
  author={Trischler, Adam and Wang, Tong and Yuan, Xingdi and Harris, Justin and Sordoni, Alessandro and Bachman, Philip and Suleman, Kaheer},
  journal={arXiv preprint arXiv:1611.09830},
  year={2016}
}

@article{paulus2017deep,
  title={A deep reinforced model for abstractive summarization},
  author={Paulus, Romain and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1705.04304},
  year={2017}
}

@article{liu2019fine,
  title={Fine-tune {BERT} for Extractive Summarization},
  author={Liu, Yang},
  journal={arXiv preprint arXiv:1903.10318},
  year={2019}
}

@article{huang2018gpipe,
  title={{GPipe}: Efficient training of giant neural networks using pipeline parallelism},
  author={Huang, Yanping and Cheng, Yonglong and Chen, Dehao and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V and Chen, Zhifeng},
  journal={arXiv preprint arXiv:1811.06965},
  year={2018}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@article{konevcny2016federated,
  title={Federated learning: Strategies for improving communication efficiency},
  author={Kone{\v{c}}n{\`y}, Jakub and McMahan, H. Brendan and Yu, Felix X. and Richt{\'a}rik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
  journal={arXiv preprint arXiv:1610.05492},
  year={2016}
}

@article{konevcny2015federated,
  title={Federated optimization: Distributed optimization beyond the datacenter},
  author={Kone{\v{c}}n{\`y}, Jakub and McMahan, Brendan and Ramage, Daniel},
  journal={arXiv preprint arXiv:1511.03575},
  year={2015}
}

@article{zhang2018record,
  title={{ReCoRD}: Bridging the gap between human and machine commonsense reading comprehension},
  author={Zhang, Sheng and Liu, Xiaodong and Liu, Jingjing and Gao, Jianfeng and Duh, Kevin and Van Durme, Benjamin},
  journal={arXiv preprint arXiv:1810.12885},
  year={2018}
}

@article{clark2019boolq,
  title={{BoolQ}: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  author={Clark, Christopher and Lee, Kenton and Chang, Ming-Wei and Kwiatkowski, Tom and Collins, Michael and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1905.10044},
  year={2019}
}

@article{keskar2019ctrl,
  title={{CTRL}: A conditional transformer language model for controllable generation},
  author={Keskar, Nitish Shirish and McCann, Bryan and Varshney, Lav R. and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1909.05858},
  year={2019}
}

@article{yang2019deepening,
  title={Deepening Hidden Representations from Pre-trained Language Models for Natural Language Understanding},
  author={Yang, Junjie and Zhao, Hai},
  journal={arXiv preprint arXiv:1911.01940},
  year={2019}
}

@article{zhang2019pegasus,
  title={PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization},
  author={Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter J},
  journal={arXiv preprint arXiv:1912.08777},
  year={2019}
}

@article{sun2019ernie,
  title={ERNIE: Enhanced Representation through Knowledge Integration},
  author={Sun, Yu and Wang, Shuohuan and Li, Yukun and Feng, Shikun and Chen, Xuyi and Zhang, Han and Tian, Xin and Zhu, Danxiang and Tian, Hao and Wu, Hua},
  journal={arXiv preprint arXiv:1904.09223},
  year={2019}
}

@article{keskar2019unifying,
  title={Unifying question answering and text classification via span extraction},
  author={Keskar, Nitish Shirish and McCann, Bryan and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1904.09286},
  year={2019}
}

@article{grave2018learning,
  title={Learning word vectors for 157 languages},
  author={Grave, Edouard and Bojanowski, Piotr and Gupta, Prakhar and Joulin, Armand and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1802.06893},
  year={2018}
}

@inproceedings{habernal2016c4corpus,
  title={{C4Corpus}: Multilingual Web-size corpus with free license},
  author={Habernal, Ivan and Zayed, Omnia and Gurevych, Iryna},
  booktitle={Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)},
  pages={914--922},
  year={2016}
}

@article{voita2019bottom,
  title={The bottom-up evolution of representations in the transformer: A study with machine translation and language modeling objectives},
  author={Voita, Elena and Sennrich, Rico and Titov, Ivan},
  journal={arXiv preprint arXiv:1909.01380},
  year={2019}
}

@phdthesis{ruder2019neural,
  title={Neural transfer learning for natural language processing},
  author={Ruder, Sebastian},
  school={NUI Galway},
  year={2019}
}

@article{li2012literature,
  title={Literature survey: domain adaptation algorithms for natural language processing},
  author={Li, Qi},
  year={2012}
}

@inproceedings{ratner2018snorkel,
  title={{Snorkel MeTaL}: Weak supervision for multi-task learning},
  author={Ratner, Alex and Hancock, Braden and Dunnmon, Jared and Goldman, Roger and R{\'e}, Christopher},
  booktitle={Proceedings of the Second Workshop on Data Management for End-To-End Machine Learning},
  year={2018}
}

@inproceedings{beltagy2019scibert,
  title={{SciBERT}: A pretrained language model for scientific text},
  author={Beltagy, Iz and Lo, Kyle and Cohan, Arman},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  year={2019}
}