# Neural Machine Translation by Jointly Learning to Align and Translate
## الترجمة الآلية العصبية من خلال التعلم المشترك للمحاذاة والترجمة

**arXiv ID:** 1409.0473
**Authors:** Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio
**Year:** 2014
**Categories:** Computation and Language (cs.CL); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)
**Translation Quality:** 0.94
**Glossary Terms Used:** neural machine translation (الترجمة الآلية العصبية), machine translation (الترجمة الآلية), statistical machine translation (الترجمة الآلية الإحصائية), neural network (شبكة عصبية), encoder-decoder (المشفر-مفكك الشفرة), attention mechanism (آلية الانتباه), alignment (محاذاة), vector (متجه), bottleneck (عنق الزجاجة), architecture (معمارية), performance (أداء)

### English Abstract
Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.

### الملخص العربي
الترجمة الآلية العصبية هي نهج مقترح مؤخراً للترجمة الآلية. على عكس الترجمة الآلية الإحصائية التقليدية، تهدف الترجمة الآلية العصبية إلى بناء شبكة عصبية واحدة يمكن ضبطها بشكل مشترك لتعظيم أداء الترجمة. النماذج المقترحة مؤخراً للترجمة الآلية العصبية تنتمي غالباً إلى عائلة المشفرات-مفككات الشفرة وتتكون من مشفر يشفر الجملة المصدر إلى متجه ذي طول ثابت، يولد منه مفكك الشفرة الترجمة. في هذا البحث، نفترض أن استخدام متجه ذي طول ثابت يشكل عنق زجاجة في تحسين أداء هذه المعمارية الأساسية للمشفر-مفكك الشفرة، ونقترح توسيع ذلك من خلال السماح للنموذج بالبحث التلقائي (الناعم) عن أجزاء من الجملة المصدر ذات الصلة بالتنبؤ بالكلمة المستهدفة، دون الحاجة إلى تشكيل هذه الأجزاء كقطعة صلبة بشكل صريح. باستخدام هذا النهج الجديد، نحقق أداء ترجمة مماثلاً لنظام متقدم قائم على العبارات في مهمة الترجمة من الإنجليزية إلى الفرنسية. علاوة على ذلك، يكشف التحليل النوعي أن المحاذاة (الناعمة) التي يجدها النموذج تتوافق بشكل جيد مع حدسنا.

### Back-Translation (Validation)
Neural machine translation is a recently proposed approach to machine translation. Unlike traditional statistical machine translation, neural machine translation aims to build a single neural network that can be jointly tuned to maximize translation performance. Recently proposed models for neural machine translation often belong to the family of encoder-decoders and consist of an encoder that encodes the source sentence into a fixed-length vector, from which the decoder generates the translation. In this research, we hypothesize that using a fixed-length vector constitutes a bottleneck in improving the performance of this basic encoder-decoder architecture, and we propose to extend this by allowing the model to automatically (soft) search for parts of the source sentence relevant to predicting the target word, without needing to explicitly form these parts as a hard segment. Using this new approach, we achieve translation performance comparable to an advanced phrase-based system on the English-to-French translation task. Furthermore, qualitative analysis reveals that the (soft) alignment found by the model agrees well with our intuition.

### Translation Metrics
- Iterations: 1
- Final Score: 0.94
- Quality: High
- Semantic Equivalence: Excellent - preserves the key innovation of attention mechanism
- Technical Accuracy: Very high - correctly translates encoder-decoder, attention, and alignment concepts
- Completeness: 100% - all technical details and findings preserved
- Coherence: Natural Arabic flow while maintaining technical precision
- Glossary Consistency: Strong use of established neural network and NLP terms
