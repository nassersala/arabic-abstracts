---
# Randomized Numerical Linear Algebra: A Perspective on the Field With an Eye to Software
## الجبر الخطي العددي العشوائي: منظور للمجال مع نظرة للبرمجيات

**arXiv ID:** 2302.11474
**Authors:** Riley Murray, James Demmel, Michael W. Mahoney, N. Benjamin Erichson, Maksim Melnichenko, Osman Asif Malik, Laura Grigori, Piotr Luszczek, Michał Dereziński, Miles E. Lopes, Tianyu Liang, Hengrui Luo, Jack Dongarra
**Year:** 2023
**Categories:** Numerical Analysis (math.NA); Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)
**Translation Quality:** 0.93
**Glossary Terms Used:** algorithm (خوارزمية), machine learning (تعلم الآلة), matrix (مصفوفة), optimization (تحسين), library (مكتبة), data structure (بنية البيانات)

### English Abstract
Randomized numerical linear algebra - RandNLA, for short - concerns the use of randomization as a resource to develop improved algorithms for large-scale linear algebra computations. The origins of contemporary RandNLA lay in theoretical computer science, where it blossomed from a simple idea: randomization provides an avenue for computing approximate solutions to linear algebra problems more efficiently than deterministic algorithms. This idea proved fruitful in the development of scalable algorithms for machine learning and statistical data analysis applications. However, RandNLA's true potential only came into focus upon integration with the fields of numerical analysis and "classical" numerical linear algebra. Through the efforts of many individuals, randomized algorithms have been developed that provide full control over the accuracy of their solutions and that can be every bit as reliable as algorithms that might be found in libraries such as LAPACK. Recent years have even seen the incorporation of certain RandNLA methods into MATLAB, the NAG Library, NVIDIA's cuSOLVER, and SciKit-Learn. For all its success, we believe that RandNLA has yet to realize its full potential. In particular, we believe the scientific community stands to benefit significantly from suitably defined "RandBLAS" and "RandLAPACK" libraries, to serve as standards conceptually analogous to BLAS and LAPACK. This 200-page monograph represents a step toward defining such standards. In it, we cover topics spanning basic sketching, least squares and optimization, low-rank approximation, full matrix decompositions, leverage score sampling, and sketching data with tensor product structures (among others). Much of the provided pseudo-code has been tested via publicly available MATLAB and Python implementations.

### الملخص العربي
الجبر الخطي العددي العشوائي - أو RandNLA اختصاراً - يتعلق باستخدام العشوائية كمورد لتطوير خوارزميات محسّنة لحسابات الجبر الخطي واسعة النطاق. تكمن أصول RandNLA المعاصرة في علوم الحاسوب النظرية، حيث ازدهرت من فكرة بسيطة: توفر العشوائية طريقة لحساب حلول تقريبية لمسائل الجبر الخطي بكفاءة أكبر من الخوارزميات الحتمية. أثبتت هذه الفكرة ثمارها في تطوير خوارزميات قابلة للتوسع لتطبيقات تعلم الآلة وتحليل البيانات الإحصائي. ومع ذلك، لم تتضح الإمكانات الحقيقية لـ RandNLA إلا عند التكامل مع مجالات التحليل العددي والجبر الخطي العددي "الكلاسيكي". من خلال جهود العديد من الأفراد، تم تطوير خوارزميات عشوائية توفر تحكماً كاملاً في دقة حلولها ويمكن أن تكون موثوقة تماماً مثل الخوارزميات التي قد توجد في مكتبات مثل LAPACK. شهدت السنوات الأخيرة حتى دمج بعض طرق RandNLA في MATLAB ومكتبة NAG وcuSOLVER من NVIDIA وSciKit-Learn. على الرغم من كل نجاحها، نعتقد أن RandNLA لم تحقق إمكاناتها الكاملة بعد. على وجه الخصوص، نعتقد أن المجتمع العلمي سيستفيد بشكل كبير من مكتبات "RandBLAS" و"RandLAPACK" المعرّفة بشكل مناسب، لتكون بمثابة معايير مماثلة مفاهيمياً لـ BLAS وLAPACK. تمثل هذه المونوغرافيا المكونة من 200 صفحة خطوة نحو تحديد مثل هذه المعايير. فيها، نغطي موضوعات تمتد من الرسم التخطيطي الأساسي، والمربعات الصغرى والتحسين، وتقريب الرتبة المنخفضة، وتحليلات المصفوفة الكاملة، وأخذ عينات نقاط الرافعة، ورسم البيانات بهياكل حاصل الضرب الموتري (من بين أمور أخرى). تم اختبار الكثير من الشفرة الزائفة المقدمة عبر تطبيقات MATLAB وPython المتاحة للعامة.

### Back-Translation (Validation)
Randomized numerical linear algebra - or RandNLA for short - concerns the use of randomness as a resource to develop improved algorithms for large-scale linear algebra computations. The origins of contemporary RandNLA lie in theoretical computer science, where it flourished from a simple idea: randomness provides a way to compute approximate solutions to linear algebra problems more efficiently than deterministic algorithms. This idea proved fruitful in developing scalable algorithms for machine learning and statistical data analysis applications. However, the true potential of RandNLA only became clear upon integration with the fields of numerical analysis and "classical" numerical linear algebra. Through the efforts of many individuals, randomized algorithms have been developed that provide full control over the accuracy of their solutions and can be as reliable as algorithms found in libraries such as LAPACK. Recent years have even seen the integration of some RandNLA methods into MATLAB, the NAG Library, NVIDIA's cuSOLVER, and SciKit-Learn. Despite all its success, we believe RandNLA has not yet realized its full potential. In particular, we believe the scientific community would benefit significantly from properly defined "RandBLAS" and "RandLAPACK" libraries, to serve as standards conceptually analogous to BLAS and LAPACK. This 200-page monograph represents a step toward defining such standards. In it, we cover topics ranging from basic sketching, least squares and optimization, low-rank approximation, full matrix decompositions, leverage score sampling, and sketching data with tensor product structures (among others). Much of the provided pseudocode has been tested via publicly available MATLAB and Python implementations.

### Translation Metrics
- Iterations: 1
- Final Score: 0.93
- Quality: High
---
