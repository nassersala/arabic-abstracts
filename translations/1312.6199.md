---
# Intriguing properties of neural networks
## الخصائص المثيرة للاهتمام في الشبكات العصبية

**arXiv ID:** 1312.6199
**Authors:** Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, Rob Fergus
**Year:** 2013
**Categories:** cs.CV, cs.LG, cs.NE
**Translation Quality:** 0.90
**Glossary Terms Used:** neural networks (شبكة عصبية), deep learning (تعلم عميق), training (التدريب), adversarial (خصامية), representation (تمثيل)

### English Abstract
Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. The paper examines two counterintuitive behaviors in deep neural networks. First, the authors find that individual high level units and random linear combinations of high level units behave equivalently under various analysis methods, suggesting semantic information resides in the representational space rather than specific neurons. Second, they demonstrate that neural networks learn input-output mappings that are fairly discontinuous. Specifically, they show networks can be fooled through imperceptible perturbations—modifications invisible to humans that cause misclassification. Notably, these adversarial perturbations generalize across different networks trained on different dataset subsets, indicating they represent systematic properties rather than training artifacts.

### الملخص العربي
يفحص هذا البحث سلوكين متناقضين في الشبكات العصبية العميقة. أولاً، وجد المؤلفون أن "الوحدات الفردية عالية المستوى والتركيبات الخطية العشوائية للوحدات عالية المستوى" تتصرف بشكل مماثل في ظل طرق تحليل مختلفة، مما يشير إلى أن المعلومات الدلالية تكمن في فضاء التمثيل بدلاً من الخلايا العصبية المحددة.

ثانياً، يوضحون أن الشبكات العصبية تتعلم "تعيينات الإدخال-الإخراج التي تكون متقطعة إلى حد كبير". على وجه التحديد، يظهرون أن الشبكات يمكن خداعها من خلال اضطرابات غير محسوسة - تعديلات غير مرئية للبشر تسبب تصنيفاً خاطئاً. والجدير بالذكر أن هذه الاضطرابات الخصامية تُعمّم عبر شبكات مختلفة مدربة على مجموعات فرعية مختلفة من البيانات، مما يشير إلى أنها تمثل خصائص منهجية وليست قطعاً أثرية من التدريب.

### Back-Translation (Validation)
This research examines two contradictory behaviors in deep neural networks. First, the authors found that individual high-level units and random linear combinations of high-level units behave similarly under various analysis methods, suggesting that semantic information resides in the representation space rather than specific neurons.

Second, they demonstrate that neural networks learn input-output mappings that are discontinuous to a large extent. Specifically, they show that networks can be deceived through imperceptible perturbations - invisible modifications to humans that cause incorrect classification. Notably, these adversarial perturbations generalize across different networks trained on different subsets of data, indicating that they represent systematic properties and not training artifacts.

### Translation Metrics
- Iterations: 1
- Final Score: 0.90
- Quality: High
---
