# Accelerating BLAS and LAPACK via Efficient Floating Point Architecture Design
## تسريع BLAS و LAPACK عبر تصميم معمارية فعالة للنقطة العائمة

**arXiv ID:** 1610.08705
**Authors:** Farhad Merchant, Anupam Chattopadhyay, Soumyendu Raha, S K Nandy, Ranjani Narayan
**Year:** 2016
**Categories:** cs.DC, cs.PF
**Translation Quality:** 0.93
**Glossary Terms Used:** linear algebra, algorithm, architecture, optimization, performance, bandwidth, pipeline

### English Abstract
Basic Linear Algebra Subprograms (BLAS) and Linear Algebra Package (LAPACK) form basic building blocks for several High Performance Computing (HPC) applications and hence dictate performance of the HPC applications. Performance in such tuned packages is attained through tuning of several algorithmic and architectural parameters such as number of parallel operations in the Directed Acyclic Graph of the BLAS/LAPACK routines, sizes of the memories in the memory hierarchy of the underlying platform, bandwidth of the memory, and structure of the compute resources in the underlying platform. In this paper, we closely investigate the impact of the Floating Point Unit (FPU) micro-architecture for performance tuning of BLAS and LAPACK. We present theoretical analysis for pipeline depth of different floating point operations like multiplier, adder, square root, and divider followed by characterization of BLAS and LAPACK to determine several parameters required in the theoretical framework for deciding optimum pipeline depth of the floating operations. A simple design of a Processing Element (PE) is presented and shown that the PE outperforms the most recent custom realizations of BLAS and LAPACK by 1.1X to 1.5X in Gflops/W, and 1.9X to 2.1X in Gflops/mm^2.

### الملخص العربي
تشكل البرامج الفرعية الأساسية للجبر الخطي (BLAS) وحزمة الجبر الخطي (LAPACK) الوحدات البنائية الأساسية للعديد من تطبيقات الحوسبة عالية الأداء (HPC)، وبالتالي تحدد أداء تطبيقات HPC. يتم تحقيق الأداء في مثل هذه الحزم المحسّنة من خلال ضبط العديد من المعاملات الخوارزمية والمعمارية مثل عدد العمليات المتوازية في الرسم البياني غير الدوري الموجّه لبرامج BLAS/LAPACK، وأحجام الذاكرة في التسلسل الهرمي للذاكرة للمنصة الأساسية، وعرض النطاق الترددي للذاكرة، وبنية موارد الحوسبة في المنصة الأساسية. في هذه الورقة، نحقق بعناية في تأثير المعمارية الدقيقة لوحدة النقطة العائمة (FPU) لضبط أداء BLAS و LAPACK. نقدم تحليلاً نظرياً لعمق خط الأنابيب لعمليات النقطة العائمة المختلفة مثل المضارب والجامع والجذر التربيعي والمقسم، متبوعاً بتوصيف BLAS و LAPACK لتحديد المعاملات المختلفة المطلوبة في الإطار النظري لتحديد عمق خط الأنابيب الأمثل لعمليات النقطة العائمة. يتم تقديم تصميم بسيط لعنصر المعالجة (PE) ويُظهر أن PE يتفوق على أحدث التطبيقات المخصصة لـ BLAS و LAPACK بمقدار 1.1X إلى 1.5X في Gflops/W، و1.9X إلى 2.1X في Gflops/mm^2.

### Back-Translation (Validation)
Basic Linear Algebra Subprograms (BLAS) and Linear Algebra Package (LAPACK) form the basic building blocks for many High Performance Computing (HPC) applications, and thus determine the performance of HPC applications. Performance in such optimized packages is achieved through tuning several algorithmic and architectural parameters such as the number of parallel operations in the directed acyclic graph of BLAS/LAPACK routines, memory sizes in the memory hierarchy for the underlying platform, memory bandwidth, and the structure of computing resources in the underlying platform. In this paper, we carefully investigate the impact of Floating Point Unit (FPU) micro-architecture on tuning BLAS and LAPACK performance. We present theoretical analysis for pipeline depth of different floating point operations such as multiplier, adder, square root, and divider, followed by characterization of BLAS and LAPACK to determine the various parameters required in the theoretical framework for determining optimal pipeline depth for floating point operations. A simple design of a Processing Element (PE) is presented and shows that the PE outperforms the most recent custom realizations of BLAS and LAPACK by 1.1X to 1.5X in Gflops/W, and 1.9X to 2.1X in Gflops/mm^2.

### Translation Metrics
- Iterations: 1
- Final Score: 0.93
- Quality: High
