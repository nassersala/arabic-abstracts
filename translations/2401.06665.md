# PolyTOPS: Reconfigurable and Flexible Polyhedral Scheduler
## PolyTOPS: جدولة متعددة السطوح قابلة لإعادة التكوين ومرنة

**arXiv ID:** 2401.06665
**Authors:** Gianpietro Consolaro, Zhen Zhang, Harenome Razanajato, Nelson Lossing, Nassim Tchoulak, Adilla Susungi, Artur Cesar Araujo Alves, Renwei Zhang, Denis Barthou, Corinne Ancourt, Cedric Bastoul
**Year:** 2024
**Categories:** cs.DC, cs.CL, cs.PF
**Translation Quality:** 0.92
**Glossary Terms Used:** polyhedral techniques, code optimization, compiler, loop optimization, scheduler, architecture, parallelism, NPU, Neural Processing Unit, AI, heterogeneous architecture, deep learning compiler, code generator, speedup, multicore

### English Abstract
Polyhedral techniques have been widely used for automatic code optimization in low-level compilers and higher-level processes. Loop optimization is central to this technique, and several polyhedral schedulers like Feautrier, Pluto, isl and Tensor Scheduler have been proposed, each of them targeting a different architecture, parallelism model, or application scenario. The need for scenario-specific optimization is growing due to the heterogeneity of architectures. One of the most critical cases is represented by NPUs (Neural Processing Units) used for AI, which may require loop optimization with different objectives. Another factor to be considered is the framework or compiler in which polyhedral optimization takes place. Different scenarios, depending on the target architecture, compilation environment, and application domain, may require different kinds of optimization to best exploit the architecture feature set. We introduce a new configurable polyhedral scheduler, PolyTOPS, that can be adjusted to various scenarios with straightforward, high-level configurations. This scheduler allows the creation of diverse scheduling strategies that can be both scenario-specific (like state-of-the-art schedulers) and kernel-specific, breaking the concept of a one-size-fits-all scheduler approach. PolyTOPS has been used with isl and CLooG as code generators and has been integrated in MindSpore AKG deep learning compiler. Experimental results in different scenarios show good performance: a geomean speedup of 7.66x on MindSpore (for the NPU Ascend architecture) hybrid custom operators over isl scheduling, a geomean speedup up to 1.80x on PolyBench on different multicore architectures over Pluto scheduling. Finally, some comparisons with different state-of-the-art tools are presented in the PolyMage scenario.

### الملخص العربي
تم استخدام التقنيات متعددة السطوح على نطاق واسع للتحسين التلقائي للشفرة في المترجمات منخفضة المستوى والعمليات عالية المستوى. يعتبر تحسين الحلقات محورياً لهذه التقنية، وتم اقتراح عدة جدولات متعددة السطوح مثل Feautrier وPluto وisl وTensor Scheduler، يستهدف كل منها معمارية أو نموذج تشغيل متوازٍ أو سيناريو تطبيق مختلف. تتزايد الحاجة إلى التحسين الخاص بالسيناريو بسبب تباين المعماريات. واحدة من أكثر الحالات أهمية تمثلها وحدات المعالجة العصبية (NPUs) المستخدمة للذكاء الاصطناعي، والتي قد تتطلب تحسين الحلقات بأهداف مختلفة. عامل آخر يجب مراعاته هو الإطار أو المترجم الذي يحدث فيه التحسين متعدد السطوح. قد تتطلب السيناريوهات المختلفة، اعتماداً على المعمارية المستهدفة وبيئة التجميع ومجال التطبيق، أنواعاً مختلفة من التحسين للاستفادة المثلى من مجموعة ميزات المعمارية. نقدم جدولة جديدة قابلة للتكوين متعددة السطوح، PolyTOPS، يمكن تعديلها لسيناريوهات مختلفة بتكوينات مباشرة عالية المستوى. تسمح هذه الجدولة بإنشاء استراتيجيات جدولة متنوعة يمكن أن تكون خاصة بالسيناريو (مثل الجدولات الحديثة) وخاصة بالنواة، مما يكسر مفهوم نهج الجدولة الواحد الذي يناسب الجميع. تم استخدام PolyTOPS مع isl وCLooG كمولدات شفرة وتم دمجه في مترجم التعلم العميق MindSpore AKG. تُظهر النتائج التجريبية في سيناريوهات مختلفة أداءً جيداً: تسريع متوسط هندسي قدره 7.66 مرة على MindSpore (لمعمارية NPU Ascend) للمشغلات المخصصة الهجينة عن جدولة isl، وتسريع متوسط هندسي يصل إلى 1.80 مرة على PolyBench على معماريات متعددة الأنوية المختلفة عن جدولة Pluto. أخيراً، يتم تقديم بعض المقارنات مع أدوات حديثة مختلفة في سيناريو PolyMage.

### Back-Translation (Validation)
Polyhedral techniques have been widely used for automatic code optimization in low-level compilers and high-level processes. Loop optimization is central to this technique, and several polyhedral schedulers such as Feautrier, Pluto, isl, and Tensor Scheduler have been proposed, each targeting a different architecture, parallel execution model, or application scenario. The need for scenario-specific optimization is increasing due to architectural heterogeneity. One of the most important cases is represented by Neural Processing Units (NPUs) used for artificial intelligence, which may require loop optimization with different objectives. Another factor to consider is the framework or compiler in which polyhedral optimization occurs. Different scenarios, depending on the target architecture, compilation environment, and application domain, may require different types of optimization for optimal utilization of the architecture's feature set. We introduce a new configurable polyhedral scheduler, PolyTOPS, that can be adjusted for different scenarios with straightforward high-level configurations. This scheduler allows the creation of diverse scheduling strategies that can be scenario-specific (like modern schedulers) and kernel-specific, breaking the one-size-fits-all scheduling approach concept. PolyTOPS has been used with isl and CLooG as code generators and has been integrated into the MindSpore AKG deep learning compiler. Experimental results in different scenarios show good performance: a geometric mean speedup of 7.66× on MindSpore (for the NPU Ascend architecture) for hybrid custom operators over isl scheduling, and a geometric mean speedup up to 1.80× on PolyBench on different multi-core architectures over Pluto scheduling. Finally, some comparisons with different state-of-the-art tools are presented in the PolyMage scenario.

### Translation Metrics
- Iterations: 1
- Final Score: 0.92
- Quality: High
