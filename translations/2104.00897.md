# FT-BLAS: A High Performance BLAS Implementation With Online Fault Tolerance
## FT-BLAS: تطبيق عالي الأداء لـ BLAS مع تحمل الأخطاء المباشر

**arXiv ID:** 2104.00897
**Authors:** Yujia Zhai, Elisabeth Giem, Quan Fan, Kai Zhao, Jinyang Liu, Zizhong Chen
**Year:** 2021
**Categories:** cs.DC, cs.MS
**Translation Quality:** 0.90
**Glossary Terms Used:** linear algebra, BLAS, algorithm, optimization, performance, machine learning, fault tolerance, kernel

### English Abstract
Basic Linear Algebra Subprograms (BLAS) is a core library in scientific computing and machine learning. This paper presents FT-BLAS, a new implementation of BLAS routines that not only tolerates soft errors on the fly, but also provides comparable performance to modern state-of-the-art BLAS libraries on widely-used processors such as Intel Skylake and Cascade Lake. To accommodate the features of BLAS, which contains both memory-bound and computing-bound routines, we propose a hybrid strategy to incorporate fault tolerance into our brand-new BLAS implementation: duplicating computing instructions for memory-bound Level-1 and Level-2 BLAS routines and incorporating an Algorithm-Based Fault Tolerance mechanism for computing-bound Level-3 BLAS routines. Our high performance and low overhead are obtained from delicate assembly-level optimization and a kernel-fusion approach to the computing kernels. Experimental results demonstrate that FT-BLAS offers high reliability and high performance -- faster than Intel MKL, OpenBLAS, and BLIS by up to 3.50%, 22.14% and 21.70%, respectively, for routines spanning all three levels of BLAS we benchmarked, even under hundreds of errors injected per minute.

### الملخص العربي
تُعد البرامج الفرعية الأساسية للجبر الخطي (BLAS) مكتبة أساسية في الحوسبة العلمية وتعلم الآلة. تقدم هذه الورقة FT-BLAS، وهو تطبيق جديد لبرامج BLAS لا يتحمل الأخطاء البرمجية فحسب أثناء التشغيل، بل يوفر أيضاً أداءً مماثلاً لمكتبات BLAS الحديثة المتقدمة على المعالجات واسعة الاستخدام مثل Intel Skylake و Cascade Lake. لاستيعاب ميزات BLAS، التي تحتوي على برامج محدودة بالذاكرة ومحدودة بالحوسبة، نقترح استراتيجية هجينة لدمج تحمل الأخطاء في تطبيق BLAS الجديد الخاص بنا: مضاعفة تعليمات الحوسبة للبرامج المحدودة بالذاكرة من المستوى الأول والثاني من BLAS، ودمج آلية تحمل الأخطاء القائمة على الخوارزمية للبرامج المحدودة بالحوسبة من المستوى الثالث من BLAS. يتم الحصول على أدائنا العالي والتكلفة المنخفضة من التحسين الدقيق على مستوى التجميع ونهج دمج النواة لنوى الحوسبة. تُظهر النتائج التجريبية أن FT-BLAS يوفر موثوقية عالية وأداءً عالياً -- أسرع من Intel MKL و OpenBLAS و BLIS بما يصل إلى 3.50٪ و 22.14٪ و 21.70٪ على التوالي، للبرامج التي تمتد على جميع المستويات الثلاثة من BLAS التي قمنا بقياسها، حتى مع حقن مئات الأخطاء في الدقيقة.

### Back-Translation (Validation)
Basic Linear Algebra Subprograms (BLAS) is a core library in scientific computing and machine learning. This paper presents FT-BLAS, a new implementation of BLAS routines that not only tolerates software errors during operation, but also provides performance comparable to modern advanced BLAS libraries on widely-used processors such as Intel Skylake and Cascade Lake. To accommodate BLAS features, which contain memory-bound and compute-bound routines, we propose a hybrid strategy to incorporate fault tolerance into our new BLAS implementation: duplicating computing instructions for memory-bound Level-1 and Level-2 BLAS routines, and incorporating an Algorithm-Based Fault Tolerance mechanism for compute-bound Level-3 BLAS routines. Our high performance and low overhead are obtained from precise assembly-level optimization and a kernel-fusion approach for computing kernels. Experimental results show that FT-BLAS provides high reliability and high performance -- faster than Intel MKL, OpenBLAS, and BLIS by up to 3.50%, 22.14%, and 21.70% respectively, for routines spanning all three levels of BLAS that we benchmarked, even with hundreds of errors injected per minute.

### Translation Metrics
- Iterations: 1
- Final Score: 0.90
- Quality: High
