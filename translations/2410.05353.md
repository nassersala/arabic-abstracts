# Towards a Categorical Foundation of Deep Learning: A Survey
## نحو أساس فئوي للتعلم العميق: استعراض

**arXiv ID:** 2410.05353
**Authors:** Francesco Riccardo Crescenzi
**Year:** 2024
**Categories:** Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Category Theory (math.CT)
**Translation Quality:** 0.94
**Glossary Terms Used:** machine learning, deep learning, category, optics, gradient, functor, neural network, algebra, integral transform, string diagram (new), abstraction, reproducibility (new)

### English Abstract
The unprecedented pace of machine learning research has lead to incredible advances, but also poses hard challenges. At present, the field lacks strong theoretical underpinnings, and many important achievements stem from ad hoc design choices which are hard to justify in principle and whose effectiveness often goes unexplained. Research debt is increasing and many papers are found not to be reproducible. This thesis is a survey that covers some recent work attempting to study machine learning categorically. Category theory is a branch of abstract mathematics that has found successful applications in many fields, both inside and outside mathematics. Acting as a lingua franca of mathematics and science, category theory might be able to give a unifying structure to the field of machine learning. This could solve some of the aforementioned problems. In this work, we mainly focus on the application of category theory to deep learning. Namely, we discuss the use of categorical optics to model gradient-based learning, the use of categorical algebras and integral transforms to link classical computer science to neural networks, the use of functors to link different layers of abstraction and preserve structure, and, finally, the use of string diagrams to provide detailed representations of neural network architectures.

### الملخص العربي
الوتيرة غير المسبوقة لأبحاث تعلم الآلة أدت إلى تقدمات مذهلة، ولكنها تطرح أيضاً تحديات صعبة. في الوقت الحاضر، يفتقر المجال إلى أسس نظرية قوية، والعديد من الإنجازات المهمة تنبع من خيارات تصميمية مخصصة يصعب تبريرها من حيث المبدأ وغالباً ما تظل فعاليتها غير مفسرة. الدين البحثي يتزايد والعديد من الأوراق تبين أنها غير قابلة لإعادة الإنتاج. هذه الأطروحة هي استعراض يغطي بعض الأعمال الحديثة التي تحاول دراسة تعلم الآلة فئوياً. نظرية الفئات هي فرع من الرياضيات المجردة وجدت تطبيقات ناجحة في العديد من المجالات، داخل الرياضيات وخارجها على حد سواء. بوصفها لغة مشتركة للرياضيات والعلوم، قد تكون نظرية الفئات قادرة على إعطاء بنية موحدة لمجال تعلم الآلة. هذا يمكن أن يحل بعض المشكلات المذكورة أعلاه. في هذا العمل، نركز بشكل رئيسي على تطبيق نظرية الفئات على التعلم العميق. وبالتحديد، نناقش استخدام البصريات الفئوية لنمذجة التعلم القائم على التدرجات، واستخدام الجبر الفئوي والتحويلات التكاملية لربط علم الحاسوب الكلاسيكي بالشبكات العصبية، واستخدام الدوال التصنيفية لربط طبقات مختلفة من التجريد والحفاظ على البنية، وأخيراً، استخدام المخططات الخيطية لتوفير تمثيلات مفصلة لبنى الشبكات العصبية.

### Back-Translation (Validation)
The unprecedented pace of machine learning research has led to amazing advances, but it also poses difficult challenges. At present, the field lacks strong theoretical foundations, and many important achievements stem from ad hoc design choices that are difficult to justify in principle and whose effectiveness often remains unexplained. Research debt is increasing and many papers are shown to be non-reproducible. This thesis is a review covering some recent work attempting to study machine learning categorically. Category theory is a branch of abstract mathematics that has found successful applications in many fields, both inside and outside mathematics. As a common language for mathematics and science, category theory may be able to give a unified structure to the field of machine learning. This could solve some of the aforementioned problems. In this work, we focus primarily on the application of category theory to deep learning. Specifically, we discuss the use of categorical optics to model gradient-based learning, the use of categorical algebra and integral transforms to link classical computer science to neural networks, the use of functors to link different layers of abstraction and preserve structure, and finally, the use of string diagrams to provide detailed representations of neural network architectures.

### Translation Metrics
- Iterations: 1
- Final Score: 0.94
- Quality: High
