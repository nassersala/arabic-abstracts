---
# Scaling Laws for Data Filtering -- Data Curation cannot be Compute Agnostic
## قوانين التوسع لتصفية البيانات -- لا يمكن أن تكون تنظيم البيانات مستقلاً عن الحساب

**arXiv ID:** 2404.07177
**Authors:** Sachin Goyal, Pratyush Maini, Zachary C. Lipton, Aditi Raghunathan, J. Zico Kolter
**Year:** 2024
**Categories:** Machine Learning (cs.LG)
**Translation Quality:** 0.90
**Glossary Terms Used:** scaling laws, data filtering, data curation, training, compute, model, optimization, benchmark, utility, neural network

### English Abstract
The researchers demonstrate that filtering data without considering available training compute leads to suboptimal results. They propose neural scaling laws addressing the quality-quantity tradeoff in web data curation. Their framework characterizes utility across data quality subsets, accounts for diminishing returns with repetition, and models interactions between combined data pools. The authors conclude that data curation cannot be agnostic of the total compute that a model will be trained for and use their methodology to optimize performance on Datacomp benchmarks across varying computational budgets.

### الملخص العربي
يُظهر الباحثون أن تصفية البيانات دون مراعاة الحساب التدريبي المتاح يؤدي إلى نتائج دون المستوى الأمثل. يقترحون قوانين التوسع العصبية التي تعالج المفاضلة بين الجودة والكمية في تنظيم بيانات الويب. يُميِّز إطار عملهم الفائدة عبر مجموعات فرعية من جودة البيانات، ويأخذ في الاعتبار تناقص العوائد مع التكرار، ويُنمذج التفاعلات بين مجموعات البيانات المدمجة. يستنتج المؤلفون أن تنظيم البيانات لا يمكن أن يكون مستقلاً عن إجمالي الحساب الذي سيُدرَّب عليه النموذج ويستخدمون منهجيتهم لتحسين الأداء على معايير Datacomp عبر ميزانيات حسابية متنوعة.

### Back-Translation (Validation)
The researchers show that filtering data without considering available training compute leads to suboptimal results. They propose neural scaling laws that address the quality-quantity tradeoff in web data curation. Their framework characterizes utility across data quality subsets, accounts for diminishing returns with repetition, and models interactions between combined data pools. The authors conclude that data curation cannot be independent of the total compute on which the model will be trained and use their methodology to optimize performance on Datacomp benchmarks across varying computational budgets.

### Translation Metrics
- Iterations: 1
- Final Score: 0.90
- Quality: High
---
