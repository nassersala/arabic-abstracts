# A Survey on the Optimization of Large Language Model-based Agents
## مسح شامل حول تحسين الوكلاء المبنية على نماذج اللغة الكبيرة

**arXiv ID:** 2503.12434
**Authors:** Shangheng Du, Jiabao Zhao, Jinxin Shi, Zhentao Xie, Xin Jiang, Yanhong Bai, Liang He
**Year:** 2025
**Categories:** cs.AI
**Translation Quality:** 0.94
**Glossary Terms Used:** التحسين, خوارزمية, معيار, تعلم معزز, استرجاع

### English Abstract
With the rapid development of Large Language Models (LLMs), LLM-based agents have been widely adopted in various fields, becoming essential for autonomous decision-making and interactive tasks. However, current work typically relies on prompt design or fine-tuning strategies applied to vanilla LLMs, which often leads to limited effectiveness or suboptimal performance in complex agent-related environments. Although LLM optimization techniques can improve model performance across many general tasks, they lack specialized optimization towards critical agent functionalities such as long-term planning, dynamic environmental interaction, and complex decision-making. Although numerous recent studies have explored various strategies to optimize LLM-based agents for complex agent tasks, a systematic review summarizing and comparing these methods from a holistic perspective is still lacking. In this survey, we provide a comprehensive review of LLM-based agent optimization approaches, categorizing them into parameter-driven and parameter-free methods. We first focus on parameter-driven optimization, covering fine-tuning-based optimization, reinforcement learning-based optimization, and hybrid strategies, analyzing key aspects such as trajectory data construction, fine-tuning techniques, reward function design, and optimization algorithms. Additionally, we briefly discuss parameter-free strategies that optimize agent behavior through prompt engineering and external knowledge retrieval. Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of LLM-based agents, and discuss major challenges and promising future directions.

### الملخص العربي
مع التطور السريع لنماذج اللغة الكبيرة، تم اعتماد الوكلاء المبنية على نماذج اللغة الكبيرة على نطاق واسع في مجالات متنوعة، لتصبح أساسية لاتخاذ القرارات المستقلة والمهام التفاعلية. ومع ذلك، يعتمد العمل الحالي عادةً على تصميم الموجهات أو استراتيجيات الضبط الدقيق المطبقة على نماذج اللغة الكبيرة الأساسية، مما يؤدي غالباً إلى فعالية محدودة أو أداء دون المستوى الأمثل في بيئات الوكلاء المعقدة. على الرغم من أن تقنيات تحسين نماذج اللغة الكبيرة يمكن أن تحسن أداء النموذج عبر العديد من المهام العامة، إلا أنها تفتقر إلى التحسين المتخصص نحو الوظائف الحرجة للوكلاء مثل التخطيط طويل الأمد، والتفاعل البيئي الديناميكي، واتخاذ القرارات المعقدة. على الرغم من أن العديد من الدراسات الحديثة استكشفت استراتيجيات مختلفة لتحسين الوكلاء المبنية على نماذج اللغة الكبيرة للمهام المعقدة، لا يزال هناك نقص في مراجعة منهجية تلخص وتقارن هذه الأساليب من منظور شامل. في هذا المسح، نقدم مراجعة شاملة لأساليب تحسين الوكلاء المبنية على نماذج اللغة الكبيرة، ونصنفها إلى أساليب مبنية على المعاملات وأساليب خالية من المعاملات. نركز أولاً على التحسين المبني على المعاملات، ونغطي التحسين القائم على الضبط الدقيق، والتحسين القائم على التعلم المعزز، والاستراتيجيات الهجينة، ونحلل الجوانب الرئيسية مثل بناء بيانات المسار، وتقنيات الضبط الدقيق، وتصميم دالة المكافأة، وخوارزميات التحسين. بالإضافة إلى ذلك، نناقش بإيجاز الاستراتيجيات الخالية من المعاملات التي تحسن سلوك الوكيل من خلال هندسة الموجهات واسترجاع المعرفة الخارجية. أخيراً، نلخص مجموعات البيانات والمعايير المستخدمة للتقييم والضبط، ونراجع التطبيقات الرئيسية للوكلاء المبنية على نماذج اللغة الكبيرة، ونناقش التحديات الرئيسية والاتجاهات المستقبلية الواعدة.

### Back-Translation (Validation)
With the rapid development of large language models, agents built on large language models have been widely adopted across diverse fields, becoming fundamental for autonomous decision-making and interactive tasks. However, current work typically relies on prompt design or fine-tuning strategies applied to basic large language models, which often leads to limited effectiveness or suboptimal performance in complex agent environments. Although large language model optimization techniques can improve model performance across many general tasks, they lack specialized optimization toward critical agent functions such as long-term planning, dynamic environmental interaction, and complex decision-making. Although many recent studies have explored various strategies to optimize agents built on large language models for complex tasks, there is still a lack of systematic review that summarizes and compares these approaches from a comprehensive perspective. In this survey, we provide a comprehensive review of optimization approaches for agents built on large language models, categorizing them into parameter-based and parameter-free methods. We first focus on parameter-based optimization, covering fine-tuning-based optimization, reinforcement learning-based optimization, and hybrid strategies, analyzing key aspects such as trajectory data construction, fine-tuning techniques, reward function design, and optimization algorithms. Additionally, we briefly discuss parameter-free strategies that improve agent behavior through prompt engineering and external knowledge retrieval. Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of agents built on large language models, and discuss major challenges and promising future directions.

### Translation Metrics
- Iterations: 1
- Final Score: 0.94
- Quality: High
