---
# SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis
## SDXL: تحسين نماذج الانتشار الكامنة لتوليد صور عالية الدقة

**arXiv ID:** 2307.01952
**Authors:** Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna, Robin Rombach
**Year:** 2023
**Categories:** cs.CV, cs.AI
**Translation Quality:** 0.90
**Glossary Terms Used:** diffusion models, latent space, text encoders, architecture, training, optimization, generation

### English Abstract
We present SDXL, a latent diffusion model for text-to-image synthesis. Compared to previous versions of Stable Diffusion, SDXL leverages a three times larger UNet backbone: The increase of model parameters is mainly due to more attention blocks and a larger cross-attention context as SDXL uses a second text encoder. We design multiple novel conditioning schemes and train SDXL on multiple aspect ratios. We also introduce a refinement model which is used to improve the visual fidelity of samples generated by SDXL using a post-hoc image-to-image technique. We demonstrate that SDXL shows drastically improved performance compared to previous versions of Stable Diffusion and achieves results competitive with those of black-box state-of-the-art image generators. Code and model weights are available at https://github.com/Stability-AI/generative-models.

### الملخص العربي
يقدم المؤلفون SDXL، وهو نظام انتشار كامن لتوليد الصور من النص يتميز ببنية UNet أكبر ثلاث مرات مقارنة بإصدارات Stable Diffusion السابقة. تشمل الابتكارات الرئيسية مشفرات نصية مزدوجة، واستراتيجيات تكييف جديدة، وتدريب متعدد النسب، ونموذج تحسين لتعزيز الجودة البصرية. يُظهر الباحثون تحسيناً كبيراً في الأداء مقارنة بالنماذج السابقة ونتائج تنافسية مع مولدات الصور المتقدمة المملوكة. يوفرون وصولاً عاماً إلى الكود والأوزان النموذجية.

### Back-Translation (Validation)
The authors present SDXL, a latent diffusion system for text-to-image generation featuring a UNet backbone three times larger compared to previous Stable Diffusion versions. Key innovations include dual text encoders, novel conditioning strategies, multi-aspect ratio training, and a refinement model to enhance visual quality. The researchers demonstrate significant performance improvement compared to previous models and competitive results with advanced proprietary image generators. They provide public access to the code and model weights.

### Translation Metrics
- Iterations: 1
- Final Score: 0.90
- Quality: High
---
