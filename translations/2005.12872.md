---
# End-to-End Object Detection with Transformers
## الكشف عن الأجسام من طرف إلى طرف باستخدام المحولات

**arXiv ID:** 2005.12872
**Authors:** Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko
**Year:** 2020
**Categories:** cs.CV (Computer Vision and Pattern Recognition)
**Translation Quality:** 0.92
**Glossary Terms Used:** محول (transformer), كشف الأجسام (object detection), مشفر-فك تشفير (encoder-decoder), التنبؤ (prediction), مجموعة بيانات (dataset), التدريب (training), مدرب مسبقاً (pretrained), استدلال (reasoning), متوازٍ (parallel)

### English Abstract
We present a new method that views object detection as a direct set prediction problem. Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like non-maximum suppression or anchor generation that explicitly encode our prior knowledge about the task. The main ingredients of the new framework, called DEtection TRansformer or DETR, are a set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel. The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster RCNN baseline on the challenging COCO object detection dataset. Moreover, DETR can be easily generalized to produce panoptic segmentation in a unified manner. We show that it significantly outperforms competitive baselines.

### الملخص العربي
يقدم الباحثون DETR (محول الكشف)، الذي يعيد صياغة كشف الأجسام كتحدٍ للتنبؤ المباشر بالمجموعات. يزيل نهجهم مكونات خط الأنابيب التقليدية بما في ذلك قمع عدم الحد الأقصى وتوليد المراسي. يجمع إطار العمل بين خسارة شاملة قائمة على المجموعات باستخدام المطابقة الثنائية مع تصميم مشفر-فك تشفير المحول. يعالج النموذج مجموعة ثابتة من استعلامات الأجسام المتعلمة للاستدلال حول علاقات الأجسام وسياق الصورة، وينتج التنبؤات النهائية بشكل متوازٍ. تحقق الطريقة نتائج تنافسية مع Faster RCNN على مجموعة بيانات COCO وتمتد إلى مهام التجزئة الشاملة. تم توفير كود التدريب والنماذج المدربة مسبقاً للجمهور.

### Back-Translation (Validation)
The researchers present DETR (Detection Transformer), which reformulates object detection as a direct set prediction challenge. Their approach eliminates traditional pipeline components including non-maximum suppression and anchor generation. The framework combines a comprehensive set-based loss using bipartisan matching with a transformer encoder-decoder design. The model processes a fixed set of learned object queries to reason about object relationships and image context, and produces final predictions in parallel. The method achieves competitive results with Faster RCNN on the COCO dataset and extends to comprehensive segmentation tasks. Training code and pretrained models have been made available to the public.

### Translation Metrics
- Iterations: 1
- Final Score: 0.92
- Quality: High
---
