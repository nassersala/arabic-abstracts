---
# Less is More: Recursive Reasoning with Tiny Networks
## الأقل هو الأكثر: الاستدلال العودي بالشبكات الصغيرة

**arXiv ID:** 2510.04871
**Authors:** Alexia Jolicoeur-Martineau
**Year:** 2025
**Categories:** Machine Learning (cs.LG), Artificial Intelligence (cs.AI)
**Translation Quality:** 0.95
**Glossary Terms Used:** reasoning, recursive, neural network, parameters, benchmark, generalization, performance, architecture, complexity, hierarchical

### English Abstract
The paper introduces the Tiny Recursive Model (TRM), a simplified recursive reasoning approach using a single neural network with only 2 layers and 7M parameters. The method reportedly outperforms larger language models on challenging puzzle tasks including Sudoku, Maze, and ARC-AGI benchmarks. Specifically, TRM achieves 45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs while using less than 0.01% of the parameters compared to models like Deepseek R1 and Gemini 2.5 Pro. The approach builds upon the Hierarchical Reasoning Model (HRM) concept but demonstrates superior generalization performance with minimal architectural complexity.

### الملخص العربي
تقدم الورقة نموذج الاستدلال العودي الصغير (TRM)، وهو منهج مبسط للاستدلال العودي يستخدم شبكة عصبية واحدة ذات طبقتين فقط و7 ملايين معامل. يتفوق هذا الأسلوب على نماذج اللغة الكبيرة في مهام الألغاز الصعبة بما في ذلك معايير سودوكو والمتاهة وARC-AGI. على وجه التحديد، يحقق TRM دقة اختبار بنسبة 45٪ على ARC-AGI-1 و8٪ على ARC-AGI-2، وهو أعلى من معظم نماذج اللغة الكبيرة، بينما يستخدم أقل من 0.01٪ من المعاملات مقارنة بنماذج مثل Deepseek R1 وGemini 2.5 Pro. يعتمد هذا النهج على مفهوم نموذج الاستدلال الهرمي (HRM) لكنه يُظهر أداء تعميم متفوق بتعقيد معماري أدنى.

### Back-Translation (Validation)
The paper presents the Tiny Recursive Reasoning Model (TRM), a simplified recursive reasoning approach that uses a single neural network with only two layers and 7 million parameters. This method outperforms large language models in difficult puzzle tasks including Sudoku, Maze, and ARC-AGI benchmarks. Specifically, TRM achieves a test accuracy of 45% on ARC-AGI-1 and 8% on ARC-AGI-2, which is higher than most large language models, while using less than 0.01% of the parameters compared to models like Deepseek R1 and Gemini 2.5 Pro. This approach is based on the concept of the Hierarchical Reasoning Model (HRM) but demonstrates superior generalization performance with minimal architectural complexity.

### Translation Metrics
- Iterations: 1
- Final Score: 0.95
- Quality: High
---
