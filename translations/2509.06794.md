# Dato: A Task-Based Programming Model for Dataflow Accelerators
## Dato: نموذج برمجة قائم على المهام لمسرّعات تدفق البيانات

**arXiv ID:** 2509.06794
**Authors:** Shihan Fang, Hongzheng Chen, Niansong Zhang, Jiajie Li, Han Meng, Adrian Liu, Zhiru Zhang
**Year:** 2025
**Categories:** Programming Languages (cs.PL); Hardware Architecture (cs.AR); Machine Learning (cs.LG)
**Translation Quality:** 0.94
**Glossary Terms Used:** programming, optimization, machine learning, framework

### English Abstract
The paper introduces Dato, a Python-embedded programming model designed for dataflow accelerators. The system elevates data communication and sharding to first-class type constructs, allowing developers to express programs as task graphs with explicit stream connections. The approach combines high-level abstractions with fine-grained optimization capabilities. Key results include achieving up to 84% hardware utilization for GEMM on AMD Ryzen AI NPU and demonstrating a 2.81x speedup on attention kernels compared to commercial frameworks.

### الملخص العربي
تقدم الورقة Dato، وهو نموذج برمجة مضمّن في بايثون مصمم لمسرّعات تدفق البيانات. يرفع النظام اتصالات البيانات والتجزئة إلى بنى أنواع من الدرجة الأولى، مما يسمح للمطورين بالتعبير عن البرامج كرسوم بيانية للمهام مع اتصالات تدفق صريحة. يجمع النهج بين التجريدات عالية المستوى وقدرات التحسين الدقيقة. تشمل النتائج الرئيسية تحقيق استخدام للأجهزة يصل إلى 84% لعملية GEMM على وحدة معالجة NPU من AMD Ryzen AI وإظهار تسريع بمقدار 2.81× على نوى الانتباه مقارنة بأطر العمل التجارية.

### Back-Translation (Validation)
The paper introduces Dato, a programming model embedded in Python designed for dataflow accelerators. The system elevates data communications and sharding to first-class type constructs, allowing developers to express programs as task graphs with explicit stream connections. The approach combines high-level abstractions with fine-grained optimization capabilities. Key results include achieving hardware utilization up to 84% for GEMM operation on AMD Ryzen AI NPU and demonstrating a 2.81× speedup on attention cores compared to commercial frameworks.

### Translation Metrics
- Iterations: 1
- Final Score: 0.94
- Quality: High
