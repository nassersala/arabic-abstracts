---
# Deep Learning with Differential Privacy
## التعلم العميق مع الخصوصية التفاضلية

**arXiv ID:** 1607.00133
**Authors:** Martín Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, Li Zhang
**Year:** 2016
**Categories:** stat.ML, cs.CR, cs.LG
**Translation Quality:** 0.92
**Glossary Terms Used:** machine learning (تعلم الآلة), neural networks (شبكة عصبية), deep learning (تعلم عميق), training (التدريب), privacy (خصوصية), differential privacy (خصوصية تفاضلية), model (نموذج), algorithm (خوارزمية)

### English Abstract
Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.

### الملخص العربي
تحقق تقنيات تعلم الآلة القائمة على الشبكات العصبية نتائج ملحوظة في مجموعة واسعة من المجالات. غالباً ما يتطلب تدريب النماذج مجموعات بيانات كبيرة وممثلة، والتي قد يتم الحصول عليها من الجمهور وتحتوي على معلومات حساسة. يجب ألا تكشف النماذج عن معلومات خاصة في مجموعات البيانات هذه. معالجةً لهذا الهدف، نطور تقنيات خوارزمية جديدة للتعلم وتحليلاً محسّناً لتكاليف الخصوصية ضمن إطار الخصوصية التفاضلية. يوضح تنفيذنا وتجاربنا أنه يمكننا تدريب الشبكات العصبية العميقة بأهداف غير محدبة، تحت ميزانية خصوصية متواضعة، وبتكلفة قابلة للإدارة من حيث تعقيد البرمجيات وكفاءة التدريب وجودة النموذج.

### Back-Translation (Validation)
Machine learning techniques based on neural networks achieve remarkable results in a wide range of domains. Often, training models requires large and representative datasets, which may be obtained from the public and contain sensitive information. Models should not reveal private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and an improved analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in terms of software complexity, training efficiency, and model quality.

### Translation Metrics
- Iterations: 1
- Final Score: 0.92
- Quality: High
---
