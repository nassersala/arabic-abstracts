---
# Position: Quo Vadis, Unsupervised Time Series Anomaly Detection?
## ورقة موقف: إلى أين، كشف الشذوذ في السلاسل الزمنية غير الموجه؟

**arXiv ID:** 2405.02678
**Authors:** M. Saquib Sarfraz, Mei-Yen Chen, Lukas Layer, Kunyu Peng, Marios Koulakis
**Year:** 2024
**Categories:** Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV)
**Translation Quality:** 0.91
**Glossary Terms Used:** time series, anomaly detection, unsupervised, deep learning, evaluation, benchmark, model, complexity, interpretability, dataset

### English Abstract
This position paper critiques current practices in time series anomaly detection research. The authors argue that the field relies on flawed evaluation metrics, inconsistent benchmarking practices and insufficient justification for complex model designs. Their analysis reveals that state-of-the-art deep learning models essentially function as linear mappings, suggesting minimal benefit from increased complexity. The paper advocates for redirecting focus toward rigorous evaluation protocols, simpler interpretable methods, and non-trivial datasets rather than pursuing increasingly complex architectures. The work was accepted at ICML 2024.

### الملخص العربي
تنتقد هذه الورقة الموضعية الممارسات الحالية في بحوث كشف الشذوذ في السلاسل الزمنية. يجادل المؤلفون بأن المجال يعتمد على مقاييس تقييم معيبة، وممارسات قياس أداء غير متسقة، ومبررات غير كافية لتصاميم النماذج المعقدة. يكشف تحليلهم أن نماذج التعلم العميق المتقدمة تعمل بشكل أساسي كتعيينات خطية، مما يشير إلى فائدة ضئيلة من زيادة التعقيد. تدعو الورقة إلى إعادة توجيه التركيز نحو بروتوكولات تقييم صارمة، وطرق أبسط قابلة للتفسير، ومجموعات بيانات غير تافهة بدلاً من السعي وراء معماريات أكثر تعقيداً بشكل متزايد. تم قبول العمل في ICML 2024.

### Back-Translation (Validation)
This position paper critiques current practices in time series anomaly detection research. The authors argue that the field relies on flawed evaluation metrics, inconsistent performance measurement practices, and insufficient justifications for complex model designs. Their analysis reveals that advanced deep learning models essentially operate as linear mappings, suggesting minimal benefit from increased complexity. The paper calls for redirecting focus toward rigorous evaluation protocols, simpler interpretable methods, and non-trivial datasets rather than pursuing increasingly complex architectures. The work was accepted at ICML 2024.

### Translation Metrics
- Iterations: 1
- Final Score: 0.91
- Quality: High
---
