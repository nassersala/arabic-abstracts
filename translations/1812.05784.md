---
# PointPillars: Fast Encoders for Object Detection from Point Clouds
## PointPillars: مشفرات سريعة للكشف عن الأجسام من سحب النقاط

**arXiv ID:** 1812.05784
**Authors:** Alex H. Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, Oscar Beijbom
**Year:** 2019
**Categories:** cs.LG, cs.CV, stat.ML
**Translation Quality:** 0.93
**Glossary Terms Used:** سحابة النقاط (point cloud), كشف الأجسام (object detection), مشفر (encoder), القيادة الذاتية (autonomous driving), تمثيل (representation), معمارية (architecture), التفافي (convolutional), ثنائي الأبعاد (2D), ثلاثي الأبعاد (3D), الدقة (precision), التدريب (training), شبكة (network), معيار (benchmark), أداء (performance)

### English Abstract
Object detection in point clouds is an important aspect of many robotics applications such as autonomous driving. In this paper we consider the problem of encoding a point cloud into a format appropriate for a downstream detection pipeline. Recent literature suggests two types of encoders; fixed encoders tend to be fast but sacrifice accuracy, while encoders that are learned from data are more accurate, but slower. In this work we propose PointPillars, a novel encoder which utilizes PointNets to learn a representation of point clouds organized in vertical columns (pillars). While the encoded features can be used with any standard 2D convolutional detection architecture, we further propose a lean downstream network. Extensive experimentation shows that PointPillars outperforms previous encoders with respect to both speed and accuracy by a large margin. Despite only using lidar, our full detection pipeline significantly outperforms the state of the art, even among fusion methods, with respect to both the 3D and bird's eye view KITTI benchmarks. This detection performance is achieved while running at 62 Hz: a 2 - 4 fold runtime improvement. A faster version of our method matches the state of the art at 105 Hz. These benchmarks suggest that PointPillars is an appropriate encoding for object detection in point clouds.

### الملخص العربي
كشف الأجسام في سحابة النقاط جانب مهم من العديد من تطبيقات الروبوتات مثل القيادة الذاتية. في هذا البحث نتناول مشكلة ترميز سحابة النقاط إلى صيغة مناسبة لخط أنابيب الكشف اللاحق. تقترح الأدبيات الحديثة نوعين من المشفرات؛ المشفرات الثابتة تميل إلى أن تكون سريعة لكنها تضحي بالدقة، بينما المشفرات المتعلمة من البيانات أكثر دقة لكنها أبطأ. في هذا العمل نقترح PointPillars، وهو مشفر جديد يستخدم PointNets لتعلم تمثيل لسحب النقاط المنظمة في أعمدة عمودية (أعمدة). بينما يمكن استخدام الميزات المشفرة مع أي معمارية كشف التفافية ثنائية الأبعاد قياسية، نقترح أيضاً شبكة لاحقة نحيفة. تظهر التجارب المكثفة أن PointPillars يتفوق على المشفرات السابقة من حيث السرعة والدقة بهامش كبير. على الرغم من استخدام الليدار فقط، فإن خط أنابيب الكشف الكامل لدينا يتفوق بشكل كبير على أحدث ما توصلت إليه التقنية، حتى بين طرق الدمج، فيما يتعلق بمعايير KITTI ثلاثية الأبعاد ومن منظور عين الطائر. يتم تحقيق أداء الكشف هذا أثناء العمل بتردد 62 هرتز: تحسين من ضعفين إلى 4 أضعاف في وقت التشغيل. نسخة أسرع من طريقتنا تطابق أحدث ما توصلت إليه التقنية عند 105 هرتز.

### Back-Translation (Validation)
Object detection in point clouds is an important aspect of many robotics applications such as autonomous driving. In this research we address the problem of encoding point clouds into a format suitable for downstream detection pipeline. Recent literature proposes two types of encoders; fixed encoders tend to be fast but sacrifice accuracy, while encoders learned from data are more accurate but slower. In this work we propose PointPillars, a new encoder that uses PointNets to learn a representation of point clouds organized in vertical columns (pillars). While the encoded features can be used with any standard 2D convolutional detection architecture, we also propose a lean downstream network. Extensive experiments show that PointPillars outperforms previous encoders in terms of speed and accuracy by a large margin. Despite using only lidar, our full detection pipeline significantly outperforms state of the art, even among fusion methods, regarding 3D KITTI benchmarks and bird's eye view. This detection performance is achieved while running at 62 Hz: a 2 to 4 fold improvement in runtime. A faster version of our method matches state of the art at 105 Hz.

### Translation Metrics
- Iterations: 1
- Final Score: 0.93
- Quality: High
---
