---
# Learning Structure-Aware Representations of Dependent Types
## تعلم تمثيلات واعية بالبنية للأنواع التابعة

**arXiv ID:** 2402.02104
**Authors:** Konstantinos Kogkalidis, Orestis Melkonian, Jean-Philippe Bernardy
**Year:** 2024
**Categories:** Machine Learning (cs.LG); Programming Languages (cs.PL)
**Translation Quality:** 0.92
**Glossary Terms Used:** programming language, proof, formalization, machine learning, practitioner, novel, state, architecture, neural network, principles, type system, dependent types

### English Abstract
Agda is a dependently-typed programming language and a proof assistant, pivotal in proof formalization and programming language theory. This paper extends the Agda ecosystem into machine learning territory, and, vice versa, makes Agda-related resources available to machine learning practitioners. We introduce and release a novel dataset of Agda program-proofs that is elaborate and extensive enough to support various machine learning applications -- the first of its kind. Leveraging the dataset's ultra-high resolution, which details proof states at the sub-type level, we propose a novel neural architecture targeted at faithfully representing dependently-typed programs on the basis of structural rather than nominal principles. We instantiate and evaluate our architecture in a premise selection setup, where it achieves promising initial results, surpassing strong baselines.

### الملخص العربي
Agda هي لغة برمجة ذات أنواع تابعة ومساعد برهان، محورية في الصياغة الرسمية للبراهين ونظرية لغات البرمجة. يمتد هذا البحث بنظام Agda البيئي إلى مجال تعلم الآلة، والعكس صحيح، يجعل الموارد المتعلقة بـ Agda متاحة لممارسي تعلم الآلة. نقدم ونطلق مجموعة بيانات جديدة من برامج-براهين Agda التي هي مفصلة وواسعة بما يكفي لدعم تطبيقات تعلم الآلة المتنوعة -- الأولى من نوعها. بالاستفادة من الدقة الفائقة لمجموعة البيانات، التي تفصل حالات البرهان على مستوى النوع الفرعي، نقترح معمارية عصبية جديدة تستهدف تمثيل البرامج ذات الأنواع التابعة بأمانة على أساس مبادئ بنيوية بدلاً من اسمية. نجسد ونقيم معماريتنا في إعداد اختيار المقدمات، حيث تحقق نتائج أولية واعدة، متجاوزة خطوط الأساس القوية.

### Back-Translation (Validation)
Agda is a dependently-typed programming language and a proof assistant, pivotal in formal formalization of proofs and programming language theory. This research extends the Agda ecosystem to the field of machine learning, and vice versa, makes Agda-related resources available to machine learning practitioners. We introduce and release a novel dataset of Agda program-proofs that is detailed and extensive enough to support various machine learning applications -- the first of its kind. Leveraging the ultra-high resolution of the dataset, which details proof states at the sub-type level, we propose a novel neural architecture targeting faithful representation of dependently-typed programs on the basis of structural rather than nominal principles. We instantiate and evaluate our architecture in a premise selection setup, where it achieves promising initial results, surpassing strong baselines.

### Translation Metrics
- Iterations: 1
- Final Score: 0.92
- Quality: High
---
