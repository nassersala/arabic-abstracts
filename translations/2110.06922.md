---
# DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries
## DETR3D: الكشف عن الأجسام ثلاثية الأبعاد من صور متعددة الرؤى عبر استعلامات من ثلاثي إلى ثنائي الأبعاد

**arXiv ID:** 2110.06922
**Authors:** Yue Wang, Vitor Guizilini, Tianyuan Zhang, Yilun Wang, Hang Zhao, Justin Solomon
**Year:** 2021
**Categories:** cs.CV (Computer Vision and Pattern Recognition), cs.AI (Artificial Intelligence), cs.LG (Machine Learning), cs.RO (Robotics)
**Translation Quality:** 0.93
**Glossary Terms Used:** الكشف عن الأجسام (object detection), ثلاثي الأبعاد (3D), ثنائي الأبعاد (2D), رؤى متعددة (multi-view), إطار عمل (framework), استعلامات (queries), الميزات (features), مصفوفات (matrices), التحويل (transformation), صناديق التحديد (bounding boxes), التنبؤ (prediction), خسارة (loss), تقدير العمق (depth estimation), الاستنتاج (inference), معيار (benchmark), القيادة الذاتية (autonomous driving)

### English Abstract
The paper presents a framework for detecting 3D objects across multiple camera views. Rather than predicting 3D boxes from single images or relying on depth prediction networks, the approach works directly in 3D space. The method extracts 2D features from camera images and employs sparse 3D object queries to connect these features via camera transformation matrices. It predicts bounding boxes per query using set-to-set loss for comparing predictions against ground truth. This top-down strategy avoids compounding errors from separate depth estimation and eliminates post-processing like non-maximum suppression, enhancing inference speed. The technique achieves leading results on the nuScenes autonomous driving benchmark.

### الملخص العربي
يقدم البحث إطار عمل للكشف عن الأجسام ثلاثية الأبعاد عبر رؤى كاميرات متعددة. بدلاً من التنبؤ بالصناديق ثلاثية الأبعاد من صور فردية أو الاعتماد على شبكات التنبؤ بالعمق، يعمل النهج مباشرة في الفضاء ثلاثي الأبعاد. تستخرج الطريقة ميزات ثنائية الأبعاد من صور الكاميرا وتوظف استعلامات أجسام ثلاثية الأبعاد متفرقة لربط هذه الميزات عبر مصفوفات تحويل الكاميرا. تتنبأ بصناديق التحديد لكل استعلام باستخدام خسارة من مجموعة إلى مجموعة لمقارنة التنبؤات مع الحقيقة الأرضية. تتجنب هذه الاستراتيجية من الأعلى إلى الأسفل الأخطاء المركبة من تقدير العمق المنفصل وتزيل المعالجة اللاحقة مثل قمع عدم الحد الأقصى، مما يعزز سرعة الاستنتاج. تحقق التقنية نتائج رائدة على معيار القيادة الذاتية nuScenes.

### Back-Translation (Validation)
The research presents a framework for detecting three-dimensional objects across multiple camera views. Instead of predicting 3D boxes from individual images or relying on depth prediction networks, the approach works directly in three-dimensional space. The method extracts two-dimensional features from camera images and employs sparse 3D object queries to connect these features via camera transformation matrices. It predicts bounding boxes for each query using set-to-set loss to compare predictions with ground truth. This top-down strategy avoids compound errors from separate depth estimation and eliminates post-processing such as non-maximum suppression, enhancing inference speed. The technique achieves leading results on the nuScenes autonomous driving benchmark.

### Translation Metrics
- Iterations: 1
- Final Score: 0.93
- Quality: High
---
